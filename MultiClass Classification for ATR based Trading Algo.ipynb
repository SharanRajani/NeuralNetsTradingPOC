{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import math\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Jump   retOpen  Returns(120mins)  Returns(90mins)  Returns(60mins)  \\\n",
      "0      0.999012 -0.362499         -0.169998        -0.072498        -0.004997   \n",
      "1      0.999012 -0.375000         -0.167500        -0.064999         0.020000   \n",
      "2      0.999012 -0.377502         -0.087502        -0.020000        -0.050003   \n",
      "3      0.999012 -0.397499         -0.087498        -0.002499         0.007504   \n",
      "4      0.999012 -0.505001         -0.147499        -0.177502        -0.142502   \n",
      "...         ...       ...               ...              ...              ...   \n",
      "17203  0.998697 -0.144997          0.017502        -0.004997         0.005005   \n",
      "17204  0.998697 -0.152496         -0.019997        -0.007500         0.012505   \n",
      "17205  0.998697 -0.189995         -0.049995        -0.039993        -0.029999   \n",
      "17206  0.998697 -0.184998         -0.040001        -0.019997        -0.019997   \n",
      "17207  0.998697 -0.172501         -0.022499        -0.012505        -0.027504   \n",
      "\n",
      "       Returns(30mins)  Returns(15mins)       ATR  EndBars  \n",
      "0            -0.035000         0.042503  0.794683       24  \n",
      "1             0.030003        -0.012501  0.794683       23  \n",
      "2            -0.015003        -0.002502  0.794683       22  \n",
      "3            -0.022499        -0.019997  0.794683       21  \n",
      "4            -0.127499        -0.107502  0.794683       20  \n",
      "...                ...              ...       ...      ...  \n",
      "17203         0.014999         0.020004  0.312337        5  \n",
      "17204         0.012505        -0.007500  0.312337        4  \n",
      "17205        -0.044998        -0.037498  0.312337        3  \n",
      "17206        -0.032501         0.004997  0.312337        2  \n",
      "17207         0.017494         0.012497  0.313627        1  \n",
      "\n",
      "[17208 rows x 9 columns]\n",
      "0        4\n",
      "1        4\n",
      "2        4\n",
      "3        4\n",
      "4        4\n",
      "        ..\n",
      "17203    2\n",
      "17204    2\n",
      "17205    2\n",
      "17206    2\n",
      "17207    2\n",
      "Name: Target, Length: 17208, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\rajan\\OneDrive\\Documents\\FullDataset.csv\",sep=\",\")\n",
    "X=data.iloc[:,0:9]\n",
    "print(X)\n",
    "Y=data.iloc[:,9]\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\rajan\\OneDrive\\Documents\\Returns.csv\",sep=\",\")\n",
    "X=data.iloc[:,0]\n",
    "print(X.quantile(0.3))\n",
    "print(X.quantile(0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47787905 0.26957539 0.41093545 0.47212749 0.57388601 0.42523392\n",
      " 0.4394395  0.68147733 1.        ]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.54193548 1.30215664 0.43241613 1.60597294 1.54262662]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(Y),Y)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "Y=Y.to_numpy()\n",
    "Y = Y.reshape(len(Y), 1)\n",
    "Y = onehot_encoder.fit_transform(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(Y))\n",
    "print((len(Y[Y==0])/len(Y))*100)\n",
    "print((len(Y[Y==1])/len(Y))*100)\n",
    "print((len(Y[Y==2])/len(Y))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajan\\AppData\\Local\\conda\\conda\\envs\\PythonGPU\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_107 (Dense)            (None, 256)               2560      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 46,501\n",
      "Trainable params: 46,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13766 samples, validate on 3442 samples\n",
      "Epoch 1/3000\n",
      "13766/13766 [==============================] - 2s 171us/step - loss: 1.4655 - acc: 0.4364 - val_loss: 1.3616 - val_acc: 0.4625\n",
      "Epoch 2/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.3874 - acc: 0.4621 - val_loss: 1.3447 - val_acc: 0.4625\n",
      "Epoch 3/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3685 - acc: 0.4625 - val_loss: 1.3317 - val_acc: 0.4625\n",
      "Epoch 4/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.3625 - acc: 0.4625 - val_loss: 1.3295 - val_acc: 0.4625\n",
      "Epoch 5/3000\n",
      "13766/13766 [==============================] - 1s 75us/step - loss: 1.3554 - acc: 0.4624 - val_loss: 1.3259 - val_acc: 0.4625\n",
      "Epoch 6/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3517 - acc: 0.4635 - val_loss: 1.3340 - val_acc: 0.4625\n",
      "Epoch 7/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.3481 - acc: 0.4640 - val_loss: 1.3221 - val_acc: 0.4625\n",
      "Epoch 8/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3470 - acc: 0.4643 - val_loss: 1.3272 - val_acc: 0.4628\n",
      "Epoch 9/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3414 - acc: 0.4659 - val_loss: 1.3253 - val_acc: 0.4646\n",
      "Epoch 10/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3452 - acc: 0.4635 - val_loss: 1.3220 - val_acc: 0.4628\n",
      "Epoch 11/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3425 - acc: 0.4642 - val_loss: 1.3202 - val_acc: 0.4648\n",
      "Epoch 12/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3399 - acc: 0.4652 - val_loss: 1.3224 - val_acc: 0.4701\n",
      "Epoch 13/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.3410 - acc: 0.4661 - val_loss: 1.3251 - val_acc: 0.4663\n",
      "Epoch 14/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.3389 - acc: 0.4660 - val_loss: 1.3191 - val_acc: 0.4660\n",
      "Epoch 15/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.3354 - acc: 0.4668 - val_loss: 1.3222 - val_acc: 0.4663\n",
      "Epoch 16/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.3418 - acc: 0.4686 - val_loss: 1.3176 - val_acc: 0.4698\n",
      "Epoch 17/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.3350 - acc: 0.4672 - val_loss: 1.3225 - val_acc: 0.4680\n",
      "Epoch 18/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.3365 - acc: 0.4664 - val_loss: 1.3171 - val_acc: 0.4695\n",
      "Epoch 19/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.3358 - acc: 0.4674 - val_loss: 1.3187 - val_acc: 0.4666\n",
      "Epoch 20/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.3315 - acc: 0.4681 - val_loss: 1.3146 - val_acc: 0.4692\n",
      "Epoch 21/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.3348 - acc: 0.4668 - val_loss: 1.3164 - val_acc: 0.4669\n",
      "Epoch 22/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.3323 - acc: 0.4669 - val_loss: 1.3167 - val_acc: 0.4672\n",
      "Epoch 23/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.3312 - acc: 0.4682 - val_loss: 1.3134 - val_acc: 0.4686\n",
      "Epoch 24/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.3318 - acc: 0.4666 - val_loss: 1.3253 - val_acc: 0.4646\n",
      "Epoch 25/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.3311 - acc: 0.4668 - val_loss: 1.3118 - val_acc: 0.4689\n",
      "Epoch 26/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.3322 - acc: 0.4667 - val_loss: 1.3113 - val_acc: 0.4669\n",
      "Epoch 27/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.3284 - acc: 0.4666 - val_loss: 1.3097 - val_acc: 0.4712\n",
      "Epoch 28/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.3315 - acc: 0.4696 - val_loss: 1.3195 - val_acc: 0.4686\n",
      "Epoch 29/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3290 - acc: 0.4689 - val_loss: 1.3128 - val_acc: 0.4704\n",
      "Epoch 30/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 1.3283 - acc: 0.4668 - val_loss: 1.3211 - val_acc: 0.4698\n",
      "Epoch 31/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3290 - acc: 0.4681 - val_loss: 1.3153 - val_acc: 0.4683\n",
      "Epoch 32/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.3260 - acc: 0.4690 - val_loss: 1.3104 - val_acc: 0.4698\n",
      "Epoch 33/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.3270 - acc: 0.4660 - val_loss: 1.3148 - val_acc: 0.4698\n",
      "Epoch 34/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.3291 - acc: 0.4666 - val_loss: 1.3131 - val_acc: 0.4663\n",
      "Epoch 35/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3270 - acc: 0.4675 - val_loss: 1.3160 - val_acc: 0.4669\n",
      "Epoch 36/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.3270 - acc: 0.4691 - val_loss: 1.3136 - val_acc: 0.4666\n",
      "Epoch 37/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.3286 - acc: 0.4672 - val_loss: 1.3089 - val_acc: 0.4683\n",
      "Epoch 38/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.3239 - acc: 0.4689 - val_loss: 1.3080 - val_acc: 0.4689\n",
      "Epoch 39/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.3264 - acc: 0.4664 - val_loss: 1.3093 - val_acc: 0.4695\n",
      "Epoch 40/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.3266 - acc: 0.4690 - val_loss: 1.3089 - val_acc: 0.4704\n",
      "Epoch 41/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.3223 - acc: 0.4698 - val_loss: 1.3072 - val_acc: 0.4701\n",
      "Epoch 42/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3255 - acc: 0.4667 - val_loss: 1.3074 - val_acc: 0.4707\n",
      "Epoch 43/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.3238 - acc: 0.4689 - val_loss: 1.3121 - val_acc: 0.4695\n",
      "Epoch 44/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3244 - acc: 0.4707 - val_loss: 1.3096 - val_acc: 0.4704\n",
      "Epoch 45/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 1.3224 - acc: 0.4698 - val_loss: 1.3111 - val_acc: 0.4707\n",
      "Epoch 46/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3239 - acc: 0.4693 - val_loss: 1.3097 - val_acc: 0.4686\n",
      "Epoch 47/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3214 - acc: 0.4701 - val_loss: 1.3102 - val_acc: 0.4686\n",
      "Epoch 48/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3243 - acc: 0.4697 - val_loss: 1.3096 - val_acc: 0.4686\n",
      "Epoch 49/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.3220 - acc: 0.4706 - val_loss: 1.3126 - val_acc: 0.4675\n",
      "Epoch 50/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.3220 - acc: 0.4723 - val_loss: 1.3039 - val_acc: 0.4709\n",
      "Epoch 51/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.3191 - acc: 0.4682 - val_loss: 1.3113 - val_acc: 0.4704\n",
      "Epoch 52/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3225 - acc: 0.4688 - val_loss: 1.3134 - val_acc: 0.4686\n",
      "Epoch 53/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.3211 - acc: 0.4709 - val_loss: 1.3147 - val_acc: 0.4689\n",
      "Epoch 54/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.3215 - acc: 0.4672 - val_loss: 1.3108 - val_acc: 0.4695\n",
      "Epoch 55/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.3209 - acc: 0.4688 - val_loss: 1.3063 - val_acc: 0.4707\n",
      "Epoch 56/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3182 - acc: 0.4678 - val_loss: 1.3102 - val_acc: 0.4692\n",
      "Epoch 57/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.3179 - acc: 0.4706 - val_loss: 1.3050 - val_acc: 0.4698\n",
      "Epoch 58/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3163 - acc: 0.4699 - val_loss: 1.3052 - val_acc: 0.4709\n",
      "Epoch 59/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.3188 - acc: 0.4686 - val_loss: 1.3081 - val_acc: 0.4686\n",
      "Epoch 60/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3171 - acc: 0.4711 - val_loss: 1.3089 - val_acc: 0.4698\n",
      "Epoch 61/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3162 - acc: 0.4699 - val_loss: 1.3039 - val_acc: 0.4683\n",
      "Epoch 62/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3171 - acc: 0.4694 - val_loss: 1.3041 - val_acc: 0.4683\n",
      "Epoch 63/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3148 - acc: 0.4721 - val_loss: 1.3079 - val_acc: 0.4683\n",
      "Epoch 64/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.3165 - acc: 0.4682 - val_loss: 1.3026 - val_acc: 0.4683\n",
      "Epoch 65/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.3146 - acc: 0.4715 - val_loss: 1.3035 - val_acc: 0.4675\n",
      "Epoch 66/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3136 - acc: 0.4716 - val_loss: 1.3053 - val_acc: 0.4727\n",
      "Epoch 67/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.3142 - acc: 0.4704 - val_loss: 1.3031 - val_acc: 0.4686\n",
      "Epoch 68/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 1.3163 - acc: 0.4694 - val_loss: 1.3012 - val_acc: 0.4675\n",
      "Epoch 69/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3136 - acc: 0.4708 - val_loss: 1.3083 - val_acc: 0.4678\n",
      "Epoch 70/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.3163 - acc: 0.4696 - val_loss: 1.2985 - val_acc: 0.4680\n",
      "Epoch 71/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3111 - acc: 0.4704 - val_loss: 1.3002 - val_acc: 0.4698\n",
      "Epoch 72/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3118 - acc: 0.4715 - val_loss: 1.3096 - val_acc: 0.4736\n",
      "Epoch 73/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.3109 - acc: 0.4712 - val_loss: 1.2994 - val_acc: 0.4686\n",
      "Epoch 74/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.3093 - acc: 0.4707 - val_loss: 1.2948 - val_acc: 0.4712\n",
      "Epoch 75/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3099 - acc: 0.4715 - val_loss: 1.2970 - val_acc: 0.4698\n",
      "Epoch 76/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3071 - acc: 0.4704 - val_loss: 1.2950 - val_acc: 0.4669\n",
      "Epoch 77/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3093 - acc: 0.4712 - val_loss: 1.2931 - val_acc: 0.4680\n",
      "Epoch 78/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.3076 - acc: 0.4736 - val_loss: 1.2983 - val_acc: 0.4698\n",
      "Epoch 79/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.3055 - acc: 0.4733 - val_loss: 1.2957 - val_acc: 0.4698\n",
      "Epoch 80/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.3066 - acc: 0.4718 - val_loss: 1.2941 - val_acc: 0.4686\n",
      "Epoch 81/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3015 - acc: 0.4742 - val_loss: 1.2930 - val_acc: 0.4660\n",
      "Epoch 82/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.3033 - acc: 0.4743 - val_loss: 1.2967 - val_acc: 0.4660\n",
      "Epoch 83/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.3039 - acc: 0.4738 - val_loss: 1.2960 - val_acc: 0.4675\n",
      "Epoch 84/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.3035 - acc: 0.4738 - val_loss: 1.2919 - val_acc: 0.4683\n",
      "Epoch 85/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.3015 - acc: 0.4716 - val_loss: 1.2884 - val_acc: 0.4695\n",
      "Epoch 86/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3025 - acc: 0.4727 - val_loss: 1.2890 - val_acc: 0.4715\n",
      "Epoch 87/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2988 - acc: 0.4746 - val_loss: 1.2913 - val_acc: 0.4678\n",
      "Epoch 88/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.3041 - acc: 0.4749 - val_loss: 1.2900 - val_acc: 0.4663\n",
      "Epoch 89/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3000 - acc: 0.4750 - val_loss: 1.2851 - val_acc: 0.4733\n",
      "Epoch 90/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.3002 - acc: 0.4744 - val_loss: 1.2893 - val_acc: 0.4712\n",
      "Epoch 91/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2972 - acc: 0.4754 - val_loss: 1.2899 - val_acc: 0.4666\n",
      "Epoch 92/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.2943 - acc: 0.4776 - val_loss: 1.2832 - val_acc: 0.4718\n",
      "Epoch 93/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2950 - acc: 0.4768 - val_loss: 1.2821 - val_acc: 0.4651\n",
      "Epoch 94/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2949 - acc: 0.4789 - val_loss: 1.2797 - val_acc: 0.4756\n",
      "Epoch 95/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2953 - acc: 0.4784 - val_loss: 1.2798 - val_acc: 0.4770\n",
      "Epoch 96/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.2955 - acc: 0.4811 - val_loss: 1.2779 - val_acc: 0.4712\n",
      "Epoch 97/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2888 - acc: 0.4803 - val_loss: 1.2945 - val_acc: 0.4709\n",
      "Epoch 98/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2937 - acc: 0.4765 - val_loss: 1.2752 - val_acc: 0.4788\n",
      "Epoch 99/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.2880 - acc: 0.4814 - val_loss: 1.2852 - val_acc: 0.4768\n",
      "Epoch 100/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2901 - acc: 0.4823 - val_loss: 1.2808 - val_acc: 0.4811\n",
      "Epoch 101/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.2866 - acc: 0.4827 - val_loss: 1.2731 - val_acc: 0.4814\n",
      "Epoch 102/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2857 - acc: 0.4794 - val_loss: 1.2833 - val_acc: 0.4747\n",
      "Epoch 103/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2876 - acc: 0.4779 - val_loss: 1.2727 - val_acc: 0.4855\n",
      "Epoch 104/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 1.2853 - acc: 0.4821 - val_loss: 1.2801 - val_acc: 0.4808\n",
      "Epoch 105/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.2846 - acc: 0.4855 - val_loss: 1.2710 - val_acc: 0.4904\n",
      "Epoch 106/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.2850 - acc: 0.4824 - val_loss: 1.2811 - val_acc: 0.4872\n",
      "Epoch 107/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2809 - acc: 0.4831 - val_loss: 1.2683 - val_acc: 0.4959\n",
      "Epoch 108/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.2817 - acc: 0.4867 - val_loss: 1.2717 - val_acc: 0.4910\n",
      "Epoch 109/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2820 - acc: 0.4838 - val_loss: 1.2726 - val_acc: 0.4852\n",
      "Epoch 110/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.2834 - acc: 0.4843 - val_loss: 1.2736 - val_acc: 0.4907\n",
      "Epoch 111/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.2811 - acc: 0.4861 - val_loss: 1.2673 - val_acc: 0.4933\n",
      "Epoch 112/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2797 - acc: 0.4862 - val_loss: 1.2750 - val_acc: 0.4808\n",
      "Epoch 113/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2795 - acc: 0.4863 - val_loss: 1.2788 - val_acc: 0.4768\n",
      "Epoch 114/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2764 - acc: 0.4871 - val_loss: 1.2719 - val_acc: 0.4913\n",
      "Epoch 115/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2753 - acc: 0.4916 - val_loss: 1.2626 - val_acc: 0.4965\n",
      "Epoch 116/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2726 - acc: 0.4877 - val_loss: 1.2696 - val_acc: 0.4939\n",
      "Epoch 117/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2743 - acc: 0.4887 - val_loss: 1.2594 - val_acc: 0.4962\n",
      "Epoch 118/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.2753 - acc: 0.4882 - val_loss: 1.2593 - val_acc: 0.4983\n",
      "Epoch 119/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2731 - acc: 0.4892 - val_loss: 1.2610 - val_acc: 0.4971\n",
      "Epoch 120/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.2730 - acc: 0.4872 - val_loss: 1.2558 - val_acc: 0.4954\n",
      "Epoch 121/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.2692 - acc: 0.4906 - val_loss: 1.2548 - val_acc: 0.5017\n",
      "Epoch 122/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.2680 - acc: 0.4874 - val_loss: 1.2531 - val_acc: 0.4977\n",
      "Epoch 123/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.2698 - acc: 0.4914 - val_loss: 1.2604 - val_acc: 0.4924\n",
      "Epoch 124/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.2705 - acc: 0.4915 - val_loss: 1.2521 - val_acc: 0.5000\n",
      "Epoch 125/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2671 - acc: 0.4931 - val_loss: 1.2679 - val_acc: 0.4890\n",
      "Epoch 126/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2690 - acc: 0.4906 - val_loss: 1.2613 - val_acc: 0.4977\n",
      "Epoch 127/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2649 - acc: 0.4948 - val_loss: 1.2569 - val_acc: 0.5029\n",
      "Epoch 128/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.2617 - acc: 0.4923 - val_loss: 1.2469 - val_acc: 0.5070\n",
      "Epoch 129/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.2622 - acc: 0.4939 - val_loss: 1.2536 - val_acc: 0.5052\n",
      "Epoch 130/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.2612 - acc: 0.4945 - val_loss: 1.2551 - val_acc: 0.4991\n",
      "Epoch 131/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.2606 - acc: 0.4959 - val_loss: 1.2504 - val_acc: 0.4942\n",
      "Epoch 132/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2632 - acc: 0.4938 - val_loss: 1.2575 - val_acc: 0.5015\n",
      "Epoch 133/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.2612 - acc: 0.4951 - val_loss: 1.2432 - val_acc: 0.5070\n",
      "Epoch 134/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2606 - acc: 0.4942 - val_loss: 1.2506 - val_acc: 0.5038\n",
      "Epoch 135/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.2593 - acc: 0.4964 - val_loss: 1.2446 - val_acc: 0.5061\n",
      "Epoch 136/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.2593 - acc: 0.4948 - val_loss: 1.2422 - val_acc: 0.5064\n",
      "Epoch 137/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.2555 - acc: 0.4946 - val_loss: 1.2499 - val_acc: 0.5029\n",
      "Epoch 138/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.2541 - acc: 0.5013 - val_loss: 1.2404 - val_acc: 0.5076\n",
      "Epoch 139/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.2544 - acc: 0.4972 - val_loss: 1.2479 - val_acc: 0.5078\n",
      "Epoch 140/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2591 - acc: 0.4997 - val_loss: 1.2512 - val_acc: 0.4983\n",
      "Epoch 141/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.2542 - acc: 0.4934 - val_loss: 1.2405 - val_acc: 0.5026\n",
      "Epoch 142/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.2534 - acc: 0.4980 - val_loss: 1.2446 - val_acc: 0.5070\n",
      "Epoch 143/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2484 - acc: 0.5005 - val_loss: 1.2415 - val_acc: 0.5064\n",
      "Epoch 144/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2477 - acc: 0.5014 - val_loss: 1.2451 - val_acc: 0.5023\n",
      "Epoch 145/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2520 - acc: 0.4998 - val_loss: 1.2422 - val_acc: 0.5084\n",
      "Epoch 146/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2470 - acc: 0.5009 - val_loss: 1.2402 - val_acc: 0.5070\n",
      "Epoch 147/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.2470 - acc: 0.5003 - val_loss: 1.2382 - val_acc: 0.5099\n",
      "Epoch 148/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.2480 - acc: 0.5000 - val_loss: 1.2453 - val_acc: 0.5113\n",
      "Epoch 149/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.2547 - acc: 0.4988 - val_loss: 1.2363 - val_acc: 0.5081\n",
      "Epoch 150/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.2448 - acc: 0.5016 - val_loss: 1.2289 - val_acc: 0.5087\n",
      "Epoch 151/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.2457 - acc: 0.5018 - val_loss: 1.2355 - val_acc: 0.5134\n",
      "Epoch 152/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.2453 - acc: 0.5033 - val_loss: 1.2299 - val_acc: 0.5099\n",
      "Epoch 153/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.2443 - acc: 0.5009 - val_loss: 1.2296 - val_acc: 0.5125\n",
      "Epoch 154/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2417 - acc: 0.5060 - val_loss: 1.2252 - val_acc: 0.5099\n",
      "Epoch 155/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2441 - acc: 0.5045 - val_loss: 1.2339 - val_acc: 0.5084\n",
      "Epoch 156/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2446 - acc: 0.5022 - val_loss: 1.2266 - val_acc: 0.5105\n",
      "Epoch 157/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2380 - acc: 0.5053 - val_loss: 1.2356 - val_acc: 0.5052\n",
      "Epoch 158/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2383 - acc: 0.5052 - val_loss: 1.2265 - val_acc: 0.5116\n",
      "Epoch 159/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.2403 - acc: 0.5044 - val_loss: 1.2380 - val_acc: 0.5122\n",
      "Epoch 160/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2370 - acc: 0.5073 - val_loss: 1.2296 - val_acc: 0.5142\n",
      "Epoch 161/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2348 - acc: 0.5078 - val_loss: 1.2289 - val_acc: 0.5110\n",
      "Epoch 162/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2397 - acc: 0.5008 - val_loss: 1.2495 - val_acc: 0.5035\n",
      "Epoch 163/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2319 - acc: 0.5070 - val_loss: 1.2178 - val_acc: 0.5186\n",
      "Epoch 164/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2329 - acc: 0.5058 - val_loss: 1.2250 - val_acc: 0.5206\n",
      "Epoch 165/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.2391 - acc: 0.5057 - val_loss: 1.2328 - val_acc: 0.5116\n",
      "Epoch 166/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.2327 - acc: 0.5073 - val_loss: 1.2251 - val_acc: 0.5137\n",
      "Epoch 167/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 1.2349 - acc: 0.5070 - val_loss: 1.2218 - val_acc: 0.5128\n",
      "Epoch 168/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.2301 - acc: 0.5072 - val_loss: 1.2259 - val_acc: 0.5102\n",
      "Epoch 169/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.2354 - acc: 0.5046 - val_loss: 1.2182 - val_acc: 0.5203\n",
      "Epoch 170/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.2254 - acc: 0.5084 - val_loss: 1.2199 - val_acc: 0.5171\n",
      "Epoch 171/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2338 - acc: 0.5047 - val_loss: 1.2325 - val_acc: 0.5166\n",
      "Epoch 172/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.2302 - acc: 0.5065 - val_loss: 1.2157 - val_acc: 0.5169\n",
      "Epoch 173/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2316 - acc: 0.5077 - val_loss: 1.2044 - val_acc: 0.5230\n",
      "Epoch 174/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 1.2281 - acc: 0.5059 - val_loss: 1.2212 - val_acc: 0.5128\n",
      "Epoch 175/3000\n",
      "13766/13766 [==============================] - 1s 64us/step - loss: 1.2277 - acc: 0.5108 - val_loss: 1.2079 - val_acc: 0.5177\n",
      "Epoch 176/3000\n",
      "13766/13766 [==============================] - 1s 68us/step - loss: 1.2211 - acc: 0.5118 - val_loss: 1.2149 - val_acc: 0.5218\n",
      "Epoch 177/3000\n",
      "13766/13766 [==============================] - 1s 73us/step - loss: 1.2273 - acc: 0.5076 - val_loss: 1.2221 - val_acc: 0.5099\n",
      "Epoch 178/3000\n",
      "13766/13766 [==============================] - 1s 67us/step - loss: 1.2198 - acc: 0.5121 - val_loss: 1.2145 - val_acc: 0.5206\n",
      "Epoch 179/3000\n",
      "13766/13766 [==============================] - 1s 75us/step - loss: 1.2201 - acc: 0.5106 - val_loss: 1.2146 - val_acc: 0.5163\n",
      "Epoch 180/3000\n",
      "13766/13766 [==============================] - 1s 64us/step - loss: 1.2270 - acc: 0.5067 - val_loss: 1.2100 - val_acc: 0.5169\n",
      "Epoch 181/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 1.2148 - acc: 0.5142 - val_loss: 1.2009 - val_acc: 0.5224\n",
      "Epoch 182/3000\n",
      "13766/13766 [==============================] - 1s 63us/step - loss: 1.2233 - acc: 0.5142 - val_loss: 1.2072 - val_acc: 0.5128\n",
      "Epoch 183/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.2285 - acc: 0.5077 - val_loss: 1.2032 - val_acc: 0.5230\n",
      "Epoch 184/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 1.2197 - acc: 0.5129 - val_loss: 1.2089 - val_acc: 0.5145\n",
      "Epoch 185/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2179 - acc: 0.5101 - val_loss: 1.1994 - val_acc: 0.5128\n",
      "Epoch 186/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.2208 - acc: 0.5121 - val_loss: 1.2090 - val_acc: 0.5180\n",
      "Epoch 187/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.2168 - acc: 0.5126 - val_loss: 1.2118 - val_acc: 0.5212\n",
      "Epoch 188/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.2163 - acc: 0.5104 - val_loss: 1.2047 - val_acc: 0.5154\n",
      "Epoch 189/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.2156 - acc: 0.5166 - val_loss: 1.2135 - val_acc: 0.5169\n",
      "Epoch 190/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.2163 - acc: 0.5135 - val_loss: 1.2160 - val_acc: 0.5116\n",
      "Epoch 191/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.2143 - acc: 0.5129 - val_loss: 1.2129 - val_acc: 0.5206\n",
      "Epoch 192/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 1.2160 - acc: 0.5123 - val_loss: 1.2106 - val_acc: 0.5212\n",
      "Epoch 193/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.2106 - acc: 0.5152 - val_loss: 1.1986 - val_acc: 0.5215\n",
      "Epoch 194/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.2136 - acc: 0.5158 - val_loss: 1.1995 - val_acc: 0.5232\n",
      "Epoch 195/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.2117 - acc: 0.5155 - val_loss: 1.2053 - val_acc: 0.5232\n",
      "Epoch 196/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.2061 - acc: 0.5149 - val_loss: 1.2041 - val_acc: 0.5230\n",
      "Epoch 197/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.2084 - acc: 0.5169 - val_loss: 1.2117 - val_acc: 0.5279\n",
      "Epoch 198/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.2103 - acc: 0.5158 - val_loss: 1.2078 - val_acc: 0.5200\n",
      "Epoch 199/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.2108 - acc: 0.5135 - val_loss: 1.1947 - val_acc: 0.5206\n",
      "Epoch 200/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2096 - acc: 0.5136 - val_loss: 1.2103 - val_acc: 0.5192\n",
      "Epoch 201/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.2118 - acc: 0.5123 - val_loss: 1.2012 - val_acc: 0.5256\n",
      "Epoch 202/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.2089 - acc: 0.5142 - val_loss: 1.1895 - val_acc: 0.5261\n",
      "Epoch 203/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.2100 - acc: 0.5131 - val_loss: 1.2038 - val_acc: 0.5215\n",
      "Epoch 204/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.2050 - acc: 0.5147 - val_loss: 1.1881 - val_acc: 0.5259\n",
      "Epoch 205/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.2056 - acc: 0.5165 - val_loss: 1.2111 - val_acc: 0.5171\n",
      "Epoch 206/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.2048 - acc: 0.5171 - val_loss: 1.1948 - val_acc: 0.5302\n",
      "Epoch 207/3000\n",
      "13766/13766 [==============================] - 1s 64us/step - loss: 1.2005 - acc: 0.5188 - val_loss: 1.1954 - val_acc: 0.5261\n",
      "Epoch 208/3000\n",
      "13766/13766 [==============================] - 1s 70us/step - loss: 1.2067 - acc: 0.5134 - val_loss: 1.1885 - val_acc: 0.5305\n",
      "Epoch 209/3000\n",
      "13766/13766 [==============================] - 1s 72us/step - loss: 1.2011 - acc: 0.5191 - val_loss: 1.1971 - val_acc: 0.5247\n",
      "Epoch 210/3000\n",
      "13766/13766 [==============================] - 1s 72us/step - loss: 1.2048 - acc: 0.5173 - val_loss: 1.1953 - val_acc: 0.5200\n",
      "Epoch 211/3000\n",
      "13766/13766 [==============================] - 1s 67us/step - loss: 1.1955 - acc: 0.5227 - val_loss: 1.2112 - val_acc: 0.5198\n",
      "Epoch 212/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.2047 - acc: 0.5151 - val_loss: 1.1860 - val_acc: 0.5253\n",
      "Epoch 213/3000\n",
      "13766/13766 [==============================] - 1s 65us/step - loss: 1.1959 - acc: 0.5188 - val_loss: 1.1895 - val_acc: 0.5256\n",
      "Epoch 214/3000\n",
      "13766/13766 [==============================] - 1s 66us/step - loss: 1.1930 - acc: 0.5219 - val_loss: 1.1945 - val_acc: 0.5253\n",
      "Epoch 215/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.1994 - acc: 0.5198 - val_loss: 1.2094 - val_acc: 0.5186\n",
      "Epoch 216/3000\n",
      "13766/13766 [==============================] - 1s 65us/step - loss: 1.1983 - acc: 0.5214 - val_loss: 1.1984 - val_acc: 0.5267\n",
      "Epoch 217/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.1982 - acc: 0.5176 - val_loss: 1.1898 - val_acc: 0.5247\n",
      "Epoch 218/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.1975 - acc: 0.5160 - val_loss: 1.1830 - val_acc: 0.5270\n",
      "Epoch 219/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1945 - acc: 0.5227 - val_loss: 1.1948 - val_acc: 0.5267\n",
      "Epoch 220/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1929 - acc: 0.5175 - val_loss: 1.2029 - val_acc: 0.5192\n",
      "Epoch 221/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.2024 - acc: 0.5165 - val_loss: 1.1835 - val_acc: 0.5293\n",
      "Epoch 222/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.1995 - acc: 0.5183 - val_loss: 1.1929 - val_acc: 0.5267\n",
      "Epoch 223/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.1964 - acc: 0.5182 - val_loss: 1.1937 - val_acc: 0.5250\n",
      "Epoch 224/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.1982 - acc: 0.5180 - val_loss: 1.1854 - val_acc: 0.5279\n",
      "Epoch 225/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.1974 - acc: 0.5170 - val_loss: 1.1838 - val_acc: 0.5270\n",
      "Epoch 226/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1948 - acc: 0.5143 - val_loss: 1.1905 - val_acc: 0.5296\n",
      "Epoch 227/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1975 - acc: 0.5208 - val_loss: 1.1803 - val_acc: 0.5273\n",
      "Epoch 228/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 1.1896 - acc: 0.5228 - val_loss: 1.1796 - val_acc: 0.5288\n",
      "Epoch 229/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 1.1926 - acc: 0.5200 - val_loss: 1.1836 - val_acc: 0.5247\n",
      "Epoch 230/3000\n",
      "13766/13766 [==============================] - 1s 64us/step - loss: 1.1841 - acc: 0.5227 - val_loss: 1.1869 - val_acc: 0.5285\n",
      "Epoch 231/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1889 - acc: 0.5198 - val_loss: 1.1861 - val_acc: 0.5346\n",
      "Epoch 232/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1968 - acc: 0.5198 - val_loss: 1.2016 - val_acc: 0.5241\n",
      "Epoch 233/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.1927 - acc: 0.5225 - val_loss: 1.1859 - val_acc: 0.5282\n",
      "Epoch 234/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1834 - acc: 0.5231 - val_loss: 1.1842 - val_acc: 0.5308\n",
      "Epoch 235/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1839 - acc: 0.5259 - val_loss: 1.1856 - val_acc: 0.5247\n",
      "Epoch 236/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1913 - acc: 0.5216 - val_loss: 1.1880 - val_acc: 0.5296\n",
      "Epoch 237/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1933 - acc: 0.5182 - val_loss: 1.1855 - val_acc: 0.5261\n",
      "Epoch 238/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1908 - acc: 0.5200 - val_loss: 1.1908 - val_acc: 0.5259\n",
      "Epoch 239/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1891 - acc: 0.5214 - val_loss: 1.1775 - val_acc: 0.5296\n",
      "Epoch 240/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1881 - acc: 0.5239 - val_loss: 1.1726 - val_acc: 0.5328\n",
      "Epoch 241/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1850 - acc: 0.5256 - val_loss: 1.1756 - val_acc: 0.5322\n",
      "Epoch 242/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1910 - acc: 0.5222 - val_loss: 1.1792 - val_acc: 0.5317\n",
      "Epoch 243/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1796 - acc: 0.5267 - val_loss: 1.1937 - val_acc: 0.5195\n",
      "Epoch 244/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1848 - acc: 0.5246 - val_loss: 1.1708 - val_acc: 0.5340\n",
      "Epoch 245/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1872 - acc: 0.5270 - val_loss: 1.1657 - val_acc: 0.5340\n",
      "Epoch 246/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1890 - acc: 0.5251 - val_loss: 1.1824 - val_acc: 0.5221\n",
      "Epoch 247/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1860 - acc: 0.5259 - val_loss: 1.1720 - val_acc: 0.5352\n",
      "Epoch 248/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1833 - acc: 0.5230 - val_loss: 1.1756 - val_acc: 0.5334\n",
      "Epoch 249/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1854 - acc: 0.5252 - val_loss: 1.1721 - val_acc: 0.5314\n",
      "Epoch 250/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1853 - acc: 0.5241 - val_loss: 1.1642 - val_acc: 0.5322\n",
      "Epoch 251/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1812 - acc: 0.5256 - val_loss: 1.1853 - val_acc: 0.5320\n",
      "Epoch 252/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1877 - acc: 0.5255 - val_loss: 1.1726 - val_acc: 0.5273\n",
      "Epoch 253/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1762 - acc: 0.5272 - val_loss: 1.1722 - val_acc: 0.5340\n",
      "Epoch 254/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1789 - acc: 0.5256 - val_loss: 1.1696 - val_acc: 0.5291\n",
      "Epoch 255/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1780 - acc: 0.5277 - val_loss: 1.1873 - val_acc: 0.5296\n",
      "Epoch 256/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1793 - acc: 0.5236 - val_loss: 1.1695 - val_acc: 0.5357\n",
      "Epoch 257/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1794 - acc: 0.5260 - val_loss: 1.1662 - val_acc: 0.5366\n",
      "Epoch 258/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1817 - acc: 0.5270 - val_loss: 1.1791 - val_acc: 0.5276\n",
      "Epoch 259/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1824 - acc: 0.5254 - val_loss: 1.1709 - val_acc: 0.5352\n",
      "Epoch 260/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1737 - acc: 0.5285 - val_loss: 1.1712 - val_acc: 0.5317\n",
      "Epoch 261/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1778 - acc: 0.5262 - val_loss: 1.1798 - val_acc: 0.5285\n",
      "Epoch 262/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1768 - acc: 0.5279 - val_loss: 1.1740 - val_acc: 0.5325\n",
      "Epoch 263/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1797 - acc: 0.5295 - val_loss: 1.1681 - val_acc: 0.5357\n",
      "Epoch 264/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1753 - acc: 0.5281 - val_loss: 1.1626 - val_acc: 0.5311\n",
      "Epoch 265/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1807 - acc: 0.5228 - val_loss: 1.1740 - val_acc: 0.5328\n",
      "Epoch 266/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1794 - acc: 0.5256 - val_loss: 1.1720 - val_acc: 0.5325\n",
      "Epoch 267/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1756 - acc: 0.5296 - val_loss: 1.1698 - val_acc: 0.5381\n",
      "Epoch 268/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1698 - acc: 0.5317 - val_loss: 1.1695 - val_acc: 0.5334\n",
      "Epoch 269/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1707 - acc: 0.5305 - val_loss: 1.1708 - val_acc: 0.5340\n",
      "Epoch 270/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1660 - acc: 0.5315 - val_loss: 1.1741 - val_acc: 0.5325\n",
      "Epoch 271/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1745 - acc: 0.5277 - val_loss: 1.1738 - val_acc: 0.5325\n",
      "Epoch 272/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1711 - acc: 0.5316 - val_loss: 1.1717 - val_acc: 0.5383\n",
      "Epoch 273/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1724 - acc: 0.5278 - val_loss: 1.1592 - val_acc: 0.5375\n",
      "Epoch 274/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1685 - acc: 0.5281 - val_loss: 1.1569 - val_acc: 0.5386\n",
      "Epoch 275/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1701 - acc: 0.5320 - val_loss: 1.1768 - val_acc: 0.5302\n",
      "Epoch 276/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1797 - acc: 0.5277 - val_loss: 1.1702 - val_acc: 0.5418\n",
      "Epoch 277/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1696 - acc: 0.5303 - val_loss: 1.1688 - val_acc: 0.5372\n",
      "Epoch 278/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1718 - acc: 0.5278 - val_loss: 1.1613 - val_acc: 0.5439\n",
      "Epoch 279/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1700 - acc: 0.5259 - val_loss: 1.1609 - val_acc: 0.5383\n",
      "Epoch 280/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1715 - acc: 0.5285 - val_loss: 1.1526 - val_acc: 0.5383\n",
      "Epoch 281/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1767 - acc: 0.5262 - val_loss: 1.1671 - val_acc: 0.5296\n",
      "Epoch 282/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1740 - acc: 0.5317 - val_loss: 1.1726 - val_acc: 0.5346\n",
      "Epoch 283/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1704 - acc: 0.5329 - val_loss: 1.1658 - val_acc: 0.5439\n",
      "Epoch 284/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1702 - acc: 0.5282 - val_loss: 1.1562 - val_acc: 0.5386\n",
      "Epoch 285/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1666 - acc: 0.5338 - val_loss: 1.1573 - val_acc: 0.5456\n",
      "Epoch 286/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1613 - acc: 0.5318 - val_loss: 1.1589 - val_acc: 0.5383\n",
      "Epoch 287/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1596 - acc: 0.5331 - val_loss: 1.1676 - val_acc: 0.5346\n",
      "Epoch 288/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1602 - acc: 0.5323 - val_loss: 1.1673 - val_acc: 0.5349\n",
      "Epoch 289/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1682 - acc: 0.5305 - val_loss: 1.1729 - val_acc: 0.5392\n",
      "Epoch 290/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1668 - acc: 0.5282 - val_loss: 1.1643 - val_acc: 0.5395\n",
      "Epoch 291/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1667 - acc: 0.5306 - val_loss: 1.1541 - val_acc: 0.5401\n",
      "Epoch 292/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1692 - acc: 0.5326 - val_loss: 1.1513 - val_acc: 0.5375\n",
      "Epoch 293/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1562 - acc: 0.5336 - val_loss: 1.1526 - val_acc: 0.5401\n",
      "Epoch 294/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1598 - acc: 0.5331 - val_loss: 1.1706 - val_acc: 0.5401\n",
      "Epoch 295/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1693 - acc: 0.5277 - val_loss: 1.1577 - val_acc: 0.5363\n",
      "Epoch 296/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1602 - acc: 0.5322 - val_loss: 1.1472 - val_acc: 0.5462\n",
      "Epoch 297/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1651 - acc: 0.5321 - val_loss: 1.1629 - val_acc: 0.5427\n",
      "Epoch 298/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1629 - acc: 0.5326 - val_loss: 1.1577 - val_acc: 0.5386\n",
      "Epoch 299/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1575 - acc: 0.5340 - val_loss: 1.1685 - val_acc: 0.5299\n",
      "Epoch 300/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1601 - acc: 0.5341 - val_loss: 1.1661 - val_acc: 0.5354\n",
      "Epoch 301/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1588 - acc: 0.5333 - val_loss: 1.1538 - val_acc: 0.5413\n",
      "Epoch 302/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1646 - acc: 0.5259 - val_loss: 1.1579 - val_acc: 0.5395\n",
      "Epoch 303/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1527 - acc: 0.5364 - val_loss: 1.1586 - val_acc: 0.5369\n",
      "Epoch 304/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1623 - acc: 0.5336 - val_loss: 1.1678 - val_acc: 0.5401\n",
      "Epoch 305/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1682 - acc: 0.5305 - val_loss: 1.1511 - val_acc: 0.5447\n",
      "Epoch 306/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1603 - acc: 0.5352 - val_loss: 1.1605 - val_acc: 0.5386\n",
      "Epoch 307/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1609 - acc: 0.5318 - val_loss: 1.1686 - val_acc: 0.5352\n",
      "Epoch 308/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.1553 - acc: 0.5371 - val_loss: 1.1574 - val_acc: 0.5410\n",
      "Epoch 309/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.1586 - acc: 0.5317 - val_loss: 1.1496 - val_acc: 0.5363\n",
      "Epoch 310/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1558 - acc: 0.5343 - val_loss: 1.1415 - val_acc: 0.5442\n",
      "Epoch 311/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1589 - acc: 0.5330 - val_loss: 1.1497 - val_acc: 0.5357\n",
      "Epoch 312/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1572 - acc: 0.5339 - val_loss: 1.1589 - val_acc: 0.5421\n",
      "Epoch 313/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1579 - acc: 0.5320 - val_loss: 1.1474 - val_acc: 0.5442\n",
      "Epoch 314/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1535 - acc: 0.5356 - val_loss: 1.1675 - val_acc: 0.5427\n",
      "Epoch 315/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.1578 - acc: 0.5356 - val_loss: 1.1450 - val_acc: 0.5430\n",
      "Epoch 316/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1545 - acc: 0.5331 - val_loss: 1.1402 - val_acc: 0.5482\n",
      "Epoch 317/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1573 - acc: 0.5352 - val_loss: 1.1506 - val_acc: 0.5407\n",
      "Epoch 318/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1575 - acc: 0.5344 - val_loss: 1.1463 - val_acc: 0.5482\n",
      "Epoch 319/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1556 - acc: 0.5344 - val_loss: 1.1557 - val_acc: 0.5383\n",
      "Epoch 320/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1473 - acc: 0.5384 - val_loss: 1.1497 - val_acc: 0.5430\n",
      "Epoch 321/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1551 - acc: 0.5320 - val_loss: 1.1485 - val_acc: 0.5462\n",
      "Epoch 322/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1615 - acc: 0.5323 - val_loss: 1.1604 - val_acc: 0.5410\n",
      "Epoch 323/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1609 - acc: 0.5351 - val_loss: 1.1436 - val_acc: 0.5413\n",
      "Epoch 324/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.1547 - acc: 0.5308 - val_loss: 1.1537 - val_acc: 0.5404\n",
      "Epoch 325/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.1460 - acc: 0.5366 - val_loss: 1.1554 - val_acc: 0.5439\n",
      "Epoch 326/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.1495 - acc: 0.5377 - val_loss: 1.1592 - val_acc: 0.5482\n",
      "Epoch 327/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1489 - acc: 0.5354 - val_loss: 1.1498 - val_acc: 0.5404\n",
      "Epoch 328/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1489 - acc: 0.5402 - val_loss: 1.1472 - val_acc: 0.5482\n",
      "Epoch 329/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1504 - acc: 0.5383 - val_loss: 1.1477 - val_acc: 0.5447\n",
      "Epoch 330/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1499 - acc: 0.5360 - val_loss: 1.1529 - val_acc: 0.5392\n",
      "Epoch 331/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1547 - acc: 0.5344 - val_loss: 1.1427 - val_acc: 0.5436\n",
      "Epoch 332/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1465 - acc: 0.5413 - val_loss: 1.1450 - val_acc: 0.5465\n",
      "Epoch 333/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1455 - acc: 0.5396 - val_loss: 1.1552 - val_acc: 0.5424\n",
      "Epoch 334/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1470 - acc: 0.5381 - val_loss: 1.1599 - val_acc: 0.5410\n",
      "Epoch 335/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1527 - acc: 0.5369 - val_loss: 1.1407 - val_acc: 0.5459\n",
      "Epoch 336/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1477 - acc: 0.5386 - val_loss: 1.1397 - val_acc: 0.5392\n",
      "Epoch 337/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1520 - acc: 0.5361 - val_loss: 1.1412 - val_acc: 0.5433\n",
      "Epoch 338/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.1547 - acc: 0.5338 - val_loss: 1.1524 - val_acc: 0.5459\n",
      "Epoch 339/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1555 - acc: 0.5360 - val_loss: 1.1494 - val_acc: 0.5418\n",
      "Epoch 340/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.1459 - acc: 0.5404 - val_loss: 1.1434 - val_acc: 0.5450\n",
      "Epoch 341/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1417 - acc: 0.5402 - val_loss: 1.1540 - val_acc: 0.5404\n",
      "Epoch 342/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1449 - acc: 0.5367 - val_loss: 1.1517 - val_acc: 0.5445\n",
      "Epoch 343/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1503 - acc: 0.5365 - val_loss: 1.1429 - val_acc: 0.5450\n",
      "Epoch 344/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1451 - acc: 0.5391 - val_loss: 1.1454 - val_acc: 0.5418\n",
      "Epoch 345/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1445 - acc: 0.5355 - val_loss: 1.1666 - val_acc: 0.5331\n",
      "Epoch 346/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.1509 - acc: 0.5368 - val_loss: 1.1430 - val_acc: 0.5485\n",
      "Epoch 347/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.1527 - acc: 0.5362 - val_loss: 1.1471 - val_acc: 0.5476\n",
      "Epoch 348/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1426 - acc: 0.5404 - val_loss: 1.1470 - val_acc: 0.5474\n",
      "Epoch 349/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1481 - acc: 0.5376 - val_loss: 1.1430 - val_acc: 0.5471\n",
      "Epoch 350/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1511 - acc: 0.5388 - val_loss: 1.1492 - val_acc: 0.5445\n",
      "Epoch 351/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1485 - acc: 0.5384 - val_loss: 1.1466 - val_acc: 0.5456\n",
      "Epoch 352/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1484 - acc: 0.5367 - val_loss: 1.1416 - val_acc: 0.5375\n",
      "Epoch 353/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1386 - acc: 0.5406 - val_loss: 1.1411 - val_acc: 0.5494\n",
      "Epoch 354/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1483 - acc: 0.5368 - val_loss: 1.1422 - val_acc: 0.5404\n",
      "Epoch 355/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1414 - acc: 0.5405 - val_loss: 1.1490 - val_acc: 0.5421\n",
      "Epoch 356/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1481 - acc: 0.5358 - val_loss: 1.1445 - val_acc: 0.5445\n",
      "Epoch 357/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1444 - acc: 0.5415 - val_loss: 1.1614 - val_acc: 0.5383\n",
      "Epoch 358/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1458 - acc: 0.5377 - val_loss: 1.1383 - val_acc: 0.5508\n",
      "Epoch 359/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1434 - acc: 0.5406 - val_loss: 1.1526 - val_acc: 0.5386\n",
      "Epoch 360/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1482 - acc: 0.5344 - val_loss: 1.1471 - val_acc: 0.5471\n",
      "Epoch 361/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.1472 - acc: 0.5370 - val_loss: 1.1395 - val_acc: 0.5503\n",
      "Epoch 362/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.1467 - acc: 0.5384 - val_loss: 1.1369 - val_acc: 0.5471\n",
      "Epoch 363/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1424 - acc: 0.5416 - val_loss: 1.1429 - val_acc: 0.5427\n",
      "Epoch 364/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1385 - acc: 0.5370 - val_loss: 1.1395 - val_acc: 0.5462\n",
      "Epoch 365/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1345 - acc: 0.5421 - val_loss: 1.1616 - val_acc: 0.5450\n",
      "Epoch 366/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1434 - acc: 0.5393 - val_loss: 1.1404 - val_acc: 0.5494\n",
      "Epoch 367/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1385 - acc: 0.5423 - val_loss: 1.1457 - val_acc: 0.5476\n",
      "Epoch 368/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1416 - acc: 0.5405 - val_loss: 1.1543 - val_acc: 0.5392\n",
      "Epoch 369/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1424 - acc: 0.5380 - val_loss: 1.1405 - val_acc: 0.5476\n",
      "Epoch 370/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1436 - acc: 0.5410 - val_loss: 1.1386 - val_acc: 0.5436\n",
      "Epoch 371/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1422 - acc: 0.5420 - val_loss: 1.1436 - val_acc: 0.5456\n",
      "Epoch 372/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1422 - acc: 0.5400 - val_loss: 1.1362 - val_acc: 0.5506\n",
      "Epoch 373/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1439 - acc: 0.5391 - val_loss: 1.1379 - val_acc: 0.5462\n",
      "Epoch 374/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1370 - acc: 0.5437 - val_loss: 1.1525 - val_acc: 0.5430\n",
      "Epoch 375/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1448 - acc: 0.5398 - val_loss: 1.1415 - val_acc: 0.5456\n",
      "Epoch 376/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.1400 - acc: 0.5437 - val_loss: 1.1485 - val_acc: 0.5424\n",
      "Epoch 377/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 1.1357 - acc: 0.5419 - val_loss: 1.1617 - val_acc: 0.5354\n",
      "Epoch 378/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1384 - acc: 0.5431 - val_loss: 1.1356 - val_acc: 0.5526\n",
      "Epoch 379/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1401 - acc: 0.5410 - val_loss: 1.1444 - val_acc: 0.5482\n",
      "Epoch 380/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1339 - acc: 0.5424 - val_loss: 1.1390 - val_acc: 0.5468\n",
      "Epoch 381/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1431 - acc: 0.5384 - val_loss: 1.1409 - val_acc: 0.5410\n",
      "Epoch 382/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1397 - acc: 0.5419 - val_loss: 1.1310 - val_acc: 0.5520\n",
      "Epoch 383/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1350 - acc: 0.5419 - val_loss: 1.1370 - val_acc: 0.5465\n",
      "Epoch 384/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1356 - acc: 0.5414 - val_loss: 1.1263 - val_acc: 0.5604\n",
      "Epoch 385/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1435 - acc: 0.5423 - val_loss: 1.1494 - val_acc: 0.5357\n",
      "Epoch 386/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1334 - acc: 0.5413 - val_loss: 1.1484 - val_acc: 0.5401\n",
      "Epoch 387/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1331 - acc: 0.5462 - val_loss: 1.1412 - val_acc: 0.5442\n",
      "Epoch 388/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1388 - acc: 0.5402 - val_loss: 1.1536 - val_acc: 0.5413\n",
      "Epoch 389/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1384 - acc: 0.5392 - val_loss: 1.1404 - val_acc: 0.5491\n",
      "Epoch 390/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1303 - acc: 0.5429 - val_loss: 1.1362 - val_acc: 0.5418\n",
      "Epoch 391/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1346 - acc: 0.5431 - val_loss: 1.1481 - val_acc: 0.5465\n",
      "Epoch 392/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1382 - acc: 0.5413 - val_loss: 1.1242 - val_acc: 0.5543\n",
      "Epoch 393/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1283 - acc: 0.5447 - val_loss: 1.1409 - val_acc: 0.5482\n",
      "Epoch 394/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1358 - acc: 0.5399 - val_loss: 1.1363 - val_acc: 0.5506\n",
      "Epoch 395/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1411 - acc: 0.5402 - val_loss: 1.1327 - val_acc: 0.5535\n",
      "Epoch 396/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1337 - acc: 0.5408 - val_loss: 1.1411 - val_acc: 0.5503\n",
      "Epoch 397/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1298 - acc: 0.5439 - val_loss: 1.1365 - val_acc: 0.5546\n",
      "Epoch 398/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1332 - acc: 0.5436 - val_loss: 1.1469 - val_acc: 0.5474\n",
      "Epoch 399/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1392 - acc: 0.5408 - val_loss: 1.1370 - val_acc: 0.5520\n",
      "Epoch 400/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1361 - acc: 0.5413 - val_loss: 1.1469 - val_acc: 0.5383\n",
      "Epoch 401/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1235 - acc: 0.5482 - val_loss: 1.1337 - val_acc: 0.5506\n",
      "Epoch 402/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1278 - acc: 0.5439 - val_loss: 1.1371 - val_acc: 0.5517\n",
      "Epoch 403/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1379 - acc: 0.5397 - val_loss: 1.1360 - val_acc: 0.5549\n",
      "Epoch 404/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1288 - acc: 0.5432 - val_loss: 1.1359 - val_acc: 0.5567\n",
      "Epoch 405/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1345 - acc: 0.5387 - val_loss: 1.1432 - val_acc: 0.5479\n",
      "Epoch 406/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1365 - acc: 0.5398 - val_loss: 1.1346 - val_acc: 0.5526\n",
      "Epoch 407/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1341 - acc: 0.5419 - val_loss: 1.1371 - val_acc: 0.5456\n",
      "Epoch 408/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1372 - acc: 0.5428 - val_loss: 1.1483 - val_acc: 0.5439\n",
      "Epoch 409/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1301 - acc: 0.5446 - val_loss: 1.1331 - val_acc: 0.5511\n",
      "Epoch 410/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1301 - acc: 0.5419 - val_loss: 1.1436 - val_acc: 0.5497\n",
      "Epoch 411/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1294 - acc: 0.5412 - val_loss: 1.1346 - val_acc: 0.5474\n",
      "Epoch 412/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1316 - acc: 0.5392 - val_loss: 1.1406 - val_acc: 0.5479\n",
      "Epoch 413/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1280 - acc: 0.5436 - val_loss: 1.1411 - val_acc: 0.5497\n",
      "Epoch 414/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1373 - acc: 0.5398 - val_loss: 1.1391 - val_acc: 0.5535\n",
      "Epoch 415/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1238 - acc: 0.5470 - val_loss: 1.1323 - val_acc: 0.5535\n",
      "Epoch 416/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1299 - acc: 0.5436 - val_loss: 1.1224 - val_acc: 0.5497\n",
      "Epoch 417/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1236 - acc: 0.5462 - val_loss: 1.1333 - val_acc: 0.5523\n",
      "Epoch 418/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1281 - acc: 0.5424 - val_loss: 1.1365 - val_acc: 0.5540\n",
      "Epoch 419/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1327 - acc: 0.5412 - val_loss: 1.1278 - val_acc: 0.5450\n",
      "Epoch 420/3000\n",
      "13766/13766 [==============================] - ETA: 0s - loss: 1.1343 - acc: 0.543 - 1s 41us/step - loss: 1.1314 - acc: 0.5442 - val_loss: 1.1380 - val_acc: 0.5500\n",
      "Epoch 421/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1152 - acc: 0.5465 - val_loss: 1.1183 - val_acc: 0.5581\n",
      "Epoch 422/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1256 - acc: 0.5463 - val_loss: 1.1312 - val_acc: 0.5581\n",
      "Epoch 423/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1290 - acc: 0.5397 - val_loss: 1.1409 - val_acc: 0.5465\n",
      "Epoch 424/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1227 - acc: 0.5437 - val_loss: 1.1453 - val_acc: 0.5436\n",
      "Epoch 425/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1240 - acc: 0.5487 - val_loss: 1.1253 - val_acc: 0.5523\n",
      "Epoch 426/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1209 - acc: 0.5454 - val_loss: 1.1311 - val_acc: 0.5578\n",
      "Epoch 427/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1273 - acc: 0.5434 - val_loss: 1.1273 - val_acc: 0.5503\n",
      "Epoch 428/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1263 - acc: 0.5439 - val_loss: 1.1292 - val_acc: 0.5552\n",
      "Epoch 429/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1196 - acc: 0.5502 - val_loss: 1.1281 - val_acc: 0.5506\n",
      "Epoch 430/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1277 - acc: 0.5408 - val_loss: 1.1320 - val_acc: 0.5552\n",
      "Epoch 431/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1242 - acc: 0.5448 - val_loss: 1.1457 - val_acc: 0.5514\n",
      "Epoch 432/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1292 - acc: 0.5460 - val_loss: 1.1282 - val_acc: 0.5569\n",
      "Epoch 433/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1258 - acc: 0.5451 - val_loss: 1.1305 - val_acc: 0.5514\n",
      "Epoch 434/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1233 - acc: 0.5452 - val_loss: 1.1293 - val_acc: 0.5476\n",
      "Epoch 435/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1304 - acc: 0.5417 - val_loss: 1.1300 - val_acc: 0.5537\n",
      "Epoch 436/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1274 - acc: 0.5447 - val_loss: 1.1226 - val_acc: 0.5491\n",
      "Epoch 437/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1174 - acc: 0.5493 - val_loss: 1.1226 - val_acc: 0.5578\n",
      "Epoch 438/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1227 - acc: 0.5469 - val_loss: 1.1391 - val_acc: 0.5439\n",
      "Epoch 439/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.1293 - acc: 0.5446 - val_loss: 1.1174 - val_acc: 0.5575\n",
      "Epoch 440/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1238 - acc: 0.5458 - val_loss: 1.1263 - val_acc: 0.5523\n",
      "Epoch 441/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1254 - acc: 0.5457 - val_loss: 1.1288 - val_acc: 0.5540\n",
      "Epoch 442/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1226 - acc: 0.5479 - val_loss: 1.1277 - val_acc: 0.5561\n",
      "Epoch 443/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1263 - acc: 0.5462 - val_loss: 1.1219 - val_acc: 0.5540\n",
      "Epoch 444/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1176 - acc: 0.5477 - val_loss: 1.1426 - val_acc: 0.5445\n",
      "Epoch 445/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1167 - acc: 0.5475 - val_loss: 1.1289 - val_acc: 0.5555\n",
      "Epoch 446/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1149 - acc: 0.5519 - val_loss: 1.1142 - val_acc: 0.5584\n",
      "Epoch 447/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1233 - acc: 0.5457 - val_loss: 1.1294 - val_acc: 0.5494\n",
      "Epoch 448/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1197 - acc: 0.5436 - val_loss: 1.1335 - val_acc: 0.5479\n",
      "Epoch 449/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1213 - acc: 0.5458 - val_loss: 1.1381 - val_acc: 0.5482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1286 - acc: 0.5426 - val_loss: 1.1171 - val_acc: 0.5552\n",
      "Epoch 451/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1251 - acc: 0.5412 - val_loss: 1.1164 - val_acc: 0.5578\n",
      "Epoch 452/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1188 - acc: 0.5475 - val_loss: 1.1217 - val_acc: 0.5523\n",
      "Epoch 453/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1187 - acc: 0.5469 - val_loss: 1.1098 - val_acc: 0.5590\n",
      "Epoch 454/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1197 - acc: 0.5445 - val_loss: 1.1336 - val_acc: 0.5535\n",
      "Epoch 455/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1212 - acc: 0.5451 - val_loss: 1.1314 - val_acc: 0.5500\n",
      "Epoch 456/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1210 - acc: 0.5452 - val_loss: 1.1242 - val_acc: 0.5572\n",
      "Epoch 457/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1279 - acc: 0.5431 - val_loss: 1.1198 - val_acc: 0.5567\n",
      "Epoch 458/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1234 - acc: 0.5486 - val_loss: 1.1328 - val_acc: 0.5523\n",
      "Epoch 459/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1111 - acc: 0.5487 - val_loss: 1.1303 - val_acc: 0.5476\n",
      "Epoch 460/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1228 - acc: 0.5509 - val_loss: 1.1100 - val_acc: 0.5514\n",
      "Epoch 461/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1197 - acc: 0.5466 - val_loss: 1.1150 - val_acc: 0.5578\n",
      "Epoch 462/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1150 - acc: 0.5490 - val_loss: 1.1183 - val_acc: 0.5674\n",
      "Epoch 463/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1129 - acc: 0.5511 - val_loss: 1.1245 - val_acc: 0.5543\n",
      "Epoch 464/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1238 - acc: 0.5489 - val_loss: 1.1251 - val_acc: 0.5555\n",
      "Epoch 465/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1156 - acc: 0.5496 - val_loss: 1.1343 - val_acc: 0.5543\n",
      "Epoch 466/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1171 - acc: 0.5460 - val_loss: 1.1253 - val_acc: 0.5558\n",
      "Epoch 467/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1182 - acc: 0.5479 - val_loss: 1.1179 - val_acc: 0.5546\n",
      "Epoch 468/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1184 - acc: 0.5503 - val_loss: 1.1235 - val_acc: 0.5491\n",
      "Epoch 469/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1126 - acc: 0.5447 - val_loss: 1.1316 - val_acc: 0.5479\n",
      "Epoch 470/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1246 - acc: 0.5466 - val_loss: 1.1191 - val_acc: 0.5561\n",
      "Epoch 471/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1211 - acc: 0.5507 - val_loss: 1.1181 - val_acc: 0.5511\n",
      "Epoch 472/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1147 - acc: 0.5471 - val_loss: 1.1198 - val_acc: 0.5529\n",
      "Epoch 473/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1212 - acc: 0.5472 - val_loss: 1.1185 - val_acc: 0.5520\n",
      "Epoch 474/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1062 - acc: 0.5504 - val_loss: 1.1102 - val_acc: 0.5561\n",
      "Epoch 475/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1184 - acc: 0.5465 - val_loss: 1.1227 - val_acc: 0.5535\n",
      "Epoch 476/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1100 - acc: 0.5486 - val_loss: 1.1241 - val_acc: 0.5549\n",
      "Epoch 477/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1169 - acc: 0.5478 - val_loss: 1.1170 - val_acc: 0.5537\n",
      "Epoch 478/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.1152 - acc: 0.5511 - val_loss: 1.1228 - val_acc: 0.5543\n",
      "Epoch 479/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1163 - acc: 0.5485 - val_loss: 1.1258 - val_acc: 0.5601\n",
      "Epoch 480/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1197 - acc: 0.5481 - val_loss: 1.1375 - val_acc: 0.5508\n",
      "Epoch 481/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.1228 - acc: 0.5508 - val_loss: 1.1138 - val_acc: 0.5558\n",
      "Epoch 482/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1176 - acc: 0.5484 - val_loss: 1.1211 - val_acc: 0.5578\n",
      "Epoch 483/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1165 - acc: 0.5467 - val_loss: 1.1248 - val_acc: 0.5529\n",
      "Epoch 484/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1171 - acc: 0.5487 - val_loss: 1.1131 - val_acc: 0.5535\n",
      "Epoch 485/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.1144 - acc: 0.5492 - val_loss: 1.1277 - val_acc: 0.5552\n",
      "Epoch 486/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1099 - acc: 0.5505 - val_loss: 1.1092 - val_acc: 0.5587\n",
      "Epoch 487/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.1122 - acc: 0.5513 - val_loss: 1.1168 - val_acc: 0.5636\n",
      "Epoch 488/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1073 - acc: 0.5505 - val_loss: 1.1109 - val_acc: 0.5601\n",
      "Epoch 489/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1126 - acc: 0.5511 - val_loss: 1.1225 - val_acc: 0.5564\n",
      "Epoch 490/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1188 - acc: 0.5481 - val_loss: 1.1222 - val_acc: 0.5584\n",
      "Epoch 491/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1164 - acc: 0.5486 - val_loss: 1.1116 - val_acc: 0.5642\n",
      "Epoch 492/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1111 - acc: 0.5535 - val_loss: 1.1068 - val_acc: 0.5625\n",
      "Epoch 493/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1145 - acc: 0.5491 - val_loss: 1.1124 - val_acc: 0.5575\n",
      "Epoch 494/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1109 - acc: 0.5515 - val_loss: 1.1221 - val_acc: 0.5532\n",
      "Epoch 495/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1097 - acc: 0.5528 - val_loss: 1.1136 - val_acc: 0.5569\n",
      "Epoch 496/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1112 - acc: 0.5470 - val_loss: 1.1129 - val_acc: 0.5569\n",
      "Epoch 497/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1114 - acc: 0.5503 - val_loss: 1.1182 - val_acc: 0.5578\n",
      "Epoch 498/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1104 - acc: 0.5495 - val_loss: 1.1258 - val_acc: 0.5506\n",
      "Epoch 499/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1094 - acc: 0.5506 - val_loss: 1.1146 - val_acc: 0.5491\n",
      "Epoch 500/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.1200 - acc: 0.5471 - val_loss: 1.1154 - val_acc: 0.5555\n",
      "Epoch 501/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1168 - acc: 0.5502 - val_loss: 1.1260 - val_acc: 0.5543\n",
      "Epoch 502/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1074 - acc: 0.5516 - val_loss: 1.1088 - val_acc: 0.5567\n",
      "Epoch 503/3000\n",
      "13766/13766 [==============================] - 1s 64us/step - loss: 1.1055 - acc: 0.5507 - val_loss: 1.1174 - val_acc: 0.5564\n",
      "Epoch 504/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1049 - acc: 0.5529 - val_loss: 1.1302 - val_acc: 0.5590\n",
      "Epoch 505/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1114 - acc: 0.5511 - val_loss: 1.1209 - val_acc: 0.5540\n",
      "Epoch 506/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.1045 - acc: 0.5514 - val_loss: 1.1243 - val_acc: 0.5514\n",
      "Epoch 507/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1078 - acc: 0.5552 - val_loss: 1.1232 - val_acc: 0.5526\n",
      "Epoch 508/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.1068 - acc: 0.5545 - val_loss: 1.1137 - val_acc: 0.5561\n",
      "Epoch 509/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1103 - acc: 0.5490 - val_loss: 1.1148 - val_acc: 0.5558\n",
      "Epoch 510/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1041 - acc: 0.5495 - val_loss: 1.1130 - val_acc: 0.5517\n",
      "Epoch 511/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1048 - acc: 0.5497 - val_loss: 1.1124 - val_acc: 0.5581\n",
      "Epoch 512/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1094 - acc: 0.5477 - val_loss: 1.1072 - val_acc: 0.5581\n",
      "Epoch 513/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1063 - acc: 0.5506 - val_loss: 1.1119 - val_acc: 0.5546\n",
      "Epoch 514/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1119 - acc: 0.5519 - val_loss: 1.1208 - val_acc: 0.5552\n",
      "Epoch 515/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1108 - acc: 0.5518 - val_loss: 1.1150 - val_acc: 0.5654\n",
      "Epoch 516/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1170 - acc: 0.5518 - val_loss: 1.1202 - val_acc: 0.5578\n",
      "Epoch 517/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1137 - acc: 0.5501 - val_loss: 1.1105 - val_acc: 0.5555\n",
      "Epoch 518/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1057 - acc: 0.5564 - val_loss: 1.1014 - val_acc: 0.5633\n",
      "Epoch 519/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0980 - acc: 0.5577 - val_loss: 1.1070 - val_acc: 0.5558\n",
      "Epoch 520/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1162 - acc: 0.5513 - val_loss: 1.1223 - val_acc: 0.5540\n",
      "Epoch 521/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1049 - acc: 0.5545 - val_loss: 1.1169 - val_acc: 0.5567\n",
      "Epoch 522/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1010 - acc: 0.5532 - val_loss: 1.1218 - val_acc: 0.5555\n",
      "Epoch 523/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.1027 - acc: 0.5522 - val_loss: 1.1116 - val_acc: 0.5610\n",
      "Epoch 524/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0961 - acc: 0.5540 - val_loss: 1.1036 - val_acc: 0.5645\n",
      "Epoch 525/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1014 - acc: 0.5559 - val_loss: 1.1129 - val_acc: 0.5604\n",
      "Epoch 526/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1078 - acc: 0.5495 - val_loss: 1.1102 - val_acc: 0.5581\n",
      "Epoch 527/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1081 - acc: 0.5522 - val_loss: 1.1187 - val_acc: 0.5552\n",
      "Epoch 528/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1015 - acc: 0.5547 - val_loss: 1.1165 - val_acc: 0.5578\n",
      "Epoch 529/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1081 - acc: 0.5514 - val_loss: 1.1133 - val_acc: 0.5610\n",
      "Epoch 530/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.1008 - acc: 0.5515 - val_loss: 1.1041 - val_acc: 0.5613\n",
      "Epoch 531/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.1160 - acc: 0.5474 - val_loss: 1.1143 - val_acc: 0.5596\n",
      "Epoch 532/3000\n",
      "13766/13766 [==============================] - ETA: 0s - loss: 1.1151 - acc: 0.546 - 1s 41us/step - loss: 1.1098 - acc: 0.5485 - val_loss: 1.1229 - val_acc: 0.5558\n",
      "Epoch 533/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1050 - acc: 0.5510 - val_loss: 1.1139 - val_acc: 0.5668\n",
      "Epoch 534/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1028 - acc: 0.5535 - val_loss: 1.1110 - val_acc: 0.5587\n",
      "Epoch 535/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1036 - acc: 0.5537 - val_loss: 1.1063 - val_acc: 0.5604\n",
      "Epoch 536/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.1001 - acc: 0.5546 - val_loss: 1.1096 - val_acc: 0.5610\n",
      "Epoch 537/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1046 - acc: 0.5568 - val_loss: 1.1146 - val_acc: 0.5636\n",
      "Epoch 538/3000\n",
      "13766/13766 [==============================] - 1s 63us/step - loss: 1.1012 - acc: 0.5507 - val_loss: 1.1148 - val_acc: 0.5616\n",
      "Epoch 539/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.1001 - acc: 0.5554 - val_loss: 1.1172 - val_acc: 0.5569\n",
      "Epoch 540/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1083 - acc: 0.5551 - val_loss: 1.1256 - val_acc: 0.5567\n",
      "Epoch 541/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0993 - acc: 0.5561 - val_loss: 1.1175 - val_acc: 0.5616\n",
      "Epoch 542/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1049 - acc: 0.5527 - val_loss: 1.1201 - val_acc: 0.5572\n",
      "Epoch 543/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1060 - acc: 0.5511 - val_loss: 1.1160 - val_acc: 0.5535\n",
      "Epoch 544/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1015 - acc: 0.5524 - val_loss: 1.1095 - val_acc: 0.5616\n",
      "Epoch 545/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0992 - acc: 0.5572 - val_loss: 1.1124 - val_acc: 0.5651\n",
      "Epoch 546/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0925 - acc: 0.5569 - val_loss: 1.1117 - val_acc: 0.5587\n",
      "Epoch 547/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1072 - acc: 0.5526 - val_loss: 1.1065 - val_acc: 0.5593\n",
      "Epoch 548/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0980 - acc: 0.5524 - val_loss: 1.1148 - val_acc: 0.5569\n",
      "Epoch 549/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0996 - acc: 0.5540 - val_loss: 1.1214 - val_acc: 0.5561\n",
      "Epoch 550/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0924 - acc: 0.5579 - val_loss: 1.1176 - val_acc: 0.5622\n",
      "Epoch 551/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0952 - acc: 0.5551 - val_loss: 1.0996 - val_acc: 0.5639\n",
      "Epoch 552/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1003 - acc: 0.5549 - val_loss: 1.1047 - val_acc: 0.5619\n",
      "Epoch 553/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0992 - acc: 0.5550 - val_loss: 1.1050 - val_acc: 0.5601\n",
      "Epoch 554/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1040 - acc: 0.5539 - val_loss: 1.1185 - val_acc: 0.5552\n",
      "Epoch 555/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1006 - acc: 0.5524 - val_loss: 1.1248 - val_acc: 0.5523\n",
      "Epoch 556/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.1005 - acc: 0.5567 - val_loss: 1.1065 - val_acc: 0.5613\n",
      "Epoch 557/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1050 - acc: 0.5508 - val_loss: 1.1110 - val_acc: 0.5596\n",
      "Epoch 558/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0947 - acc: 0.5528 - val_loss: 1.1062 - val_acc: 0.5607\n",
      "Epoch 559/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0913 - acc: 0.5547 - val_loss: 1.1243 - val_acc: 0.5517\n",
      "Epoch 560/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0872 - acc: 0.5553 - val_loss: 1.1129 - val_acc: 0.5555\n",
      "Epoch 561/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1029 - acc: 0.5553 - val_loss: 1.1229 - val_acc: 0.5546\n",
      "Epoch 562/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1042 - acc: 0.5517 - val_loss: 1.1112 - val_acc: 0.5584\n",
      "Epoch 563/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1003 - acc: 0.5564 - val_loss: 1.1175 - val_acc: 0.5578\n",
      "Epoch 564/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1024 - acc: 0.5516 - val_loss: 1.1098 - val_acc: 0.5619\n",
      "Epoch 565/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0967 - acc: 0.5546 - val_loss: 1.1132 - val_acc: 0.5628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1046 - acc: 0.5555 - val_loss: 1.1180 - val_acc: 0.5543\n",
      "Epoch 567/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1080 - acc: 0.5530 - val_loss: 1.1256 - val_acc: 0.5572\n",
      "Epoch 568/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1038 - acc: 0.5540 - val_loss: 1.1019 - val_acc: 0.5529\n",
      "Epoch 569/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0994 - acc: 0.5508 - val_loss: 1.1097 - val_acc: 0.5581\n",
      "Epoch 570/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0985 - acc: 0.5546 - val_loss: 1.1106 - val_acc: 0.5578\n",
      "Epoch 571/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1015 - acc: 0.5524 - val_loss: 1.1174 - val_acc: 0.5622\n",
      "Epoch 572/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0948 - acc: 0.5540 - val_loss: 1.1080 - val_acc: 0.5596\n",
      "Epoch 573/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.1039 - acc: 0.5541 - val_loss: 1.1172 - val_acc: 0.5537\n",
      "Epoch 574/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1023 - acc: 0.5524 - val_loss: 1.1252 - val_acc: 0.5604\n",
      "Epoch 575/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1027 - acc: 0.5548 - val_loss: 1.1251 - val_acc: 0.5540\n",
      "Epoch 576/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0964 - acc: 0.5548 - val_loss: 1.1120 - val_acc: 0.5628\n",
      "Epoch 577/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0960 - acc: 0.5563 - val_loss: 1.1068 - val_acc: 0.5607\n",
      "Epoch 578/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1073 - acc: 0.5508 - val_loss: 1.1203 - val_acc: 0.5549\n",
      "Epoch 579/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0997 - acc: 0.5554 - val_loss: 1.1099 - val_acc: 0.5723\n",
      "Epoch 580/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0951 - acc: 0.5564 - val_loss: 1.1359 - val_acc: 0.5546\n",
      "Epoch 581/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1066 - acc: 0.5525 - val_loss: 1.1131 - val_acc: 0.5558\n",
      "Epoch 582/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1005 - acc: 0.5559 - val_loss: 1.1110 - val_acc: 0.5590\n",
      "Epoch 583/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0931 - acc: 0.5575 - val_loss: 1.1028 - val_acc: 0.5596\n",
      "Epoch 584/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0970 - acc: 0.5562 - val_loss: 1.1131 - val_acc: 0.5598\n",
      "Epoch 585/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1066 - acc: 0.5538 - val_loss: 1.1021 - val_acc: 0.5648\n",
      "Epoch 586/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0905 - acc: 0.5556 - val_loss: 1.1180 - val_acc: 0.5549\n",
      "Epoch 587/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.1030 - acc: 0.5502 - val_loss: 1.1043 - val_acc: 0.5607\n",
      "Epoch 588/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0895 - acc: 0.5576 - val_loss: 1.1063 - val_acc: 0.5584\n",
      "Epoch 589/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0943 - acc: 0.5590 - val_loss: 1.1136 - val_acc: 0.5613\n",
      "Epoch 590/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.1055 - acc: 0.5522 - val_loss: 1.1028 - val_acc: 0.5604\n",
      "Epoch 591/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0966 - acc: 0.5537 - val_loss: 1.1112 - val_acc: 0.5529\n",
      "Epoch 592/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0962 - acc: 0.5579 - val_loss: 1.1055 - val_acc: 0.5674\n",
      "Epoch 593/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0919 - acc: 0.5579 - val_loss: 1.1070 - val_acc: 0.5610\n",
      "Epoch 594/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0929 - acc: 0.5578 - val_loss: 1.1158 - val_acc: 0.5578\n",
      "Epoch 595/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0919 - acc: 0.5576 - val_loss: 1.1082 - val_acc: 0.5613\n",
      "Epoch 596/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0969 - acc: 0.5557 - val_loss: 1.1076 - val_acc: 0.5642\n",
      "Epoch 597/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0963 - acc: 0.5565 - val_loss: 1.1042 - val_acc: 0.5625\n",
      "Epoch 598/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0854 - acc: 0.5601 - val_loss: 1.1037 - val_acc: 0.5648\n",
      "Epoch 599/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0922 - acc: 0.5530 - val_loss: 1.1164 - val_acc: 0.5610\n",
      "Epoch 600/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0973 - acc: 0.5562 - val_loss: 1.1159 - val_acc: 0.5628\n",
      "Epoch 601/3000\n",
      "13766/13766 [==============================] - 1s 67us/step - loss: 1.0964 - acc: 0.5559 - val_loss: 1.1007 - val_acc: 0.5619\n",
      "Epoch 602/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0915 - acc: 0.5590 - val_loss: 1.1124 - val_acc: 0.5601\n",
      "Epoch 603/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.0976 - acc: 0.5534 - val_loss: 1.1005 - val_acc: 0.5691\n",
      "Epoch 604/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.0946 - acc: 0.5544 - val_loss: 1.1183 - val_acc: 0.5578\n",
      "Epoch 605/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0879 - acc: 0.5572 - val_loss: 1.0954 - val_acc: 0.5561\n",
      "Epoch 606/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0934 - acc: 0.5566 - val_loss: 1.1011 - val_acc: 0.5590\n",
      "Epoch 607/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0965 - acc: 0.5594 - val_loss: 1.1137 - val_acc: 0.5549\n",
      "Epoch 608/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.1013 - acc: 0.5572 - val_loss: 1.1068 - val_acc: 0.5648\n",
      "Epoch 609/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0884 - acc: 0.5594 - val_loss: 1.1011 - val_acc: 0.5598\n",
      "Epoch 610/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0891 - acc: 0.5566 - val_loss: 1.1207 - val_acc: 0.5598\n",
      "Epoch 611/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0938 - acc: 0.5586 - val_loss: 1.0970 - val_acc: 0.5651\n",
      "Epoch 612/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0944 - acc: 0.5556 - val_loss: 1.1106 - val_acc: 0.5555\n",
      "Epoch 613/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0933 - acc: 0.5572 - val_loss: 1.1108 - val_acc: 0.5601\n",
      "Epoch 614/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0908 - acc: 0.5588 - val_loss: 1.1026 - val_acc: 0.5628\n",
      "Epoch 615/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0911 - acc: 0.5607 - val_loss: 1.1349 - val_acc: 0.5549\n",
      "Epoch 616/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0945 - acc: 0.5564 - val_loss: 1.1066 - val_acc: 0.5630\n",
      "Epoch 617/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0963 - acc: 0.5526 - val_loss: 1.1210 - val_acc: 0.5607\n",
      "Epoch 618/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0947 - acc: 0.5557 - val_loss: 1.1135 - val_acc: 0.5561\n",
      "Epoch 619/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0952 - acc: 0.5548 - val_loss: 1.1042 - val_acc: 0.5628\n",
      "Epoch 620/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0872 - acc: 0.5616 - val_loss: 1.1065 - val_acc: 0.5598\n",
      "Epoch 621/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0869 - acc: 0.5618 - val_loss: 1.0965 - val_acc: 0.5628\n",
      "Epoch 622/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0839 - acc: 0.5586 - val_loss: 1.1029 - val_acc: 0.5660\n",
      "Epoch 623/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0977 - acc: 0.5552 - val_loss: 1.1059 - val_acc: 0.5619\n",
      "Epoch 624/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0887 - acc: 0.5564 - val_loss: 1.1136 - val_acc: 0.5633\n",
      "Epoch 625/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0958 - acc: 0.5532 - val_loss: 1.1124 - val_acc: 0.5596\n",
      "Epoch 626/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0932 - acc: 0.5580 - val_loss: 1.1146 - val_acc: 0.5575\n",
      "Epoch 627/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0868 - acc: 0.5577 - val_loss: 1.1068 - val_acc: 0.5628\n",
      "Epoch 628/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0898 - acc: 0.5611 - val_loss: 1.1094 - val_acc: 0.5598\n",
      "Epoch 629/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0923 - acc: 0.5522 - val_loss: 1.1255 - val_acc: 0.5567\n",
      "Epoch 630/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0938 - acc: 0.5556 - val_loss: 1.1044 - val_acc: 0.5616\n",
      "Epoch 631/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0878 - acc: 0.5538 - val_loss: 1.1124 - val_acc: 0.5619\n",
      "Epoch 632/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0886 - acc: 0.5566 - val_loss: 1.1136 - val_acc: 0.5604\n",
      "Epoch 633/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0792 - acc: 0.5676 - val_loss: 1.1060 - val_acc: 0.5628\n",
      "Epoch 634/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0912 - acc: 0.5570 - val_loss: 1.1098 - val_acc: 0.5645\n",
      "Epoch 635/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0901 - acc: 0.5602 - val_loss: 1.1048 - val_acc: 0.5662\n",
      "Epoch 636/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0852 - acc: 0.5586 - val_loss: 1.1156 - val_acc: 0.5622\n",
      "Epoch 637/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0876 - acc: 0.5621 - val_loss: 1.1031 - val_acc: 0.5636\n",
      "Epoch 638/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0954 - acc: 0.5521 - val_loss: 1.1162 - val_acc: 0.5567\n",
      "Epoch 639/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0796 - acc: 0.5646 - val_loss: 1.0970 - val_acc: 0.5654\n",
      "Epoch 640/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0885 - acc: 0.5624 - val_loss: 1.1081 - val_acc: 0.5596\n",
      "Epoch 641/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0862 - acc: 0.5581 - val_loss: 1.1022 - val_acc: 0.5654\n",
      "Epoch 642/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0843 - acc: 0.5601 - val_loss: 1.1011 - val_acc: 0.5674\n",
      "Epoch 643/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0918 - acc: 0.5601 - val_loss: 1.1049 - val_acc: 0.5584\n",
      "Epoch 644/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0913 - acc: 0.5572 - val_loss: 1.1024 - val_acc: 0.5660\n",
      "Epoch 645/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0829 - acc: 0.5623 - val_loss: 1.1120 - val_acc: 0.5590\n",
      "Epoch 646/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0819 - acc: 0.5638 - val_loss: 1.1044 - val_acc: 0.5622\n",
      "Epoch 647/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0927 - acc: 0.5559 - val_loss: 1.1194 - val_acc: 0.5619\n",
      "Epoch 648/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0798 - acc: 0.5620 - val_loss: 1.1092 - val_acc: 0.5633\n",
      "Epoch 649/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0786 - acc: 0.5625 - val_loss: 1.1063 - val_acc: 0.5654\n",
      "Epoch 650/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0853 - acc: 0.5599 - val_loss: 1.1222 - val_acc: 0.5628\n",
      "Epoch 651/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0869 - acc: 0.5570 - val_loss: 1.1063 - val_acc: 0.5665\n",
      "Epoch 652/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0816 - acc: 0.5593 - val_loss: 1.1116 - val_acc: 0.5633\n",
      "Epoch 653/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0805 - acc: 0.5602 - val_loss: 1.1130 - val_acc: 0.5590\n",
      "Epoch 654/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0889 - acc: 0.5592 - val_loss: 1.1066 - val_acc: 0.5610\n",
      "Epoch 655/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0812 - acc: 0.5649 - val_loss: 1.1138 - val_acc: 0.5598\n",
      "Epoch 656/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0803 - acc: 0.5641 - val_loss: 1.1077 - val_acc: 0.5616\n",
      "Epoch 657/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0891 - acc: 0.5591 - val_loss: 1.1061 - val_acc: 0.5593\n",
      "Epoch 658/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0924 - acc: 0.5570 - val_loss: 1.0874 - val_acc: 0.5686\n",
      "Epoch 659/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0949 - acc: 0.5525 - val_loss: 1.1121 - val_acc: 0.5662\n",
      "Epoch 660/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0847 - acc: 0.5609 - val_loss: 1.1069 - val_acc: 0.5630\n",
      "Epoch 661/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0798 - acc: 0.5593 - val_loss: 1.0947 - val_acc: 0.5683\n",
      "Epoch 662/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0800 - acc: 0.5628 - val_loss: 1.1135 - val_acc: 0.5616\n",
      "Epoch 663/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0848 - acc: 0.5605 - val_loss: 1.0933 - val_acc: 0.5662\n",
      "Epoch 664/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0846 - acc: 0.5580 - val_loss: 1.1067 - val_acc: 0.5604\n",
      "Epoch 665/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0807 - acc: 0.5588 - val_loss: 1.1036 - val_acc: 0.5651\n",
      "Epoch 666/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0851 - acc: 0.5636 - val_loss: 1.1058 - val_acc: 0.5581\n",
      "Epoch 667/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0761 - acc: 0.5590 - val_loss: 1.1091 - val_acc: 0.5616\n",
      "Epoch 668/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0793 - acc: 0.5619 - val_loss: 1.0972 - val_acc: 0.5665\n",
      "Epoch 669/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0894 - acc: 0.5650 - val_loss: 1.1077 - val_acc: 0.5628\n",
      "Epoch 670/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0818 - acc: 0.5585 - val_loss: 1.0968 - val_acc: 0.5625\n",
      "Epoch 671/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0875 - acc: 0.5587 - val_loss: 1.1080 - val_acc: 0.5636\n",
      "Epoch 672/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0887 - acc: 0.5591 - val_loss: 1.0927 - val_acc: 0.5654\n",
      "Epoch 673/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0795 - acc: 0.5621 - val_loss: 1.1006 - val_acc: 0.5657\n",
      "Epoch 674/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0775 - acc: 0.5649 - val_loss: 1.1049 - val_acc: 0.5604\n",
      "Epoch 675/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0863 - acc: 0.5620 - val_loss: 1.0931 - val_acc: 0.5665\n",
      "Epoch 676/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0850 - acc: 0.5584 - val_loss: 1.1190 - val_acc: 0.5581\n",
      "Epoch 677/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0805 - acc: 0.5610 - val_loss: 1.1028 - val_acc: 0.5567\n",
      "Epoch 678/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0819 - acc: 0.5619 - val_loss: 1.1019 - val_acc: 0.5642\n",
      "Epoch 679/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0870 - acc: 0.5592 - val_loss: 1.1068 - val_acc: 0.5604\n",
      "Epoch 680/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0794 - acc: 0.5627 - val_loss: 1.0957 - val_acc: 0.5689\n",
      "Epoch 681/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0799 - acc: 0.5633 - val_loss: 1.0953 - val_acc: 0.5686\n",
      "Epoch 682/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0685 - acc: 0.5681 - val_loss: 1.1015 - val_acc: 0.5689\n",
      "Epoch 683/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0830 - acc: 0.5625 - val_loss: 1.1057 - val_acc: 0.5668\n",
      "Epoch 684/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 1.0846 - acc: 0.5627 - val_loss: 1.1129 - val_acc: 0.5642\n",
      "Epoch 685/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0819 - acc: 0.5617 - val_loss: 1.0958 - val_acc: 0.5662\n",
      "Epoch 686/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0817 - acc: 0.5634 - val_loss: 1.0985 - val_acc: 0.5686\n",
      "Epoch 687/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0771 - acc: 0.5631 - val_loss: 1.1031 - val_acc: 0.5691\n",
      "Epoch 688/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0760 - acc: 0.5632 - val_loss: 1.1074 - val_acc: 0.5596\n",
      "Epoch 689/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0852 - acc: 0.5638 - val_loss: 1.0983 - val_acc: 0.5613\n",
      "Epoch 690/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0829 - acc: 0.5637 - val_loss: 1.1059 - val_acc: 0.5660\n",
      "Epoch 691/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0762 - acc: 0.5663 - val_loss: 1.1027 - val_acc: 0.5645\n",
      "Epoch 692/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0854 - acc: 0.5595 - val_loss: 1.1119 - val_acc: 0.5697\n",
      "Epoch 693/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0758 - acc: 0.5657 - val_loss: 1.0987 - val_acc: 0.5645\n",
      "Epoch 694/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0791 - acc: 0.5638 - val_loss: 1.1013 - val_acc: 0.5633\n",
      "Epoch 695/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0822 - acc: 0.5629 - val_loss: 1.1107 - val_acc: 0.5651\n",
      "Epoch 696/3000\n",
      "13766/13766 [==============================] - ETA: 0s - loss: 1.0793 - acc: 0.562 - 1s 42us/step - loss: 1.0795 - acc: 0.5636 - val_loss: 1.1008 - val_acc: 0.5642\n",
      "Epoch 697/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0784 - acc: 0.5614 - val_loss: 1.1080 - val_acc: 0.5633\n",
      "Epoch 698/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0761 - acc: 0.5655 - val_loss: 1.1002 - val_acc: 0.5657\n",
      "Epoch 699/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0804 - acc: 0.5641 - val_loss: 1.1083 - val_acc: 0.5651\n",
      "Epoch 700/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0742 - acc: 0.5640 - val_loss: 1.1048 - val_acc: 0.5703\n",
      "Epoch 701/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0735 - acc: 0.5657 - val_loss: 1.1004 - val_acc: 0.5776\n",
      "Epoch 702/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0764 - acc: 0.5655 - val_loss: 1.0953 - val_acc: 0.5668\n",
      "Epoch 703/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0740 - acc: 0.5629 - val_loss: 1.1086 - val_acc: 0.5654\n",
      "Epoch 704/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0758 - acc: 0.5632 - val_loss: 1.1080 - val_acc: 0.5680\n",
      "Epoch 705/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0761 - acc: 0.5652 - val_loss: 1.1085 - val_acc: 0.5604\n",
      "Epoch 706/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0850 - acc: 0.5591 - val_loss: 1.0924 - val_acc: 0.5691\n",
      "Epoch 707/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0758 - acc: 0.5653 - val_loss: 1.0959 - val_acc: 0.5712\n",
      "Epoch 708/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0855 - acc: 0.5661 - val_loss: 1.1045 - val_acc: 0.5601\n",
      "Epoch 709/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0784 - acc: 0.5673 - val_loss: 1.1051 - val_acc: 0.5660\n",
      "Epoch 710/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0866 - acc: 0.5588 - val_loss: 1.0984 - val_acc: 0.5694\n",
      "Epoch 711/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0906 - acc: 0.5550 - val_loss: 1.0965 - val_acc: 0.5732\n",
      "Epoch 712/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0744 - acc: 0.5649 - val_loss: 1.0900 - val_acc: 0.5697\n",
      "Epoch 713/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0778 - acc: 0.5647 - val_loss: 1.0949 - val_acc: 0.5671\n",
      "Epoch 714/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0662 - acc: 0.5668 - val_loss: 1.1147 - val_acc: 0.5584\n",
      "Epoch 715/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0790 - acc: 0.5619 - val_loss: 1.1213 - val_acc: 0.5590\n",
      "Epoch 716/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0768 - acc: 0.5648 - val_loss: 1.0920 - val_acc: 0.5677\n",
      "Epoch 717/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0878 - acc: 0.5553 - val_loss: 1.1135 - val_acc: 0.5674\n",
      "Epoch 718/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0795 - acc: 0.5642 - val_loss: 1.0925 - val_acc: 0.5625\n",
      "Epoch 719/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0795 - acc: 0.5600 - val_loss: 1.0951 - val_acc: 0.5628\n",
      "Epoch 720/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0843 - acc: 0.5604 - val_loss: 1.1056 - val_acc: 0.5622\n",
      "Epoch 721/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0733 - acc: 0.5610 - val_loss: 1.1072 - val_acc: 0.5674\n",
      "Epoch 722/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0752 - acc: 0.5633 - val_loss: 1.0997 - val_acc: 0.5741\n",
      "Epoch 723/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0747 - acc: 0.5627 - val_loss: 1.0973 - val_acc: 0.5703\n",
      "Epoch 724/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0762 - acc: 0.5608 - val_loss: 1.1014 - val_acc: 0.5683\n",
      "Epoch 725/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0788 - acc: 0.5604 - val_loss: 1.1025 - val_acc: 0.5651\n",
      "Epoch 726/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0743 - acc: 0.5661 - val_loss: 1.1032 - val_acc: 0.5668\n",
      "Epoch 727/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0742 - acc: 0.5628 - val_loss: 1.0967 - val_acc: 0.5657\n",
      "Epoch 728/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0690 - acc: 0.5652 - val_loss: 1.1053 - val_acc: 0.5657\n",
      "Epoch 729/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0789 - acc: 0.5634 - val_loss: 1.0981 - val_acc: 0.5715\n",
      "Epoch 730/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0767 - acc: 0.5661 - val_loss: 1.1078 - val_acc: 0.5619\n",
      "Epoch 731/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0782 - acc: 0.5639 - val_loss: 1.1196 - val_acc: 0.5540\n",
      "Epoch 732/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0771 - acc: 0.5658 - val_loss: 1.1014 - val_acc: 0.5642\n",
      "Epoch 733/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0713 - acc: 0.5651 - val_loss: 1.1022 - val_acc: 0.5622\n",
      "Epoch 734/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0722 - acc: 0.5665 - val_loss: 1.1126 - val_acc: 0.5642\n",
      "Epoch 735/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0761 - acc: 0.5658 - val_loss: 1.0986 - val_acc: 0.5683\n",
      "Epoch 736/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0719 - acc: 0.5601 - val_loss: 1.1154 - val_acc: 0.5660\n",
      "Epoch 737/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0819 - acc: 0.5619 - val_loss: 1.0914 - val_acc: 0.5779\n",
      "Epoch 738/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0792 - acc: 0.5622 - val_loss: 1.1045 - val_acc: 0.5651\n",
      "Epoch 739/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0715 - acc: 0.5663 - val_loss: 1.1018 - val_acc: 0.5613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0734 - acc: 0.5670 - val_loss: 1.0917 - val_acc: 0.5662\n",
      "Epoch 741/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0658 - acc: 0.5667 - val_loss: 1.1014 - val_acc: 0.5639\n",
      "Epoch 742/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0722 - acc: 0.5619 - val_loss: 1.1026 - val_acc: 0.5706\n",
      "Epoch 743/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0758 - acc: 0.5650 - val_loss: 1.1059 - val_acc: 0.5601\n",
      "Epoch 744/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0701 - acc: 0.5694 - val_loss: 1.1029 - val_acc: 0.5694\n",
      "Epoch 745/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0701 - acc: 0.5696 - val_loss: 1.1017 - val_acc: 0.5691\n",
      "Epoch 746/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0671 - acc: 0.5685 - val_loss: 1.0962 - val_acc: 0.5677\n",
      "Epoch 747/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0761 - acc: 0.5649 - val_loss: 1.0946 - val_acc: 0.5718\n",
      "Epoch 748/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0744 - acc: 0.5669 - val_loss: 1.1018 - val_acc: 0.5671\n",
      "Epoch 749/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0604 - acc: 0.5722 - val_loss: 1.0995 - val_acc: 0.5660\n",
      "Epoch 750/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0725 - acc: 0.5645 - val_loss: 1.0976 - val_acc: 0.5700\n",
      "Epoch 751/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0808 - acc: 0.5636 - val_loss: 1.1065 - val_acc: 0.5642\n",
      "Epoch 752/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0713 - acc: 0.5633 - val_loss: 1.0919 - val_acc: 0.5694\n",
      "Epoch 753/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0869 - acc: 0.5633 - val_loss: 1.0953 - val_acc: 0.5709\n",
      "Epoch 754/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0760 - acc: 0.5668 - val_loss: 1.0873 - val_acc: 0.5726\n",
      "Epoch 755/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0755 - acc: 0.5633 - val_loss: 1.0900 - val_acc: 0.5680\n",
      "Epoch 756/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0674 - acc: 0.5669 - val_loss: 1.0922 - val_acc: 0.5680\n",
      "Epoch 757/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0672 - acc: 0.5683 - val_loss: 1.1031 - val_acc: 0.5671\n",
      "Epoch 758/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0774 - acc: 0.5638 - val_loss: 1.0882 - val_acc: 0.5718\n",
      "Epoch 759/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0722 - acc: 0.5675 - val_loss: 1.0847 - val_acc: 0.5697\n",
      "Epoch 760/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0803 - acc: 0.5614 - val_loss: 1.0995 - val_acc: 0.5691\n",
      "Epoch 761/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0706 - acc: 0.5645 - val_loss: 1.0822 - val_acc: 0.5648\n",
      "Epoch 762/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0714 - acc: 0.5659 - val_loss: 1.0921 - val_acc: 0.5700\n",
      "Epoch 763/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0736 - acc: 0.5652 - val_loss: 1.0977 - val_acc: 0.5677\n",
      "Epoch 764/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0712 - acc: 0.5649 - val_loss: 1.1021 - val_acc: 0.5697\n",
      "Epoch 765/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0745 - acc: 0.5678 - val_loss: 1.0967 - val_acc: 0.5689\n",
      "Epoch 766/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0741 - acc: 0.5615 - val_loss: 1.1066 - val_acc: 0.5598\n",
      "Epoch 767/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0667 - acc: 0.5753 - val_loss: 1.0927 - val_acc: 0.5732\n",
      "Epoch 768/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0676 - acc: 0.5664 - val_loss: 1.1031 - val_acc: 0.5622\n",
      "Epoch 769/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0783 - acc: 0.5633 - val_loss: 1.1090 - val_acc: 0.5645\n",
      "Epoch 770/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0649 - acc: 0.5710 - val_loss: 1.0974 - val_acc: 0.5700\n",
      "Epoch 771/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0691 - acc: 0.5684 - val_loss: 1.1007 - val_acc: 0.5628\n",
      "Epoch 772/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0719 - acc: 0.5674 - val_loss: 1.1038 - val_acc: 0.5619\n",
      "Epoch 773/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0678 - acc: 0.5699 - val_loss: 1.0966 - val_acc: 0.5683\n",
      "Epoch 774/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0718 - acc: 0.5645 - val_loss: 1.0876 - val_acc: 0.5706\n",
      "Epoch 775/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0790 - acc: 0.5609 - val_loss: 1.0961 - val_acc: 0.5671\n",
      "Epoch 776/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0710 - acc: 0.5678 - val_loss: 1.0978 - val_acc: 0.5694\n",
      "Epoch 777/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0653 - acc: 0.5726 - val_loss: 1.1027 - val_acc: 0.5674\n",
      "Epoch 778/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0746 - acc: 0.5637 - val_loss: 1.0979 - val_acc: 0.5697\n",
      "Epoch 779/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0693 - acc: 0.5670 - val_loss: 1.1049 - val_acc: 0.5633\n",
      "Epoch 780/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0638 - acc: 0.5706 - val_loss: 1.0865 - val_acc: 0.5662\n",
      "Epoch 781/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0734 - acc: 0.5636 - val_loss: 1.0903 - val_acc: 0.5677\n",
      "Epoch 782/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0689 - acc: 0.5668 - val_loss: 1.0838 - val_acc: 0.5718\n",
      "Epoch 783/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0672 - acc: 0.5721 - val_loss: 1.1002 - val_acc: 0.5651\n",
      "Epoch 784/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0694 - acc: 0.5686 - val_loss: 1.0909 - val_acc: 0.5694\n",
      "Epoch 785/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0640 - acc: 0.5685 - val_loss: 1.0910 - val_acc: 0.5729\n",
      "Epoch 786/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0704 - acc: 0.5657 - val_loss: 1.0894 - val_acc: 0.5622\n",
      "Epoch 787/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0695 - acc: 0.5676 - val_loss: 1.0906 - val_acc: 0.5732\n",
      "Epoch 788/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0655 - acc: 0.5673 - val_loss: 1.0815 - val_acc: 0.5712\n",
      "Epoch 789/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0688 - acc: 0.5649 - val_loss: 1.0926 - val_acc: 0.5732\n",
      "Epoch 790/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0651 - acc: 0.5689 - val_loss: 1.0936 - val_acc: 0.5680\n",
      "Epoch 791/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0647 - acc: 0.5729 - val_loss: 1.0964 - val_acc: 0.5703\n",
      "Epoch 792/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0729 - acc: 0.5671 - val_loss: 1.0890 - val_acc: 0.5674\n",
      "Epoch 793/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0716 - acc: 0.5643 - val_loss: 1.0914 - val_acc: 0.5686\n",
      "Epoch 794/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0767 - acc: 0.5686 - val_loss: 1.1003 - val_acc: 0.5657\n",
      "Epoch 795/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0633 - acc: 0.5673 - val_loss: 1.0992 - val_acc: 0.5718\n",
      "Epoch 796/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0653 - acc: 0.5681 - val_loss: 1.0906 - val_acc: 0.5721\n",
      "Epoch 797/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0637 - acc: 0.5670 - val_loss: 1.1129 - val_acc: 0.5607\n",
      "Epoch 798/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0731 - acc: 0.5696 - val_loss: 1.1056 - val_acc: 0.5619\n",
      "Epoch 799/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0736 - acc: 0.5660 - val_loss: 1.0935 - val_acc: 0.5680\n",
      "Epoch 800/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0703 - acc: 0.5660 - val_loss: 1.0996 - val_acc: 0.5651\n",
      "Epoch 801/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0653 - acc: 0.5692 - val_loss: 1.1086 - val_acc: 0.5686\n",
      "Epoch 802/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0683 - acc: 0.5672 - val_loss: 1.1199 - val_acc: 0.5607\n",
      "Epoch 803/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0574 - acc: 0.5692 - val_loss: 1.0972 - val_acc: 0.5700\n",
      "Epoch 804/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0705 - acc: 0.5729 - val_loss: 1.0941 - val_acc: 0.5718\n",
      "Epoch 805/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0664 - acc: 0.5688 - val_loss: 1.0929 - val_acc: 0.5735\n",
      "Epoch 806/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0645 - acc: 0.5721 - val_loss: 1.0890 - val_acc: 0.5744\n",
      "Epoch 807/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0606 - acc: 0.5729 - val_loss: 1.0865 - val_acc: 0.5694\n",
      "Epoch 808/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0728 - acc: 0.5649 - val_loss: 1.0829 - val_acc: 0.5709\n",
      "Epoch 809/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0705 - acc: 0.5671 - val_loss: 1.0907 - val_acc: 0.5703\n",
      "Epoch 810/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0639 - acc: 0.5684 - val_loss: 1.1065 - val_acc: 0.5613\n",
      "Epoch 811/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0639 - acc: 0.5644 - val_loss: 1.1020 - val_acc: 0.5683\n",
      "Epoch 812/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0695 - acc: 0.5677 - val_loss: 1.0792 - val_acc: 0.5747\n",
      "Epoch 813/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0570 - acc: 0.5673 - val_loss: 1.0949 - val_acc: 0.5715\n",
      "Epoch 814/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0719 - acc: 0.5636 - val_loss: 1.0989 - val_acc: 0.5660\n",
      "Epoch 815/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0584 - acc: 0.5747 - val_loss: 1.0915 - val_acc: 0.5718\n",
      "Epoch 816/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0586 - acc: 0.5723 - val_loss: 1.0968 - val_acc: 0.5744\n",
      "Epoch 817/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0700 - acc: 0.5689 - val_loss: 1.1001 - val_acc: 0.5674\n",
      "Epoch 818/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0655 - acc: 0.5705 - val_loss: 1.1003 - val_acc: 0.5686\n",
      "Epoch 819/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0659 - acc: 0.5676 - val_loss: 1.0962 - val_acc: 0.5718\n",
      "Epoch 820/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0645 - acc: 0.5688 - val_loss: 1.0875 - val_acc: 0.5755\n",
      "Epoch 821/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0696 - acc: 0.5648 - val_loss: 1.0803 - val_acc: 0.5747\n",
      "Epoch 822/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 1.0696 - acc: 0.5663 - val_loss: 1.0911 - val_acc: 0.5721\n",
      "Epoch 823/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0674 - acc: 0.5696 - val_loss: 1.0872 - val_acc: 0.5697\n",
      "Epoch 824/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0622 - acc: 0.5680 - val_loss: 1.0866 - val_acc: 0.5697\n",
      "Epoch 825/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0652 - acc: 0.5673 - val_loss: 1.0921 - val_acc: 0.5723\n",
      "Epoch 826/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0574 - acc: 0.5688 - val_loss: 1.0990 - val_acc: 0.5703\n",
      "Epoch 827/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0655 - acc: 0.5711 - val_loss: 1.0966 - val_acc: 0.5677\n",
      "Epoch 828/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0649 - acc: 0.5686 - val_loss: 1.0755 - val_acc: 0.5715\n",
      "Epoch 829/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0684 - acc: 0.5680 - val_loss: 1.0741 - val_acc: 0.5738\n",
      "Epoch 830/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0576 - acc: 0.5688 - val_loss: 1.0842 - val_acc: 0.5770\n",
      "Epoch 831/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0717 - acc: 0.5644 - val_loss: 1.1059 - val_acc: 0.5689\n",
      "Epoch 832/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0641 - acc: 0.5679 - val_loss: 1.0941 - val_acc: 0.5680\n",
      "Epoch 833/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0605 - acc: 0.5684 - val_loss: 1.0885 - val_acc: 0.5752\n",
      "Epoch 834/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0560 - acc: 0.5708 - val_loss: 1.1172 - val_acc: 0.5694\n",
      "Epoch 835/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0710 - acc: 0.5665 - val_loss: 1.0957 - val_acc: 0.5758\n",
      "Epoch 836/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0610 - acc: 0.5755 - val_loss: 1.1075 - val_acc: 0.5694\n",
      "Epoch 837/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0625 - acc: 0.5721 - val_loss: 1.0973 - val_acc: 0.5671\n",
      "Epoch 838/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0721 - acc: 0.5642 - val_loss: 1.0722 - val_acc: 0.5799\n",
      "Epoch 839/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0701 - acc: 0.5659 - val_loss: 1.0879 - val_acc: 0.5744\n",
      "Epoch 840/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0643 - acc: 0.5725 - val_loss: 1.0904 - val_acc: 0.5686\n",
      "Epoch 841/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0610 - acc: 0.5686 - val_loss: 1.1132 - val_acc: 0.5709\n",
      "Epoch 842/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0649 - acc: 0.5712 - val_loss: 1.0762 - val_acc: 0.5793\n",
      "Epoch 843/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0700 - acc: 0.5636 - val_loss: 1.0916 - val_acc: 0.5776\n",
      "Epoch 844/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0647 - acc: 0.5717 - val_loss: 1.0823 - val_acc: 0.5715\n",
      "Epoch 845/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0608 - acc: 0.5726 - val_loss: 1.0888 - val_acc: 0.5808\n",
      "Epoch 846/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0629 - acc: 0.5702 - val_loss: 1.0907 - val_acc: 0.5770\n",
      "Epoch 847/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0625 - acc: 0.5692 - val_loss: 1.0883 - val_acc: 0.5758\n",
      "Epoch 848/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0559 - acc: 0.5726 - val_loss: 1.0854 - val_acc: 0.5732\n",
      "Epoch 849/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0644 - acc: 0.5656 - val_loss: 1.0920 - val_acc: 0.5689\n",
      "Epoch 850/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0640 - acc: 0.5697 - val_loss: 1.0909 - val_acc: 0.5721\n",
      "Epoch 851/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0603 - acc: 0.5733 - val_loss: 1.0924 - val_acc: 0.5773\n",
      "Epoch 852/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0734 - acc: 0.5660 - val_loss: 1.0875 - val_acc: 0.5654\n",
      "Epoch 853/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0650 - acc: 0.5689 - val_loss: 1.0898 - val_acc: 0.5689\n",
      "Epoch 854/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0720 - acc: 0.5710 - val_loss: 1.0728 - val_acc: 0.5802\n",
      "Epoch 855/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0603 - acc: 0.5700 - val_loss: 1.0836 - val_acc: 0.5689\n",
      "Epoch 856/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0656 - acc: 0.5745 - val_loss: 1.0697 - val_acc: 0.5779\n",
      "Epoch 857/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0667 - acc: 0.5694 - val_loss: 1.0936 - val_acc: 0.5735\n",
      "Epoch 858/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0652 - acc: 0.5724 - val_loss: 1.0793 - val_acc: 0.5741\n",
      "Epoch 859/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0648 - acc: 0.5709 - val_loss: 1.1019 - val_acc: 0.5668\n",
      "Epoch 860/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0651 - acc: 0.5678 - val_loss: 1.0992 - val_acc: 0.5691\n",
      "Epoch 861/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0682 - acc: 0.5705 - val_loss: 1.0927 - val_acc: 0.5686\n",
      "Epoch 862/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0639 - acc: 0.5710 - val_loss: 1.0814 - val_acc: 0.5729\n",
      "Epoch 863/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0580 - acc: 0.5725 - val_loss: 1.0824 - val_acc: 0.5747\n",
      "Epoch 864/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0617 - acc: 0.5698 - val_loss: 1.0855 - val_acc: 0.5750\n",
      "Epoch 865/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0566 - acc: 0.5679 - val_loss: 1.0859 - val_acc: 0.5767\n",
      "Epoch 866/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0537 - acc: 0.5735 - val_loss: 1.1053 - val_acc: 0.5680\n",
      "Epoch 867/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0600 - acc: 0.5729 - val_loss: 1.0992 - val_acc: 0.5668\n",
      "Epoch 868/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0553 - acc: 0.5728 - val_loss: 1.0741 - val_acc: 0.5755\n",
      "Epoch 869/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 1.0611 - acc: 0.5722 - val_loss: 1.0860 - val_acc: 0.5726\n",
      "Epoch 870/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0682 - acc: 0.5688 - val_loss: 1.0880 - val_acc: 0.5764\n",
      "Epoch 871/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0554 - acc: 0.5714 - val_loss: 1.0977 - val_acc: 0.5622\n",
      "Epoch 872/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0813 - acc: 0.5687 - val_loss: 1.0918 - val_acc: 0.5680\n",
      "Epoch 873/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0666 - acc: 0.5693 - val_loss: 1.0815 - val_acc: 0.5782\n",
      "Epoch 874/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0601 - acc: 0.5740 - val_loss: 1.0917 - val_acc: 0.5773\n",
      "Epoch 875/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0560 - acc: 0.5710 - val_loss: 1.0863 - val_acc: 0.5721\n",
      "Epoch 876/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0729 - acc: 0.5660 - val_loss: 1.1011 - val_acc: 0.5721\n",
      "Epoch 877/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0634 - acc: 0.5686 - val_loss: 1.0857 - val_acc: 0.5764\n",
      "Epoch 878/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0588 - acc: 0.5698 - val_loss: 1.0880 - val_acc: 0.5758\n",
      "Epoch 879/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0545 - acc: 0.5795 - val_loss: 1.0922 - val_acc: 0.5767\n",
      "Epoch 880/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0516 - acc: 0.5757 - val_loss: 1.0944 - val_acc: 0.5784\n",
      "Epoch 881/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0507 - acc: 0.5751 - val_loss: 1.0740 - val_acc: 0.5764\n",
      "Epoch 882/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0516 - acc: 0.5750 - val_loss: 1.0793 - val_acc: 0.5741\n",
      "Epoch 883/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0644 - acc: 0.5700 - val_loss: 1.0779 - val_acc: 0.5776\n",
      "Epoch 884/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0579 - acc: 0.5737 - val_loss: 1.0808 - val_acc: 0.5689\n",
      "Epoch 885/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0676 - acc: 0.5708 - val_loss: 1.0803 - val_acc: 0.5674\n",
      "Epoch 886/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0571 - acc: 0.5736 - val_loss: 1.0807 - val_acc: 0.5686\n",
      "Epoch 887/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0551 - acc: 0.5757 - val_loss: 1.0690 - val_acc: 0.5738\n",
      "Epoch 888/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0596 - acc: 0.5752 - val_loss: 1.0924 - val_acc: 0.5715\n",
      "Epoch 889/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0577 - acc: 0.5709 - val_loss: 1.0860 - val_acc: 0.5738\n",
      "Epoch 890/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0642 - acc: 0.5678 - val_loss: 1.0949 - val_acc: 0.5677\n",
      "Epoch 891/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0702 - acc: 0.5653 - val_loss: 1.0871 - val_acc: 0.5813\n",
      "Epoch 892/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0611 - acc: 0.5705 - val_loss: 1.0917 - val_acc: 0.5694\n",
      "Epoch 893/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0598 - acc: 0.5681 - val_loss: 1.0804 - val_acc: 0.5721\n",
      "Epoch 894/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0544 - acc: 0.5777 - val_loss: 1.0824 - val_acc: 0.5755\n",
      "Epoch 895/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0573 - acc: 0.5686 - val_loss: 1.0914 - val_acc: 0.5686\n",
      "Epoch 896/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0571 - acc: 0.5700 - val_loss: 1.0915 - val_acc: 0.5715\n",
      "Epoch 897/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0528 - acc: 0.5749 - val_loss: 1.1073 - val_acc: 0.5633\n",
      "Epoch 898/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0609 - acc: 0.5695 - val_loss: 1.0777 - val_acc: 0.5755\n",
      "Epoch 899/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0536 - acc: 0.5736 - val_loss: 1.0866 - val_acc: 0.5732\n",
      "Epoch 900/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0639 - acc: 0.5683 - val_loss: 1.0894 - val_acc: 0.5773\n",
      "Epoch 901/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0507 - acc: 0.5725 - val_loss: 1.0896 - val_acc: 0.5738\n",
      "Epoch 902/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0497 - acc: 0.5757 - val_loss: 1.0872 - val_acc: 0.5697\n",
      "Epoch 903/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0596 - acc: 0.5741 - val_loss: 1.0805 - val_acc: 0.5796\n",
      "Epoch 904/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.0616 - acc: 0.5668 - val_loss: 1.0856 - val_acc: 0.5723\n",
      "Epoch 905/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 1.0609 - acc: 0.5705 - val_loss: 1.0796 - val_acc: 0.5729\n",
      "Epoch 906/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0510 - acc: 0.5726 - val_loss: 1.0977 - val_acc: 0.5645\n",
      "Epoch 907/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0621 - acc: 0.5706 - val_loss: 1.0918 - val_acc: 0.5767\n",
      "Epoch 908/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0551 - acc: 0.5761 - val_loss: 1.0837 - val_acc: 0.5790\n",
      "Epoch 909/3000\n",
      "13766/13766 [==============================] - 1s 85us/step - loss: 1.0559 - acc: 0.5665 - val_loss: 1.0824 - val_acc: 0.5773\n",
      "Epoch 910/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0593 - acc: 0.5721 - val_loss: 1.0996 - val_acc: 0.5625\n",
      "Epoch 911/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0556 - acc: 0.5747 - val_loss: 1.0894 - val_acc: 0.5747\n",
      "Epoch 912/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0598 - acc: 0.5735 - val_loss: 1.0788 - val_acc: 0.5750\n",
      "Epoch 913/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0533 - acc: 0.5763 - val_loss: 1.0810 - val_acc: 0.5744\n",
      "Epoch 914/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0544 - acc: 0.5734 - val_loss: 1.1056 - val_acc: 0.5741\n",
      "Epoch 915/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0529 - acc: 0.5765 - val_loss: 1.0912 - val_acc: 0.5779\n",
      "Epoch 916/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0571 - acc: 0.5702 - val_loss: 1.1018 - val_acc: 0.5738\n",
      "Epoch 917/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0603 - acc: 0.5733 - val_loss: 1.0873 - val_acc: 0.5732\n",
      "Epoch 918/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.0707 - acc: 0.5661 - val_loss: 1.0943 - val_acc: 0.5694\n",
      "Epoch 919/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0546 - acc: 0.5734 - val_loss: 1.0810 - val_acc: 0.5729\n",
      "Epoch 920/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0480 - acc: 0.5793 - val_loss: 1.0944 - val_acc: 0.5732\n",
      "Epoch 921/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0533 - acc: 0.5718 - val_loss: 1.1010 - val_acc: 0.5680\n",
      "Epoch 922/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0532 - acc: 0.5721 - val_loss: 1.0740 - val_acc: 0.5750\n",
      "Epoch 923/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0573 - acc: 0.5742 - val_loss: 1.0836 - val_acc: 0.5706\n",
      "Epoch 924/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0560 - acc: 0.5750 - val_loss: 1.0800 - val_acc: 0.5683\n",
      "Epoch 925/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0530 - acc: 0.5732 - val_loss: 1.0735 - val_acc: 0.5770\n",
      "Epoch 926/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0488 - acc: 0.5785 - val_loss: 1.0919 - val_acc: 0.5726\n",
      "Epoch 927/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0619 - acc: 0.5689 - val_loss: 1.0733 - val_acc: 0.5811\n",
      "Epoch 928/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0555 - acc: 0.5724 - val_loss: 1.0770 - val_acc: 0.5787\n",
      "Epoch 929/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0632 - acc: 0.5709 - val_loss: 1.0945 - val_acc: 0.5703\n",
      "Epoch 930/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0558 - acc: 0.5769 - val_loss: 1.1018 - val_acc: 0.5741\n",
      "Epoch 931/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0587 - acc: 0.5730 - val_loss: 1.0976 - val_acc: 0.5674\n",
      "Epoch 932/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0525 - acc: 0.5761 - val_loss: 1.0918 - val_acc: 0.5723\n",
      "Epoch 933/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0523 - acc: 0.5766 - val_loss: 1.0895 - val_acc: 0.5744\n",
      "Epoch 934/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0596 - acc: 0.5709 - val_loss: 1.0793 - val_acc: 0.5723\n",
      "Epoch 935/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0552 - acc: 0.5729 - val_loss: 1.0979 - val_acc: 0.5709\n",
      "Epoch 936/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0565 - acc: 0.5734 - val_loss: 1.0840 - val_acc: 0.5747\n",
      "Epoch 937/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0543 - acc: 0.5710 - val_loss: 1.0892 - val_acc: 0.5773\n",
      "Epoch 938/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0504 - acc: 0.5799 - val_loss: 1.0981 - val_acc: 0.5723\n",
      "Epoch 939/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0462 - acc: 0.5775 - val_loss: 1.0947 - val_acc: 0.5712\n",
      "Epoch 940/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0544 - acc: 0.5767 - val_loss: 1.0742 - val_acc: 0.5744\n",
      "Epoch 941/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0429 - acc: 0.5782 - val_loss: 1.0915 - val_acc: 0.5665\n",
      "Epoch 942/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0574 - acc: 0.5755 - val_loss: 1.0931 - val_acc: 0.5674\n",
      "Epoch 943/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0487 - acc: 0.5803 - val_loss: 1.0852 - val_acc: 0.5729\n",
      "Epoch 944/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0523 - acc: 0.5719 - val_loss: 1.0902 - val_acc: 0.5747\n",
      "Epoch 945/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0452 - acc: 0.5767 - val_loss: 1.0807 - val_acc: 0.5787\n",
      "Epoch 946/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0602 - acc: 0.5726 - val_loss: 1.0828 - val_acc: 0.5750\n",
      "Epoch 947/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0595 - acc: 0.5712 - val_loss: 1.0874 - val_acc: 0.5764\n",
      "Epoch 948/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0490 - acc: 0.5783 - val_loss: 1.0834 - val_acc: 0.5764\n",
      "Epoch 949/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0563 - acc: 0.5731 - val_loss: 1.0898 - val_acc: 0.5767\n",
      "Epoch 950/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0484 - acc: 0.5755 - val_loss: 1.0741 - val_acc: 0.5819\n",
      "Epoch 951/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0480 - acc: 0.5788 - val_loss: 1.0851 - val_acc: 0.5735\n",
      "Epoch 952/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0524 - acc: 0.5699 - val_loss: 1.0794 - val_acc: 0.5744\n",
      "Epoch 953/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0535 - acc: 0.5761 - val_loss: 1.0819 - val_acc: 0.5703\n",
      "Epoch 954/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0448 - acc: 0.5800 - val_loss: 1.0785 - val_acc: 0.5721\n",
      "Epoch 955/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0459 - acc: 0.5774 - val_loss: 1.0759 - val_acc: 0.5747\n",
      "Epoch 956/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0510 - acc: 0.5742 - val_loss: 1.0794 - val_acc: 0.5706\n",
      "Epoch 957/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0519 - acc: 0.5770 - val_loss: 1.0737 - val_acc: 0.5741\n",
      "Epoch 958/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0561 - acc: 0.5694 - val_loss: 1.0853 - val_acc: 0.5723\n",
      "Epoch 959/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0520 - acc: 0.5766 - val_loss: 1.0687 - val_acc: 0.5738\n",
      "Epoch 960/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0524 - acc: 0.5755 - val_loss: 1.0816 - val_acc: 0.5721\n",
      "Epoch 961/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0539 - acc: 0.5743 - val_loss: 1.0924 - val_acc: 0.5677\n",
      "Epoch 962/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0581 - acc: 0.5717 - val_loss: 1.0896 - val_acc: 0.5776\n",
      "Epoch 963/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0496 - acc: 0.5757 - val_loss: 1.0861 - val_acc: 0.5723\n",
      "Epoch 964/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0543 - acc: 0.5691 - val_loss: 1.0768 - val_acc: 0.5802\n",
      "Epoch 965/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0524 - acc: 0.5764 - val_loss: 1.0755 - val_acc: 0.5764\n",
      "Epoch 966/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0444 - acc: 0.5752 - val_loss: 1.0903 - val_acc: 0.5660\n",
      "Epoch 967/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0524 - acc: 0.5771 - val_loss: 1.0753 - val_acc: 0.5822\n",
      "Epoch 968/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0501 - acc: 0.5798 - val_loss: 1.1035 - val_acc: 0.5604\n",
      "Epoch 969/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0513 - acc: 0.5745 - val_loss: 1.0780 - val_acc: 0.5738\n",
      "Epoch 970/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0436 - acc: 0.5838 - val_loss: 1.0819 - val_acc: 0.5738\n",
      "Epoch 971/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0504 - acc: 0.5737 - val_loss: 1.0740 - val_acc: 0.5860\n",
      "Epoch 972/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0503 - acc: 0.5742 - val_loss: 1.0884 - val_acc: 0.5732\n",
      "Epoch 973/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0476 - acc: 0.5747 - val_loss: 1.0898 - val_acc: 0.5764\n",
      "Epoch 974/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0537 - acc: 0.5794 - val_loss: 1.0730 - val_acc: 0.5805\n",
      "Epoch 975/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0604 - acc: 0.5730 - val_loss: 1.0801 - val_acc: 0.5793\n",
      "Epoch 976/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0539 - acc: 0.5745 - val_loss: 1.0758 - val_acc: 0.5738\n",
      "Epoch 977/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0371 - acc: 0.5838 - val_loss: 1.0854 - val_acc: 0.5831\n",
      "Epoch 978/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0474 - acc: 0.5758 - val_loss: 1.0870 - val_acc: 0.5767\n",
      "Epoch 979/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0554 - acc: 0.5705 - val_loss: 1.0809 - val_acc: 0.5738\n",
      "Epoch 980/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0492 - acc: 0.5780 - val_loss: 1.0656 - val_acc: 0.5837\n",
      "Epoch 981/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0538 - acc: 0.5782 - val_loss: 1.0773 - val_acc: 0.5787\n",
      "Epoch 982/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0504 - acc: 0.5718 - val_loss: 1.0885 - val_acc: 0.5709\n",
      "Epoch 983/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0586 - acc: 0.5740 - val_loss: 1.0851 - val_acc: 0.5825\n",
      "Epoch 984/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0463 - acc: 0.5774 - val_loss: 1.0776 - val_acc: 0.5851\n",
      "Epoch 985/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0454 - acc: 0.5801 - val_loss: 1.0792 - val_acc: 0.5860\n",
      "Epoch 986/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0440 - acc: 0.5767 - val_loss: 1.0719 - val_acc: 0.5779\n",
      "Epoch 987/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0533 - acc: 0.5726 - val_loss: 1.0786 - val_acc: 0.5758\n",
      "Epoch 988/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0485 - acc: 0.5772 - val_loss: 1.0813 - val_acc: 0.5758\n",
      "Epoch 989/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0405 - acc: 0.5822 - val_loss: 1.0761 - val_acc: 0.5764\n",
      "Epoch 990/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0449 - acc: 0.5753 - val_loss: 1.0854 - val_acc: 0.5796\n",
      "Epoch 991/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0462 - acc: 0.5770 - val_loss: 1.0694 - val_acc: 0.5802\n",
      "Epoch 992/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0507 - acc: 0.5740 - val_loss: 1.0755 - val_acc: 0.5799\n",
      "Epoch 993/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0443 - acc: 0.5740 - val_loss: 1.0744 - val_acc: 0.5819\n",
      "Epoch 994/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0460 - acc: 0.5797 - val_loss: 1.0753 - val_acc: 0.5808\n",
      "Epoch 995/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0494 - acc: 0.5744 - val_loss: 1.0719 - val_acc: 0.5767\n",
      "Epoch 996/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0444 - acc: 0.5800 - val_loss: 1.0746 - val_acc: 0.5793\n",
      "Epoch 997/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0516 - acc: 0.5695 - val_loss: 1.0696 - val_acc: 0.5735\n",
      "Epoch 998/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0517 - acc: 0.5761 - val_loss: 1.0948 - val_acc: 0.5770\n",
      "Epoch 999/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0503 - acc: 0.5773 - val_loss: 1.0878 - val_acc: 0.5747\n",
      "Epoch 1000/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0507 - acc: 0.5731 - val_loss: 1.0759 - val_acc: 0.5729\n",
      "Epoch 1001/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0474 - acc: 0.5809 - val_loss: 1.0773 - val_acc: 0.5761\n",
      "Epoch 1002/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0442 - acc: 0.5803 - val_loss: 1.0770 - val_acc: 0.5761\n",
      "Epoch 1003/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0436 - acc: 0.5801 - val_loss: 1.0872 - val_acc: 0.5790\n",
      "Epoch 1004/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0334 - acc: 0.5817 - val_loss: 1.0755 - val_acc: 0.5767\n",
      "Epoch 1005/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0369 - acc: 0.5843 - val_loss: 1.0697 - val_acc: 0.5854\n",
      "Epoch 1006/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0473 - acc: 0.5774 - val_loss: 1.0679 - val_acc: 0.5793\n",
      "Epoch 1007/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0508 - acc: 0.5709 - val_loss: 1.0759 - val_acc: 0.5750\n",
      "Epoch 1008/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0467 - acc: 0.5760 - val_loss: 1.0701 - val_acc: 0.5843\n",
      "Epoch 1009/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0516 - acc: 0.5737 - val_loss: 1.0780 - val_acc: 0.5843\n",
      "Epoch 1010/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0423 - acc: 0.5787 - val_loss: 1.0765 - val_acc: 0.5802\n",
      "Epoch 1011/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0493 - acc: 0.5743 - val_loss: 1.0846 - val_acc: 0.5718\n",
      "Epoch 1012/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0590 - acc: 0.5760 - val_loss: 1.0883 - val_acc: 0.5700\n",
      "Epoch 1013/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0550 - acc: 0.5702 - val_loss: 1.0698 - val_acc: 0.5825\n",
      "Epoch 1014/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0461 - acc: 0.5742 - val_loss: 1.0885 - val_acc: 0.5773\n",
      "Epoch 1015/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0515 - acc: 0.5744 - val_loss: 1.0849 - val_acc: 0.5721\n",
      "Epoch 1016/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0524 - acc: 0.5702 - val_loss: 1.0819 - val_acc: 0.5825\n",
      "Epoch 1017/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0478 - acc: 0.5732 - val_loss: 1.0931 - val_acc: 0.5677\n",
      "Epoch 1018/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0469 - acc: 0.5771 - val_loss: 1.0820 - val_acc: 0.5811\n",
      "Epoch 1019/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0408 - acc: 0.5789 - val_loss: 1.0759 - val_acc: 0.5825\n",
      "Epoch 1020/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0476 - acc: 0.5747 - val_loss: 1.0870 - val_acc: 0.5793\n",
      "Epoch 1021/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0542 - acc: 0.5726 - val_loss: 1.0808 - val_acc: 0.5796\n",
      "Epoch 1022/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0416 - acc: 0.5773 - val_loss: 1.0830 - val_acc: 0.5782\n",
      "Epoch 1023/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0419 - acc: 0.5772 - val_loss: 1.0852 - val_acc: 0.5813\n",
      "Epoch 1024/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0392 - acc: 0.5839 - val_loss: 1.0752 - val_acc: 0.5813\n",
      "Epoch 1025/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0399 - acc: 0.5782 - val_loss: 1.0776 - val_acc: 0.5860\n",
      "Epoch 1026/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0434 - acc: 0.5796 - val_loss: 1.0723 - val_acc: 0.5825\n",
      "Epoch 1027/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0432 - acc: 0.5782 - val_loss: 1.0886 - val_acc: 0.5764\n",
      "Epoch 1028/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0432 - acc: 0.5800 - val_loss: 1.0736 - val_acc: 0.5790\n",
      "Epoch 1029/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0517 - acc: 0.5733 - val_loss: 1.0915 - val_acc: 0.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1030/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0444 - acc: 0.5786 - val_loss: 1.0804 - val_acc: 0.5822\n",
      "Epoch 1031/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0376 - acc: 0.5780 - val_loss: 1.0736 - val_acc: 0.5750\n",
      "Epoch 1032/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0393 - acc: 0.5803 - val_loss: 1.0653 - val_acc: 0.5802\n",
      "Epoch 1033/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0451 - acc: 0.5758 - val_loss: 1.0791 - val_acc: 0.5755\n",
      "Epoch 1034/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0413 - acc: 0.5798 - val_loss: 1.0843 - val_acc: 0.5747\n",
      "Epoch 1035/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0446 - acc: 0.5789 - val_loss: 1.0800 - val_acc: 0.5689\n",
      "Epoch 1036/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0364 - acc: 0.5806 - val_loss: 1.0852 - val_acc: 0.5712\n",
      "Epoch 1037/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0463 - acc: 0.5784 - val_loss: 1.0718 - val_acc: 0.5828\n",
      "Epoch 1038/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0374 - acc: 0.5801 - val_loss: 1.0791 - val_acc: 0.5784\n",
      "Epoch 1039/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0540 - acc: 0.5749 - val_loss: 1.0793 - val_acc: 0.5758\n",
      "Epoch 1040/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0383 - acc: 0.5771 - val_loss: 1.0756 - val_acc: 0.5819\n",
      "Epoch 1041/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0493 - acc: 0.5743 - val_loss: 1.0732 - val_acc: 0.5784\n",
      "Epoch 1042/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0458 - acc: 0.5782 - val_loss: 1.0626 - val_acc: 0.5840\n",
      "Epoch 1043/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0429 - acc: 0.5734 - val_loss: 1.0730 - val_acc: 0.5834\n",
      "Epoch 1044/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0491 - acc: 0.5801 - val_loss: 1.0733 - val_acc: 0.5787\n",
      "Epoch 1045/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0482 - acc: 0.5806 - val_loss: 1.0759 - val_acc: 0.5764\n",
      "Epoch 1046/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0460 - acc: 0.5810 - val_loss: 1.0826 - val_acc: 0.5691\n",
      "Epoch 1047/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0397 - acc: 0.5797 - val_loss: 1.0751 - val_acc: 0.5784\n",
      "Epoch 1048/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0370 - acc: 0.5813 - val_loss: 1.0746 - val_acc: 0.5735\n",
      "Epoch 1049/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0422 - acc: 0.5817 - val_loss: 1.0723 - val_acc: 0.5866\n",
      "Epoch 1050/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0554 - acc: 0.5739 - val_loss: 1.0785 - val_acc: 0.5787\n",
      "Epoch 1051/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0488 - acc: 0.5786 - val_loss: 1.0826 - val_acc: 0.5721\n",
      "Epoch 1052/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0477 - acc: 0.5766 - val_loss: 1.0778 - val_acc: 0.5819\n",
      "Epoch 1053/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0428 - acc: 0.5750 - val_loss: 1.0877 - val_acc: 0.5715\n",
      "Epoch 1054/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0420 - acc: 0.5794 - val_loss: 1.0722 - val_acc: 0.5787\n",
      "Epoch 1055/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0321 - acc: 0.5867 - val_loss: 1.0935 - val_acc: 0.5680\n",
      "Epoch 1056/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0486 - acc: 0.5789 - val_loss: 1.0885 - val_acc: 0.5776\n",
      "Epoch 1057/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0565 - acc: 0.5750 - val_loss: 1.0715 - val_acc: 0.5796\n",
      "Epoch 1058/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0447 - acc: 0.5790 - val_loss: 1.0742 - val_acc: 0.5799\n",
      "Epoch 1059/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0392 - acc: 0.5820 - val_loss: 1.0678 - val_acc: 0.5796\n",
      "Epoch 1060/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0488 - acc: 0.5848 - val_loss: 1.0774 - val_acc: 0.5750\n",
      "Epoch 1061/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0448 - acc: 0.5780 - val_loss: 1.0733 - val_acc: 0.5758\n",
      "Epoch 1062/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0422 - acc: 0.5772 - val_loss: 1.0794 - val_acc: 0.5735\n",
      "Epoch 1063/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0363 - acc: 0.5817 - val_loss: 1.0729 - val_acc: 0.5770\n",
      "Epoch 1064/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0437 - acc: 0.5791 - val_loss: 1.0728 - val_acc: 0.5793\n",
      "Epoch 1065/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0409 - acc: 0.5809 - val_loss: 1.0845 - val_acc: 0.5738\n",
      "Epoch 1066/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0438 - acc: 0.5768 - val_loss: 1.0790 - val_acc: 0.5773\n",
      "Epoch 1067/3000\n",
      "13766/13766 [==============================] - 1s 63us/step - loss: 1.0452 - acc: 0.5785 - val_loss: 1.0621 - val_acc: 0.5819\n",
      "Epoch 1068/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0479 - acc: 0.5788 - val_loss: 1.0997 - val_acc: 0.5700\n",
      "Epoch 1069/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0363 - acc: 0.5822 - val_loss: 1.0853 - val_acc: 0.5767\n",
      "Epoch 1070/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0450 - acc: 0.5763 - val_loss: 1.0633 - val_acc: 0.5863\n",
      "Epoch 1071/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0290 - acc: 0.5836 - val_loss: 1.0710 - val_acc: 0.5805\n",
      "Epoch 1072/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0437 - acc: 0.5771 - val_loss: 1.0716 - val_acc: 0.5819\n",
      "Epoch 1073/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0400 - acc: 0.5800 - val_loss: 1.1020 - val_acc: 0.5680\n",
      "Epoch 1074/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0495 - acc: 0.5740 - val_loss: 1.0746 - val_acc: 0.5813\n",
      "Epoch 1075/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0434 - acc: 0.5785 - val_loss: 1.0713 - val_acc: 0.5773\n",
      "Epoch 1076/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0420 - acc: 0.5783 - val_loss: 1.0636 - val_acc: 0.5811\n",
      "Epoch 1077/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0507 - acc: 0.5771 - val_loss: 1.0689 - val_acc: 0.5764\n",
      "Epoch 1078/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0355 - acc: 0.5820 - val_loss: 1.0742 - val_acc: 0.5790\n",
      "Epoch 1079/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0360 - acc: 0.5830 - val_loss: 1.0734 - val_acc: 0.5747\n",
      "Epoch 1080/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0412 - acc: 0.5748 - val_loss: 1.0764 - val_acc: 0.5825\n",
      "Epoch 1081/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0402 - acc: 0.5801 - val_loss: 1.0823 - val_acc: 0.5738\n",
      "Epoch 1082/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0472 - acc: 0.5763 - val_loss: 1.0728 - val_acc: 0.5793\n",
      "Epoch 1083/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0384 - acc: 0.5840 - val_loss: 1.0727 - val_acc: 0.5840\n",
      "Epoch 1084/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0384 - acc: 0.5824 - val_loss: 1.0706 - val_acc: 0.5799\n",
      "Epoch 1085/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0453 - acc: 0.5788 - val_loss: 1.0739 - val_acc: 0.5802\n",
      "Epoch 1086/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0482 - acc: 0.5780 - val_loss: 1.0826 - val_acc: 0.5755\n",
      "Epoch 1087/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0379 - acc: 0.5813 - val_loss: 1.0820 - val_acc: 0.5770\n",
      "Epoch 1088/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0455 - acc: 0.5776 - val_loss: 1.0741 - val_acc: 0.5782\n",
      "Epoch 1089/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0423 - acc: 0.5800 - val_loss: 1.0898 - val_acc: 0.5691\n",
      "Epoch 1090/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0354 - acc: 0.5830 - val_loss: 1.0686 - val_acc: 0.5813\n",
      "Epoch 1091/3000\n",
      "13766/13766 [==============================] - 1s 62us/step - loss: 1.0475 - acc: 0.5755 - val_loss: 1.0781 - val_acc: 0.5784\n",
      "Epoch 1092/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0478 - acc: 0.5755 - val_loss: 1.0783 - val_acc: 0.5787\n",
      "Epoch 1093/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0497 - acc: 0.5785 - val_loss: 1.0807 - val_acc: 0.5735\n",
      "Epoch 1094/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0418 - acc: 0.5828 - val_loss: 1.0682 - val_acc: 0.5822\n",
      "Epoch 1095/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0386 - acc: 0.5797 - val_loss: 1.0747 - val_acc: 0.5787\n",
      "Epoch 1096/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0418 - acc: 0.5787 - val_loss: 1.0861 - val_acc: 0.5747\n",
      "Epoch 1097/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0499 - acc: 0.5759 - val_loss: 1.0630 - val_acc: 0.5831\n",
      "Epoch 1098/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0408 - acc: 0.5797 - val_loss: 1.0683 - val_acc: 0.5796\n",
      "Epoch 1099/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0364 - acc: 0.5826 - val_loss: 1.0760 - val_acc: 0.5726\n",
      "Epoch 1100/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0398 - acc: 0.5781 - val_loss: 1.0775 - val_acc: 0.5770\n",
      "Epoch 1101/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0440 - acc: 0.5790 - val_loss: 1.0726 - val_acc: 0.5744\n",
      "Epoch 1102/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0445 - acc: 0.5772 - val_loss: 1.0743 - val_acc: 0.5779\n",
      "Epoch 1103/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0355 - acc: 0.5815 - val_loss: 1.0814 - val_acc: 0.5796\n",
      "Epoch 1104/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0317 - acc: 0.5848 - val_loss: 1.0760 - val_acc: 0.5767\n",
      "Epoch 1105/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0453 - acc: 0.5782 - val_loss: 1.0904 - val_acc: 0.5741\n",
      "Epoch 1106/3000\n",
      "13766/13766 [==============================] - ETA: 0s - loss: 1.0427 - acc: 0.579 - 1s 41us/step - loss: 1.0379 - acc: 0.5820 - val_loss: 1.0884 - val_acc: 0.5715\n",
      "Epoch 1107/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0490 - acc: 0.5740 - val_loss: 1.1003 - val_acc: 0.5700\n",
      "Epoch 1108/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0395 - acc: 0.5798 - val_loss: 1.0836 - val_acc: 0.5796\n",
      "Epoch 1109/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0344 - acc: 0.5834 - val_loss: 1.0718 - val_acc: 0.5834\n",
      "Epoch 1110/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0336 - acc: 0.5863 - val_loss: 1.0915 - val_acc: 0.5718\n",
      "Epoch 1111/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0450 - acc: 0.5787 - val_loss: 1.0804 - val_acc: 0.5770\n",
      "Epoch 1112/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0541 - acc: 0.5768 - val_loss: 1.0805 - val_acc: 0.5750\n",
      "Epoch 1113/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0372 - acc: 0.5797 - val_loss: 1.0800 - val_acc: 0.5747\n",
      "Epoch 1114/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0384 - acc: 0.5787 - val_loss: 1.0750 - val_acc: 0.5808\n",
      "Epoch 1115/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0324 - acc: 0.5824 - val_loss: 1.0884 - val_acc: 0.5758\n",
      "Epoch 1116/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0412 - acc: 0.5826 - val_loss: 1.0769 - val_acc: 0.5761\n",
      "Epoch 1117/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0388 - acc: 0.5852 - val_loss: 1.0758 - val_acc: 0.5773\n",
      "Epoch 1118/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0317 - acc: 0.5874 - val_loss: 1.0818 - val_acc: 0.5738\n",
      "Epoch 1119/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0388 - acc: 0.5824 - val_loss: 1.0765 - val_acc: 0.5773\n",
      "Epoch 1120/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0363 - acc: 0.5843 - val_loss: 1.0745 - val_acc: 0.5750\n",
      "Epoch 1121/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0409 - acc: 0.5811 - val_loss: 1.0852 - val_acc: 0.5744\n",
      "Epoch 1122/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0384 - acc: 0.5776 - val_loss: 1.0710 - val_acc: 0.5860\n",
      "Epoch 1123/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0409 - acc: 0.5834 - val_loss: 1.0746 - val_acc: 0.5782\n",
      "Epoch 1124/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0300 - acc: 0.5811 - val_loss: 1.0655 - val_acc: 0.5802\n",
      "Epoch 1125/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0368 - acc: 0.5809 - val_loss: 1.0699 - val_acc: 0.5831\n",
      "Epoch 1126/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0351 - acc: 0.5853 - val_loss: 1.0763 - val_acc: 0.5796\n",
      "Epoch 1127/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0366 - acc: 0.5815 - val_loss: 1.0881 - val_acc: 0.5680\n",
      "Epoch 1128/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0400 - acc: 0.5810 - val_loss: 1.0814 - val_acc: 0.5799\n",
      "Epoch 1129/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0472 - acc: 0.5806 - val_loss: 1.0797 - val_acc: 0.5811\n",
      "Epoch 1130/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0358 - acc: 0.5784 - val_loss: 1.0892 - val_acc: 0.5764\n",
      "Epoch 1131/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0376 - acc: 0.5806 - val_loss: 1.0705 - val_acc: 0.5808\n",
      "Epoch 1132/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0379 - acc: 0.5796 - val_loss: 1.0885 - val_acc: 0.5790\n",
      "Epoch 1133/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0463 - acc: 0.5749 - val_loss: 1.0794 - val_acc: 0.5834\n",
      "Epoch 1134/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0420 - acc: 0.5813 - val_loss: 1.0815 - val_acc: 0.5779\n",
      "Epoch 1135/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0386 - acc: 0.5800 - val_loss: 1.0794 - val_acc: 0.5799\n",
      "Epoch 1136/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0357 - acc: 0.5835 - val_loss: 1.0867 - val_acc: 0.5779\n",
      "Epoch 1137/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0370 - acc: 0.5807 - val_loss: 1.0907 - val_acc: 0.5723\n",
      "Epoch 1138/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0378 - acc: 0.5796 - val_loss: 1.0667 - val_acc: 0.5880\n",
      "Epoch 1139/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0451 - acc: 0.5800 - val_loss: 1.0859 - val_acc: 0.5709\n",
      "Epoch 1140/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0363 - acc: 0.5815 - val_loss: 1.0817 - val_acc: 0.5758\n",
      "Epoch 1141/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0415 - acc: 0.5806 - val_loss: 1.0755 - val_acc: 0.5799\n",
      "Epoch 1142/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0333 - acc: 0.5840 - val_loss: 1.0740 - val_acc: 0.5767\n",
      "Epoch 1143/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0434 - acc: 0.5814 - val_loss: 1.0754 - val_acc: 0.5767\n",
      "Epoch 1144/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0336 - acc: 0.5828 - val_loss: 1.0645 - val_acc: 0.5813\n",
      "Epoch 1145/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0356 - acc: 0.5845 - val_loss: 1.0829 - val_acc: 0.5793\n",
      "Epoch 1146/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0332 - acc: 0.5804 - val_loss: 1.0730 - val_acc: 0.5805\n",
      "Epoch 1147/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0329 - acc: 0.5795 - val_loss: 1.0758 - val_acc: 0.5808\n",
      "Epoch 1148/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0272 - acc: 0.5819 - val_loss: 1.0802 - val_acc: 0.5752\n",
      "Epoch 1149/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0358 - acc: 0.5829 - val_loss: 1.0682 - val_acc: 0.5816\n",
      "Epoch 1150/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0359 - acc: 0.5827 - val_loss: 1.0870 - val_acc: 0.5744\n",
      "Epoch 1151/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0440 - acc: 0.5797 - val_loss: 1.0825 - val_acc: 0.5691\n",
      "Epoch 1152/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0407 - acc: 0.5814 - val_loss: 1.0659 - val_acc: 0.5825\n",
      "Epoch 1153/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0311 - acc: 0.5843 - val_loss: 1.0752 - val_acc: 0.5787\n",
      "Epoch 1154/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0422 - acc: 0.5806 - val_loss: 1.0864 - val_acc: 0.5808\n",
      "Epoch 1155/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0420 - acc: 0.5808 - val_loss: 1.0732 - val_acc: 0.5877\n",
      "Epoch 1156/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0472 - acc: 0.5803 - val_loss: 1.0739 - val_acc: 0.5837\n",
      "Epoch 1157/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0270 - acc: 0.5847 - val_loss: 1.0738 - val_acc: 0.5718\n",
      "Epoch 1158/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0320 - acc: 0.5848 - val_loss: 1.0911 - val_acc: 0.5709\n",
      "Epoch 1159/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0374 - acc: 0.5774 - val_loss: 1.0698 - val_acc: 0.5770\n",
      "Epoch 1160/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0403 - acc: 0.5805 - val_loss: 1.0648 - val_acc: 0.5921\n",
      "Epoch 1161/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0414 - acc: 0.5811 - val_loss: 1.0816 - val_acc: 0.5811\n",
      "Epoch 1162/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0361 - acc: 0.5860 - val_loss: 1.0807 - val_acc: 0.5735\n",
      "Epoch 1163/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0464 - acc: 0.5777 - val_loss: 1.0832 - val_acc: 0.5726\n",
      "Epoch 1164/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0477 - acc: 0.5761 - val_loss: 1.0809 - val_acc: 0.5811\n",
      "Epoch 1165/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0448 - acc: 0.5831 - val_loss: 1.0769 - val_acc: 0.5787\n",
      "Epoch 1166/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0392 - acc: 0.5849 - val_loss: 1.0849 - val_acc: 0.5721\n",
      "Epoch 1167/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0291 - acc: 0.5847 - val_loss: 1.0627 - val_acc: 0.5834\n",
      "Epoch 1168/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0458 - acc: 0.5806 - val_loss: 1.0658 - val_acc: 0.5877\n",
      "Epoch 1169/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0320 - acc: 0.5838 - val_loss: 1.0729 - val_acc: 0.5761\n",
      "Epoch 1170/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0384 - acc: 0.5847 - val_loss: 1.0757 - val_acc: 0.5813\n",
      "Epoch 1171/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0358 - acc: 0.5802 - val_loss: 1.0650 - val_acc: 0.5869\n",
      "Epoch 1172/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0315 - acc: 0.5806 - val_loss: 1.0597 - val_acc: 0.5822\n",
      "Epoch 1173/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0292 - acc: 0.5831 - val_loss: 1.0637 - val_acc: 0.5863\n",
      "Epoch 1174/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0455 - acc: 0.5846 - val_loss: 1.0722 - val_acc: 0.5802\n",
      "Epoch 1175/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0419 - acc: 0.5789 - val_loss: 1.0721 - val_acc: 0.5782\n",
      "Epoch 1176/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0359 - acc: 0.5790 - val_loss: 1.0778 - val_acc: 0.5773\n",
      "Epoch 1177/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0414 - acc: 0.5825 - val_loss: 1.0791 - val_acc: 0.5741\n",
      "Epoch 1178/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0368 - acc: 0.5826 - val_loss: 1.0585 - val_acc: 0.5860\n",
      "Epoch 1179/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0349 - acc: 0.5800 - val_loss: 1.0717 - val_acc: 0.5915\n",
      "Epoch 1180/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0408 - acc: 0.5804 - val_loss: 1.0774 - val_acc: 0.5793\n",
      "Epoch 1181/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0384 - acc: 0.5840 - val_loss: 1.0903 - val_acc: 0.5662\n",
      "Epoch 1182/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0333 - acc: 0.5839 - val_loss: 1.0680 - val_acc: 0.5822\n",
      "Epoch 1183/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0436 - acc: 0.5754 - val_loss: 1.0708 - val_acc: 0.5787\n",
      "Epoch 1184/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0228 - acc: 0.5867 - val_loss: 1.0652 - val_acc: 0.5831\n",
      "Epoch 1185/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0405 - acc: 0.5790 - val_loss: 1.0738 - val_acc: 0.5784\n",
      "Epoch 1186/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0430 - acc: 0.5830 - val_loss: 1.0706 - val_acc: 0.5840\n",
      "Epoch 1187/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0408 - acc: 0.5786 - val_loss: 1.0723 - val_acc: 0.5863\n",
      "Epoch 1188/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0302 - acc: 0.5837 - val_loss: 1.0674 - val_acc: 0.5860\n",
      "Epoch 1189/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0337 - acc: 0.5779 - val_loss: 1.0660 - val_acc: 0.5825\n",
      "Epoch 1190/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0282 - acc: 0.5835 - val_loss: 1.0619 - val_acc: 0.5802\n",
      "Epoch 1191/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0399 - acc: 0.5812 - val_loss: 1.0718 - val_acc: 0.5758\n",
      "Epoch 1192/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0502 - acc: 0.5797 - val_loss: 1.0594 - val_acc: 0.5811\n",
      "Epoch 1193/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0356 - acc: 0.5830 - val_loss: 1.0693 - val_acc: 0.5837\n",
      "Epoch 1194/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0307 - acc: 0.5841 - val_loss: 1.0821 - val_acc: 0.5767\n",
      "Epoch 1195/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0326 - acc: 0.5835 - val_loss: 1.0692 - val_acc: 0.5782\n",
      "Epoch 1196/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0389 - acc: 0.5841 - val_loss: 1.0862 - val_acc: 0.5889\n",
      "Epoch 1197/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0450 - acc: 0.5782 - val_loss: 1.0753 - val_acc: 0.5796\n",
      "Epoch 1198/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0328 - acc: 0.5840 - val_loss: 1.0599 - val_acc: 0.5822\n",
      "Epoch 1199/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0341 - acc: 0.5833 - val_loss: 1.0714 - val_acc: 0.5764\n",
      "Epoch 1200/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0356 - acc: 0.5786 - val_loss: 1.0688 - val_acc: 0.5764\n",
      "Epoch 1201/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0392 - acc: 0.5803 - val_loss: 1.0751 - val_acc: 0.5758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1202/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0419 - acc: 0.5817 - val_loss: 1.0762 - val_acc: 0.5831\n",
      "Epoch 1203/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0334 - acc: 0.5820 - val_loss: 1.0701 - val_acc: 0.5802\n",
      "Epoch 1204/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0415 - acc: 0.5805 - val_loss: 1.0707 - val_acc: 0.5819\n",
      "Epoch 1205/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0366 - acc: 0.5794 - val_loss: 1.0630 - val_acc: 0.5872\n",
      "Epoch 1206/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0358 - acc: 0.5793 - val_loss: 1.0635 - val_acc: 0.5924\n",
      "Epoch 1207/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0217 - acc: 0.5838 - val_loss: 1.0769 - val_acc: 0.5770\n",
      "Epoch 1208/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0436 - acc: 0.5795 - val_loss: 1.0730 - val_acc: 0.5811\n",
      "Epoch 1209/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0342 - acc: 0.5832 - val_loss: 1.0687 - val_acc: 0.5813\n",
      "Epoch 1210/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0350 - acc: 0.5825 - val_loss: 1.0667 - val_acc: 0.5843\n",
      "Epoch 1211/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0306 - acc: 0.5801 - val_loss: 1.0683 - val_acc: 0.5831\n",
      "Epoch 1212/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0297 - acc: 0.5819 - val_loss: 1.0815 - val_acc: 0.5866\n",
      "Epoch 1213/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0345 - acc: 0.5839 - val_loss: 1.0858 - val_acc: 0.5735\n",
      "Epoch 1214/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0401 - acc: 0.5779 - val_loss: 1.0796 - val_acc: 0.5793\n",
      "Epoch 1215/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0282 - acc: 0.5867 - val_loss: 1.0865 - val_acc: 0.5822\n",
      "Epoch 1216/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0326 - acc: 0.5825 - val_loss: 1.0778 - val_acc: 0.5793\n",
      "Epoch 1217/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0370 - acc: 0.5815 - val_loss: 1.0790 - val_acc: 0.5805\n",
      "Epoch 1218/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.0351 - acc: 0.5817 - val_loss: 1.0904 - val_acc: 0.5770\n",
      "Epoch 1219/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0303 - acc: 0.5857 - val_loss: 1.0812 - val_acc: 0.5761\n",
      "Epoch 1220/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0328 - acc: 0.5830 - val_loss: 1.0829 - val_acc: 0.5802\n",
      "Epoch 1221/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0263 - acc: 0.5868 - val_loss: 1.0679 - val_acc: 0.5866\n",
      "Epoch 1222/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0355 - acc: 0.5836 - val_loss: 1.0762 - val_acc: 0.5863\n",
      "Epoch 1223/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 1.0351 - acc: 0.5847 - val_loss: 1.0838 - val_acc: 0.5819\n",
      "Epoch 1224/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0257 - acc: 0.5887 - val_loss: 1.0795 - val_acc: 0.5784\n",
      "Epoch 1225/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0377 - acc: 0.5848 - val_loss: 1.0560 - val_acc: 0.5872\n",
      "Epoch 1226/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0333 - acc: 0.5822 - val_loss: 1.0716 - val_acc: 0.5813\n",
      "Epoch 1227/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0317 - acc: 0.5833 - val_loss: 1.0687 - val_acc: 0.5805\n",
      "Epoch 1228/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0250 - acc: 0.5862 - val_loss: 1.0603 - val_acc: 0.5857\n",
      "Epoch 1229/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0273 - acc: 0.5874 - val_loss: 1.0885 - val_acc: 0.5674\n",
      "Epoch 1230/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0281 - acc: 0.5830 - val_loss: 1.0670 - val_acc: 0.5912\n",
      "Epoch 1231/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0317 - acc: 0.5798 - val_loss: 1.0641 - val_acc: 0.5854\n",
      "Epoch 1232/3000\n",
      "13766/13766 [==============================] - 1s 71us/step - loss: 1.0294 - acc: 0.5880 - val_loss: 1.0703 - val_acc: 0.5770\n",
      "Epoch 1233/3000\n",
      "13766/13766 [==============================] - 1s 72us/step - loss: 1.0395 - acc: 0.5822 - val_loss: 1.0641 - val_acc: 0.5779\n",
      "Epoch 1234/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.0301 - acc: 0.5871 - val_loss: 1.0668 - val_acc: 0.5840\n",
      "Epoch 1235/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0300 - acc: 0.5831 - val_loss: 1.0825 - val_acc: 0.5779\n",
      "Epoch 1236/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0237 - acc: 0.5886 - val_loss: 1.0668 - val_acc: 0.5869\n",
      "Epoch 1237/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0319 - acc: 0.5838 - val_loss: 1.0762 - val_acc: 0.5738\n",
      "Epoch 1238/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.0379 - acc: 0.5828 - val_loss: 1.0754 - val_acc: 0.5750\n",
      "Epoch 1239/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0359 - acc: 0.5873 - val_loss: 1.0884 - val_acc: 0.5776\n",
      "Epoch 1240/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0282 - acc: 0.5852 - val_loss: 1.0647 - val_acc: 0.5851\n",
      "Epoch 1241/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0280 - acc: 0.5813 - val_loss: 1.0648 - val_acc: 0.5866\n",
      "Epoch 1242/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0284 - acc: 0.5854 - val_loss: 1.0760 - val_acc: 0.5782\n",
      "Epoch 1243/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0382 - acc: 0.5820 - val_loss: 1.0813 - val_acc: 0.5718\n",
      "Epoch 1244/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0266 - acc: 0.5856 - val_loss: 1.0755 - val_acc: 0.5843\n",
      "Epoch 1245/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0354 - acc: 0.5832 - val_loss: 1.0777 - val_acc: 0.5790\n",
      "Epoch 1246/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0273 - acc: 0.5892 - val_loss: 1.0656 - val_acc: 0.5921\n",
      "Epoch 1247/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0254 - acc: 0.5871 - val_loss: 1.0736 - val_acc: 0.5816\n",
      "Epoch 1248/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0317 - acc: 0.5828 - val_loss: 1.0785 - val_acc: 0.5784\n",
      "Epoch 1249/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0330 - acc: 0.5833 - val_loss: 1.0685 - val_acc: 0.5808\n",
      "Epoch 1250/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0203 - acc: 0.5865 - val_loss: 1.0726 - val_acc: 0.5764\n",
      "Epoch 1251/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0291 - acc: 0.5850 - val_loss: 1.0751 - val_acc: 0.5828\n",
      "Epoch 1252/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0298 - acc: 0.5821 - val_loss: 1.0754 - val_acc: 0.5773\n",
      "Epoch 1253/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0276 - acc: 0.5851 - val_loss: 1.0649 - val_acc: 0.5889\n",
      "Epoch 1254/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0343 - acc: 0.5832 - val_loss: 1.0717 - val_acc: 0.5729\n",
      "Epoch 1255/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0306 - acc: 0.5795 - val_loss: 1.0709 - val_acc: 0.5843\n",
      "Epoch 1256/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0386 - acc: 0.5886 - val_loss: 1.0716 - val_acc: 0.5796\n",
      "Epoch 1257/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0257 - acc: 0.5847 - val_loss: 1.0722 - val_acc: 0.5738\n",
      "Epoch 1258/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0247 - acc: 0.5888 - val_loss: 1.0686 - val_acc: 0.5805\n",
      "Epoch 1259/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0276 - acc: 0.5843 - val_loss: 1.0606 - val_acc: 0.5828\n",
      "Epoch 1260/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0287 - acc: 0.5859 - val_loss: 1.0626 - val_acc: 0.5787\n",
      "Epoch 1261/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0341 - acc: 0.5846 - val_loss: 1.0687 - val_acc: 0.5831\n",
      "Epoch 1262/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0316 - acc: 0.5854 - val_loss: 1.0688 - val_acc: 0.5811\n",
      "Epoch 1263/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0379 - acc: 0.5793 - val_loss: 1.0809 - val_acc: 0.5767\n",
      "Epoch 1264/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0276 - acc: 0.5848 - val_loss: 1.0655 - val_acc: 0.5805\n",
      "Epoch 1265/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0326 - acc: 0.5844 - val_loss: 1.0592 - val_acc: 0.5819\n",
      "Epoch 1266/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0221 - acc: 0.5879 - val_loss: 1.0729 - val_acc: 0.5834\n",
      "Epoch 1267/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0266 - acc: 0.5856 - val_loss: 1.0694 - val_acc: 0.5816\n",
      "Epoch 1268/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0371 - acc: 0.5830 - val_loss: 1.0620 - val_acc: 0.5784\n",
      "Epoch 1269/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0255 - acc: 0.5828 - val_loss: 1.0763 - val_acc: 0.5723\n",
      "Epoch 1270/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0385 - acc: 0.5802 - val_loss: 1.0816 - val_acc: 0.5747\n",
      "Epoch 1271/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0268 - acc: 0.5826 - val_loss: 1.0680 - val_acc: 0.5874\n",
      "Epoch 1272/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0190 - acc: 0.5880 - val_loss: 1.0545 - val_acc: 0.5866\n",
      "Epoch 1273/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0304 - acc: 0.5832 - val_loss: 1.0527 - val_acc: 0.5892\n",
      "Epoch 1274/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0341 - acc: 0.5831 - val_loss: 1.0752 - val_acc: 0.5755\n",
      "Epoch 1275/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0213 - acc: 0.5850 - val_loss: 1.0562 - val_acc: 0.5901\n",
      "Epoch 1276/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.0219 - acc: 0.5899 - val_loss: 1.0847 - val_acc: 0.5747\n",
      "Epoch 1277/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0280 - acc: 0.5838 - val_loss: 1.0773 - val_acc: 0.5793\n",
      "Epoch 1278/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0375 - acc: 0.5844 - val_loss: 1.0678 - val_acc: 0.5860\n",
      "Epoch 1279/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0279 - acc: 0.5863 - val_loss: 1.0868 - val_acc: 0.5787\n",
      "Epoch 1280/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0259 - acc: 0.5871 - val_loss: 1.0748 - val_acc: 0.5816\n",
      "Epoch 1281/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0254 - acc: 0.5889 - val_loss: 1.0738 - val_acc: 0.5790\n",
      "Epoch 1282/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0430 - acc: 0.5791 - val_loss: 1.0846 - val_acc: 0.5773\n",
      "Epoch 1283/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0262 - acc: 0.5848 - val_loss: 1.0721 - val_acc: 0.5834\n",
      "Epoch 1284/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0280 - acc: 0.5827 - val_loss: 1.0736 - val_acc: 0.5863\n",
      "Epoch 1285/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0407 - acc: 0.5827 - val_loss: 1.0570 - val_acc: 0.5851\n",
      "Epoch 1286/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0242 - acc: 0.5871 - val_loss: 1.0611 - val_acc: 0.5843\n",
      "Epoch 1287/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 1.0285 - acc: 0.5899 - val_loss: 1.0532 - val_acc: 0.5901\n",
      "Epoch 1288/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0330 - acc: 0.5848 - val_loss: 1.0711 - val_acc: 0.5799\n",
      "Epoch 1289/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0358 - acc: 0.5827 - val_loss: 1.0704 - val_acc: 0.5808\n",
      "Epoch 1290/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0286 - acc: 0.5848 - val_loss: 1.0623 - val_acc: 0.5837\n",
      "Epoch 1291/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0289 - acc: 0.5875 - val_loss: 1.0718 - val_acc: 0.5802\n",
      "Epoch 1292/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0267 - acc: 0.5832 - val_loss: 1.0677 - val_acc: 0.5773\n",
      "Epoch 1293/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.0196 - acc: 0.5899 - val_loss: 1.0620 - val_acc: 0.5831\n",
      "Epoch 1294/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.0273 - acc: 0.5872 - val_loss: 1.0799 - val_acc: 0.5735\n",
      "Epoch 1295/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0342 - acc: 0.5860 - val_loss: 1.0872 - val_acc: 0.5735\n",
      "Epoch 1296/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.0336 - acc: 0.5827 - val_loss: 1.0629 - val_acc: 0.5831\n",
      "Epoch 1297/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0285 - acc: 0.5836 - val_loss: 1.0759 - val_acc: 0.5779\n",
      "Epoch 1298/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0272 - acc: 0.5842 - val_loss: 1.0742 - val_acc: 0.5784\n",
      "Epoch 1299/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0290 - acc: 0.5819 - val_loss: 1.0719 - val_acc: 0.5735\n",
      "Epoch 1300/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0271 - acc: 0.5897 - val_loss: 1.0818 - val_acc: 0.5671\n",
      "Epoch 1301/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0368 - acc: 0.5811 - val_loss: 1.0535 - val_acc: 0.5851\n",
      "Epoch 1302/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0279 - acc: 0.5867 - val_loss: 1.0542 - val_acc: 0.5828\n",
      "Epoch 1303/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0236 - acc: 0.5871 - val_loss: 1.0662 - val_acc: 0.5811\n",
      "Epoch 1304/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0278 - acc: 0.5841 - val_loss: 1.0625 - val_acc: 0.5863\n",
      "Epoch 1305/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0292 - acc: 0.5846 - val_loss: 1.0612 - val_acc: 0.5854\n",
      "Epoch 1306/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0305 - acc: 0.5851 - val_loss: 1.0618 - val_acc: 0.5843\n",
      "Epoch 1307/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0318 - acc: 0.5835 - val_loss: 1.0660 - val_acc: 0.5790\n",
      "Epoch 1308/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0315 - acc: 0.5842 - val_loss: 1.0740 - val_acc: 0.5822\n",
      "Epoch 1309/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0259 - acc: 0.5840 - val_loss: 1.0579 - val_acc: 0.5860\n",
      "Epoch 1310/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0221 - acc: 0.5925 - val_loss: 1.0619 - val_acc: 0.5822\n",
      "Epoch 1311/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0236 - acc: 0.5872 - val_loss: 1.0701 - val_acc: 0.5799\n",
      "Epoch 1312/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0386 - acc: 0.5848 - val_loss: 1.0651 - val_acc: 0.5782\n",
      "Epoch 1313/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0175 - acc: 0.5928 - val_loss: 1.0775 - val_acc: 0.5787\n",
      "Epoch 1314/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0260 - acc: 0.5892 - val_loss: 1.0526 - val_acc: 0.5860\n",
      "Epoch 1315/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0328 - acc: 0.5844 - val_loss: 1.0653 - val_acc: 0.5793\n",
      "Epoch 1316/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0269 - acc: 0.5872 - val_loss: 1.0720 - val_acc: 0.5802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1317/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0322 - acc: 0.5883 - val_loss: 1.0584 - val_acc: 0.5866\n",
      "Epoch 1318/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0177 - acc: 0.5911 - val_loss: 1.0571 - val_acc: 0.5854\n",
      "Epoch 1319/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0222 - acc: 0.5927 - val_loss: 1.0638 - val_acc: 0.5863\n",
      "Epoch 1320/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0236 - acc: 0.5892 - val_loss: 1.0785 - val_acc: 0.5721\n",
      "Epoch 1321/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0246 - acc: 0.5872 - val_loss: 1.0653 - val_acc: 0.5848\n",
      "Epoch 1322/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0269 - acc: 0.5884 - val_loss: 1.0636 - val_acc: 0.5787\n",
      "Epoch 1323/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0273 - acc: 0.5848 - val_loss: 1.0536 - val_acc: 0.5892\n",
      "Epoch 1324/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0281 - acc: 0.5863 - val_loss: 1.0706 - val_acc: 0.5779\n",
      "Epoch 1325/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0302 - acc: 0.5856 - val_loss: 1.0565 - val_acc: 0.5834\n",
      "Epoch 1326/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0280 - acc: 0.5847 - val_loss: 1.0600 - val_acc: 0.5889\n",
      "Epoch 1327/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0304 - acc: 0.5846 - val_loss: 1.0644 - val_acc: 0.5828\n",
      "Epoch 1328/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0309 - acc: 0.5863 - val_loss: 1.0938 - val_acc: 0.5782\n",
      "Epoch 1329/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0257 - acc: 0.5846 - val_loss: 1.0624 - val_acc: 0.5851\n",
      "Epoch 1330/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0288 - acc: 0.5851 - val_loss: 1.0690 - val_acc: 0.5843\n",
      "Epoch 1331/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0250 - acc: 0.5866 - val_loss: 1.0642 - val_acc: 0.5813\n",
      "Epoch 1332/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0352 - acc: 0.5832 - val_loss: 1.0644 - val_acc: 0.5796\n",
      "Epoch 1333/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0211 - acc: 0.5883 - val_loss: 1.0536 - val_acc: 0.5874\n",
      "Epoch 1334/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0220 - acc: 0.5894 - val_loss: 1.0702 - val_acc: 0.5770\n",
      "Epoch 1335/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0244 - acc: 0.5899 - val_loss: 1.0796 - val_acc: 0.5790\n",
      "Epoch 1336/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0218 - acc: 0.5878 - val_loss: 1.0588 - val_acc: 0.5860\n",
      "Epoch 1337/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0254 - acc: 0.5873 - val_loss: 1.0610 - val_acc: 0.5924\n",
      "Epoch 1338/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0273 - acc: 0.5854 - val_loss: 1.0621 - val_acc: 0.5822\n",
      "Epoch 1339/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0231 - acc: 0.5893 - val_loss: 1.0752 - val_acc: 0.5892\n",
      "Epoch 1340/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0275 - acc: 0.5885 - val_loss: 1.0647 - val_acc: 0.5857\n",
      "Epoch 1341/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0261 - acc: 0.5848 - val_loss: 1.0593 - val_acc: 0.5898\n",
      "Epoch 1342/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0276 - acc: 0.5904 - val_loss: 1.0688 - val_acc: 0.5805\n",
      "Epoch 1343/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0283 - acc: 0.5838 - val_loss: 1.0764 - val_acc: 0.5860\n",
      "Epoch 1344/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0313 - acc: 0.5857 - val_loss: 1.0630 - val_acc: 0.5860\n",
      "Epoch 1345/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0264 - acc: 0.5862 - val_loss: 1.0579 - val_acc: 0.5799\n",
      "Epoch 1346/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0274 - acc: 0.5856 - val_loss: 1.0474 - val_acc: 0.5851\n",
      "Epoch 1347/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0225 - acc: 0.5876 - val_loss: 1.0595 - val_acc: 0.5851\n",
      "Epoch 1348/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0256 - acc: 0.5838 - val_loss: 1.0711 - val_acc: 0.5851\n",
      "Epoch 1349/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0275 - acc: 0.5896 - val_loss: 1.0598 - val_acc: 0.5898\n",
      "Epoch 1350/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0176 - acc: 0.5944 - val_loss: 1.0702 - val_acc: 0.5811\n",
      "Epoch 1351/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0193 - acc: 0.5920 - val_loss: 1.0639 - val_acc: 0.5860\n",
      "Epoch 1352/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0247 - acc: 0.5891 - val_loss: 1.0683 - val_acc: 0.5874\n",
      "Epoch 1353/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0242 - acc: 0.5903 - val_loss: 1.0655 - val_acc: 0.5816\n",
      "Epoch 1354/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0269 - acc: 0.5883 - val_loss: 1.0878 - val_acc: 0.5773\n",
      "Epoch 1355/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0290 - acc: 0.5906 - val_loss: 1.0857 - val_acc: 0.5828\n",
      "Epoch 1356/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0203 - acc: 0.5896 - val_loss: 1.0748 - val_acc: 0.5851\n",
      "Epoch 1357/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0252 - acc: 0.5870 - val_loss: 1.0733 - val_acc: 0.5790\n",
      "Epoch 1358/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0246 - acc: 0.5863 - val_loss: 1.0799 - val_acc: 0.5822\n",
      "Epoch 1359/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0185 - acc: 0.5902 - val_loss: 1.0598 - val_acc: 0.5831\n",
      "Epoch 1360/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0264 - acc: 0.5852 - val_loss: 1.0570 - val_acc: 0.5880\n",
      "Epoch 1361/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0201 - acc: 0.5851 - val_loss: 1.0652 - val_acc: 0.5869\n",
      "Epoch 1362/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0171 - acc: 0.5877 - val_loss: 1.0523 - val_acc: 0.5869\n",
      "Epoch 1363/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0159 - acc: 0.5892 - val_loss: 1.0631 - val_acc: 0.5831\n",
      "Epoch 1364/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0144 - acc: 0.5902 - val_loss: 1.0684 - val_acc: 0.5796\n",
      "Epoch 1365/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0204 - acc: 0.5917 - val_loss: 1.0739 - val_acc: 0.5869\n",
      "Epoch 1366/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0265 - acc: 0.5888 - val_loss: 1.0680 - val_acc: 0.5811\n",
      "Epoch 1367/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0217 - acc: 0.5867 - val_loss: 1.0660 - val_acc: 0.5854\n",
      "Epoch 1368/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0215 - acc: 0.5927 - val_loss: 1.0649 - val_acc: 0.5822\n",
      "Epoch 1369/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0206 - acc: 0.5888 - val_loss: 1.0615 - val_acc: 0.5886\n",
      "Epoch 1370/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0193 - acc: 0.5880 - val_loss: 1.0816 - val_acc: 0.5799\n",
      "Epoch 1371/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0247 - acc: 0.5865 - val_loss: 1.0633 - val_acc: 0.5843\n",
      "Epoch 1372/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0191 - acc: 0.5888 - val_loss: 1.0706 - val_acc: 0.5843\n",
      "Epoch 1373/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0233 - acc: 0.5894 - val_loss: 1.0613 - val_acc: 0.5834\n",
      "Epoch 1374/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0285 - acc: 0.5874 - val_loss: 1.0802 - val_acc: 0.5787\n",
      "Epoch 1375/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0252 - acc: 0.5889 - val_loss: 1.0616 - val_acc: 0.5921\n",
      "Epoch 1376/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0196 - acc: 0.5901 - val_loss: 1.0541 - val_acc: 0.5898\n",
      "Epoch 1377/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0226 - acc: 0.5866 - val_loss: 1.0569 - val_acc: 0.5857\n",
      "Epoch 1378/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0228 - acc: 0.5843 - val_loss: 1.0642 - val_acc: 0.5854\n",
      "Epoch 1379/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0214 - acc: 0.5901 - val_loss: 1.0614 - val_acc: 0.5918\n",
      "Epoch 1380/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0202 - acc: 0.5888 - val_loss: 1.0545 - val_acc: 0.5976\n",
      "Epoch 1381/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0228 - acc: 0.5895 - val_loss: 1.0642 - val_acc: 0.5889\n",
      "Epoch 1382/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0270 - acc: 0.5882 - val_loss: 1.0643 - val_acc: 0.5845\n",
      "Epoch 1383/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0235 - acc: 0.5848 - val_loss: 1.0701 - val_acc: 0.5831\n",
      "Epoch 1384/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0249 - acc: 0.5894 - val_loss: 1.0620 - val_acc: 0.5880\n",
      "Epoch 1385/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0123 - acc: 0.5922 - val_loss: 1.0582 - val_acc: 0.5854\n",
      "Epoch 1386/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0243 - acc: 0.5857 - val_loss: 1.0633 - val_acc: 0.5837\n",
      "Epoch 1387/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0220 - acc: 0.5867 - val_loss: 1.0566 - val_acc: 0.5904\n",
      "Epoch 1388/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0262 - acc: 0.5889 - val_loss: 1.0541 - val_acc: 0.5869\n",
      "Epoch 1389/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0324 - acc: 0.5872 - val_loss: 1.0516 - val_acc: 0.5886\n",
      "Epoch 1390/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0240 - acc: 0.5864 - val_loss: 1.0810 - val_acc: 0.5805\n",
      "Epoch 1391/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0094 - acc: 0.5926 - val_loss: 1.0675 - val_acc: 0.5877\n",
      "Epoch 1392/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0188 - acc: 0.5902 - val_loss: 1.0611 - val_acc: 0.5825\n",
      "Epoch 1393/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0143 - acc: 0.5898 - val_loss: 1.0654 - val_acc: 0.5860\n",
      "Epoch 1394/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0277 - acc: 0.5867 - val_loss: 1.0628 - val_acc: 0.5877\n",
      "Epoch 1395/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0307 - acc: 0.5853 - val_loss: 1.0488 - val_acc: 0.5866\n",
      "Epoch 1396/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0243 - acc: 0.5888 - val_loss: 1.0554 - val_acc: 0.5921\n",
      "Epoch 1397/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0179 - acc: 0.5899 - val_loss: 1.0660 - val_acc: 0.5854\n",
      "Epoch 1398/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0141 - acc: 0.5944 - val_loss: 1.0653 - val_acc: 0.5808\n",
      "Epoch 1399/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0261 - acc: 0.5903 - val_loss: 1.0625 - val_acc: 0.5825\n",
      "Epoch 1400/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0263 - acc: 0.5885 - val_loss: 1.0587 - val_acc: 0.5828\n",
      "Epoch 1401/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0163 - acc: 0.5882 - val_loss: 1.0514 - val_acc: 0.5909\n",
      "Epoch 1402/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0222 - acc: 0.5871 - val_loss: 1.0526 - val_acc: 0.5886\n",
      "Epoch 1403/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0219 - acc: 0.5880 - val_loss: 1.0674 - val_acc: 0.5808\n",
      "Epoch 1404/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0231 - acc: 0.5867 - val_loss: 1.0572 - val_acc: 0.5854\n",
      "Epoch 1405/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0173 - acc: 0.5897 - val_loss: 1.0577 - val_acc: 0.5874\n",
      "Epoch 1406/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0211 - acc: 0.5900 - val_loss: 1.0655 - val_acc: 0.5892\n",
      "Epoch 1407/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0327 - acc: 0.5873 - val_loss: 1.0710 - val_acc: 0.5840\n",
      "Epoch 1408/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0241 - acc: 0.5875 - val_loss: 1.0511 - val_acc: 0.5944\n",
      "Epoch 1409/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0128 - acc: 0.5952 - val_loss: 1.0656 - val_acc: 0.5828\n",
      "Epoch 1410/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0172 - acc: 0.5900 - val_loss: 1.0581 - val_acc: 0.5895\n",
      "Epoch 1411/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0260 - acc: 0.5870 - val_loss: 1.0603 - val_acc: 0.5825\n",
      "Epoch 1412/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0152 - acc: 0.5919 - val_loss: 1.0548 - val_acc: 0.5869\n",
      "Epoch 1413/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0287 - acc: 0.5829 - val_loss: 1.0493 - val_acc: 0.5874\n",
      "Epoch 1414/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0221 - acc: 0.5896 - val_loss: 1.0769 - val_acc: 0.5819\n",
      "Epoch 1415/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0208 - acc: 0.5917 - val_loss: 1.0653 - val_acc: 0.5793\n",
      "Epoch 1416/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0094 - acc: 0.5892 - val_loss: 1.0536 - val_acc: 0.5845\n",
      "Epoch 1417/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0194 - acc: 0.5878 - val_loss: 1.0623 - val_acc: 0.5808\n",
      "Epoch 1418/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0166 - acc: 0.5866 - val_loss: 1.0595 - val_acc: 0.5790\n",
      "Epoch 1419/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0084 - acc: 0.5969 - val_loss: 1.0585 - val_acc: 0.5854\n",
      "Epoch 1420/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0256 - acc: 0.5862 - val_loss: 1.0559 - val_acc: 0.5970\n",
      "Epoch 1421/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0169 - acc: 0.5901 - val_loss: 1.0601 - val_acc: 0.5892\n",
      "Epoch 1422/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0175 - acc: 0.5868 - val_loss: 1.0695 - val_acc: 0.5845\n",
      "Epoch 1423/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0253 - acc: 0.5904 - val_loss: 1.0466 - val_acc: 0.5831\n",
      "Epoch 1424/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0173 - acc: 0.5942 - val_loss: 1.0660 - val_acc: 0.5872\n",
      "Epoch 1425/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0266 - acc: 0.5923 - val_loss: 1.0705 - val_acc: 0.5822\n",
      "Epoch 1426/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0203 - acc: 0.5870 - val_loss: 1.0724 - val_acc: 0.5813\n",
      "Epoch 1427/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0168 - acc: 0.5928 - val_loss: 1.0508 - val_acc: 0.5860\n",
      "Epoch 1428/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0278 - acc: 0.5863 - val_loss: 1.0529 - val_acc: 0.5866\n",
      "Epoch 1429/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0192 - acc: 0.5870 - val_loss: 1.0646 - val_acc: 0.5784\n",
      "Epoch 1430/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0177 - acc: 0.5920 - val_loss: 1.0691 - val_acc: 0.5848\n",
      "Epoch 1431/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0162 - acc: 0.5897 - val_loss: 1.0639 - val_acc: 0.5799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1432/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0275 - acc: 0.5907 - val_loss: 1.0632 - val_acc: 0.5877\n",
      "Epoch 1433/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0176 - acc: 0.5891 - val_loss: 1.0514 - val_acc: 0.5845\n",
      "Epoch 1434/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0162 - acc: 0.5878 - val_loss: 1.0720 - val_acc: 0.5811\n",
      "Epoch 1435/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0241 - acc: 0.5917 - val_loss: 1.0519 - val_acc: 0.5883\n",
      "Epoch 1436/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0170 - acc: 0.5877 - val_loss: 1.0530 - val_acc: 0.5880\n",
      "Epoch 1437/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0194 - acc: 0.5882 - val_loss: 1.0423 - val_acc: 0.5956\n",
      "Epoch 1438/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0213 - acc: 0.5888 - val_loss: 1.0551 - val_acc: 0.5904\n",
      "Epoch 1439/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0259 - acc: 0.5861 - val_loss: 1.0582 - val_acc: 0.5825\n",
      "Epoch 1440/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0244 - acc: 0.5886 - val_loss: 1.0553 - val_acc: 0.5872\n",
      "Epoch 1441/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0131 - acc: 0.5909 - val_loss: 1.0539 - val_acc: 0.5933\n",
      "Epoch 1442/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0099 - acc: 0.5956 - val_loss: 1.0626 - val_acc: 0.5866\n",
      "Epoch 1443/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0213 - acc: 0.5900 - val_loss: 1.0592 - val_acc: 0.5866\n",
      "Epoch 1444/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0134 - acc: 0.5914 - val_loss: 1.0510 - val_acc: 0.5872\n",
      "Epoch 1445/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0248 - acc: 0.5872 - val_loss: 1.0714 - val_acc: 0.5843\n",
      "Epoch 1446/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0145 - acc: 0.6013 - val_loss: 1.0655 - val_acc: 0.5906\n",
      "Epoch 1447/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0242 - acc: 0.5912 - val_loss: 1.0697 - val_acc: 0.5796\n",
      "Epoch 1448/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0277 - acc: 0.5870 - val_loss: 1.0576 - val_acc: 0.5854\n",
      "Epoch 1449/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0177 - acc: 0.5886 - val_loss: 1.0682 - val_acc: 0.5848\n",
      "Epoch 1450/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0197 - acc: 0.5914 - val_loss: 1.0607 - val_acc: 0.5869\n",
      "Epoch 1451/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0146 - acc: 0.5928 - val_loss: 1.0447 - val_acc: 0.5967\n",
      "Epoch 1452/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0160 - acc: 0.5907 - val_loss: 1.0577 - val_acc: 0.5880\n",
      "Epoch 1453/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0193 - acc: 0.5936 - val_loss: 1.0588 - val_acc: 0.5863\n",
      "Epoch 1454/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0218 - acc: 0.5883 - val_loss: 1.0703 - val_acc: 0.5802\n",
      "Epoch 1455/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0165 - acc: 0.5936 - val_loss: 1.0643 - val_acc: 0.5912\n",
      "Epoch 1456/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0138 - acc: 0.5919 - val_loss: 1.0675 - val_acc: 0.5811\n",
      "Epoch 1457/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0196 - acc: 0.5906 - val_loss: 1.0585 - val_acc: 0.5909\n",
      "Epoch 1458/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0275 - acc: 0.5852 - val_loss: 1.0915 - val_acc: 0.5764\n",
      "Epoch 1459/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0213 - acc: 0.5892 - val_loss: 1.0620 - val_acc: 0.5906\n",
      "Epoch 1460/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0200 - acc: 0.5874 - val_loss: 1.0617 - val_acc: 0.5889\n",
      "Epoch 1461/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0189 - acc: 0.5909 - val_loss: 1.0560 - val_acc: 0.5854\n",
      "Epoch 1462/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0246 - acc: 0.5894 - val_loss: 1.0555 - val_acc: 0.5889\n",
      "Epoch 1463/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0317 - acc: 0.5838 - val_loss: 1.0521 - val_acc: 0.5848\n",
      "Epoch 1464/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0144 - acc: 0.5915 - val_loss: 1.0634 - val_acc: 0.5813\n",
      "Epoch 1465/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0146 - acc: 0.5878 - val_loss: 1.0628 - val_acc: 0.5874\n",
      "Epoch 1466/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 1.0224 - acc: 0.5877 - val_loss: 1.0636 - val_acc: 0.5863\n",
      "Epoch 1467/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.0166 - acc: 0.5884 - val_loss: 1.0690 - val_acc: 0.5845\n",
      "Epoch 1468/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0189 - acc: 0.5900 - val_loss: 1.0549 - val_acc: 0.5874\n",
      "Epoch 1469/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0276 - acc: 0.5889 - val_loss: 1.0721 - val_acc: 0.5877\n",
      "Epoch 1470/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0100 - acc: 0.5936 - val_loss: 1.0589 - val_acc: 0.5828\n",
      "Epoch 1471/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0168 - acc: 0.5890 - val_loss: 1.0635 - val_acc: 0.5816\n",
      "Epoch 1472/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0167 - acc: 0.5902 - val_loss: 1.0571 - val_acc: 0.5857\n",
      "Epoch 1473/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0166 - acc: 0.5916 - val_loss: 1.0656 - val_acc: 0.5854\n",
      "Epoch 1474/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0267 - acc: 0.5870 - val_loss: 1.0685 - val_acc: 0.5790\n",
      "Epoch 1475/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0141 - acc: 0.5894 - val_loss: 1.0644 - val_acc: 0.5819\n",
      "Epoch 1476/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0144 - acc: 0.5923 - val_loss: 1.0631 - val_acc: 0.5837\n",
      "Epoch 1477/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0178 - acc: 0.5930 - val_loss: 1.0607 - val_acc: 0.5880\n",
      "Epoch 1478/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0213 - acc: 0.5896 - val_loss: 1.0575 - val_acc: 0.5866\n",
      "Epoch 1479/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0241 - acc: 0.5871 - val_loss: 1.0474 - val_acc: 0.5889\n",
      "Epoch 1480/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0127 - acc: 0.5918 - val_loss: 1.0679 - val_acc: 0.5863\n",
      "Epoch 1481/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0063 - acc: 0.5928 - val_loss: 1.0614 - val_acc: 0.5796\n",
      "Epoch 1482/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0268 - acc: 0.5904 - val_loss: 1.0601 - val_acc: 0.5860\n",
      "Epoch 1483/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0096 - acc: 0.5977 - val_loss: 1.0551 - val_acc: 0.5962\n",
      "Epoch 1484/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0160 - acc: 0.5882 - val_loss: 1.0487 - val_acc: 0.5872\n",
      "Epoch 1485/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0179 - acc: 0.5899 - val_loss: 1.0577 - val_acc: 0.5912\n",
      "Epoch 1486/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0201 - acc: 0.5868 - val_loss: 1.0473 - val_acc: 0.5901\n",
      "Epoch 1487/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0145 - acc: 0.5920 - val_loss: 1.0635 - val_acc: 0.5857\n",
      "Epoch 1488/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0139 - acc: 0.5916 - val_loss: 1.0520 - val_acc: 0.5848\n",
      "Epoch 1489/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0119 - acc: 0.5952 - val_loss: 1.0665 - val_acc: 0.5909\n",
      "Epoch 1490/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0118 - acc: 0.5952 - val_loss: 1.0614 - val_acc: 0.5825\n",
      "Epoch 1491/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0187 - acc: 0.5927 - val_loss: 1.0653 - val_acc: 0.5904\n",
      "Epoch 1492/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0139 - acc: 0.5907 - val_loss: 1.0540 - val_acc: 0.5860\n",
      "Epoch 1493/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0165 - acc: 0.5901 - val_loss: 1.0581 - val_acc: 0.5851\n",
      "Epoch 1494/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0108 - acc: 0.5912 - val_loss: 1.0556 - val_acc: 0.5863\n",
      "Epoch 1495/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0211 - acc: 0.5885 - val_loss: 1.0674 - val_acc: 0.5863\n",
      "Epoch 1496/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0226 - acc: 0.5868 - val_loss: 1.0660 - val_acc: 0.5892\n",
      "Epoch 1497/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0142 - acc: 0.5888 - val_loss: 1.0573 - val_acc: 0.5872\n",
      "Epoch 1498/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0193 - acc: 0.5904 - val_loss: 1.0507 - val_acc: 0.5863\n",
      "Epoch 1499/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0227 - acc: 0.5899 - val_loss: 1.0627 - val_acc: 0.5857\n",
      "Epoch 1500/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0128 - acc: 0.5934 - val_loss: 1.0690 - val_acc: 0.5857\n",
      "Epoch 1501/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0133 - acc: 0.5884 - val_loss: 1.0558 - val_acc: 0.5950\n",
      "Epoch 1502/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0113 - acc: 0.5940 - val_loss: 1.0679 - val_acc: 0.5869\n",
      "Epoch 1503/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0229 - acc: 0.5854 - val_loss: 1.0535 - val_acc: 0.5854\n",
      "Epoch 1504/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0144 - acc: 0.5956 - val_loss: 1.0502 - val_acc: 0.5924\n",
      "Epoch 1505/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.0135 - acc: 0.5915 - val_loss: 1.0660 - val_acc: 0.5854\n",
      "Epoch 1506/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0145 - acc: 0.5917 - val_loss: 1.0548 - val_acc: 0.5904\n",
      "Epoch 1507/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0107 - acc: 0.5926 - val_loss: 1.0582 - val_acc: 0.5874\n",
      "Epoch 1508/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0124 - acc: 0.5889 - val_loss: 1.0459 - val_acc: 0.5874\n",
      "Epoch 1509/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0164 - acc: 0.5935 - val_loss: 1.0499 - val_acc: 0.5909\n",
      "Epoch 1510/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0129 - acc: 0.5886 - val_loss: 1.0503 - val_acc: 0.5901\n",
      "Epoch 1511/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0061 - acc: 0.5970 - val_loss: 1.0583 - val_acc: 0.5886\n",
      "Epoch 1512/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0188 - acc: 0.5912 - val_loss: 1.0587 - val_acc: 0.5851\n",
      "Epoch 1513/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0151 - acc: 0.5905 - val_loss: 1.0696 - val_acc: 0.5787\n",
      "Epoch 1514/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0193 - acc: 0.5915 - val_loss: 1.0570 - val_acc: 0.5938\n",
      "Epoch 1515/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0099 - acc: 0.5966 - val_loss: 1.0682 - val_acc: 0.5816\n",
      "Epoch 1516/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0070 - acc: 0.5948 - val_loss: 1.0550 - val_acc: 0.5915\n",
      "Epoch 1517/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0259 - acc: 0.5877 - val_loss: 1.0573 - val_acc: 0.5782\n",
      "Epoch 1518/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0112 - acc: 0.5905 - val_loss: 1.0713 - val_acc: 0.5825\n",
      "Epoch 1519/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0186 - acc: 0.5911 - val_loss: 1.0594 - val_acc: 0.5906\n",
      "Epoch 1520/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0159 - acc: 0.5918 - val_loss: 1.0539 - val_acc: 0.5880\n",
      "Epoch 1521/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0091 - acc: 0.5922 - val_loss: 1.0480 - val_acc: 0.5912\n",
      "Epoch 1522/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0189 - acc: 0.5894 - val_loss: 1.0589 - val_acc: 0.5883\n",
      "Epoch 1523/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0073 - acc: 0.5936 - val_loss: 1.0695 - val_acc: 0.5889\n",
      "Epoch 1524/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0144 - acc: 0.5904 - val_loss: 1.0617 - val_acc: 0.5889\n",
      "Epoch 1525/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0103 - acc: 0.5930 - val_loss: 1.0552 - val_acc: 0.5866\n",
      "Epoch 1526/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0084 - acc: 0.5934 - val_loss: 1.0728 - val_acc: 0.5790\n",
      "Epoch 1527/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0150 - acc: 0.5921 - val_loss: 1.0654 - val_acc: 0.5805\n",
      "Epoch 1528/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0099 - acc: 0.5951 - val_loss: 1.0663 - val_acc: 0.5813\n",
      "Epoch 1529/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0112 - acc: 0.5936 - val_loss: 1.0455 - val_acc: 0.5880\n",
      "Epoch 1530/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0092 - acc: 0.5970 - val_loss: 1.0609 - val_acc: 0.5854\n",
      "Epoch 1531/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0223 - acc: 0.5902 - val_loss: 1.0483 - val_acc: 0.5880\n",
      "Epoch 1532/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0159 - acc: 0.5900 - val_loss: 1.0683 - val_acc: 0.5819\n",
      "Epoch 1533/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0221 - acc: 0.5904 - val_loss: 1.0557 - val_acc: 0.5877\n",
      "Epoch 1534/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0108 - acc: 0.5931 - val_loss: 1.0640 - val_acc: 0.5906\n",
      "Epoch 1535/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0085 - acc: 0.5945 - val_loss: 1.0837 - val_acc: 0.5790\n",
      "Epoch 1536/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.0024 - acc: 0.5996 - val_loss: 1.0507 - val_acc: 0.5854\n",
      "Epoch 1537/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9986 - acc: 0.5997 - val_loss: 1.0655 - val_acc: 0.5895\n",
      "Epoch 1538/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0138 - acc: 0.5923 - val_loss: 1.0537 - val_acc: 0.5889\n",
      "Epoch 1539/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0142 - acc: 0.5923 - val_loss: 1.0544 - val_acc: 0.5874\n",
      "Epoch 1540/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0158 - acc: 0.5910 - val_loss: 1.0517 - val_acc: 0.5898\n",
      "Epoch 1541/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0149 - acc: 0.5891 - val_loss: 1.0582 - val_acc: 0.5991\n",
      "Epoch 1542/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0255 - acc: 0.5883 - val_loss: 1.0526 - val_acc: 0.5918\n",
      "Epoch 1543/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0082 - acc: 0.5955 - val_loss: 1.0508 - val_acc: 0.5965\n",
      "Epoch 1544/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0160 - acc: 0.5930 - val_loss: 1.0537 - val_acc: 0.5866\n",
      "Epoch 1545/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 1.0153 - acc: 0.5937 - val_loss: 1.0575 - val_acc: 0.5877\n",
      "Epoch 1546/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0193 - acc: 0.5891 - val_loss: 1.0574 - val_acc: 0.5845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1547/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0119 - acc: 0.5923 - val_loss: 1.0599 - val_acc: 0.5790\n",
      "Epoch 1548/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 1.0109 - acc: 0.5908 - val_loss: 1.0534 - val_acc: 0.5889\n",
      "Epoch 1549/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 1.0156 - acc: 0.5896 - val_loss: 1.0572 - val_acc: 0.5860\n",
      "Epoch 1550/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0173 - acc: 0.5932 - val_loss: 1.0623 - val_acc: 0.5802\n",
      "Epoch 1551/3000\n",
      "13766/13766 [==============================] - 1s 83us/step - loss: 1.0070 - acc: 0.5942 - val_loss: 1.0457 - val_acc: 0.5889\n",
      "Epoch 1552/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0098 - acc: 0.5955 - val_loss: 1.0558 - val_acc: 0.5889\n",
      "Epoch 1553/3000\n",
      "13766/13766 [==============================] - ETA: 0s - loss: 1.0086 - acc: 0.594 - 1s 41us/step - loss: 1.0126 - acc: 0.5925 - val_loss: 1.0613 - val_acc: 0.5886\n",
      "Epoch 1554/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0100 - acc: 0.5931 - val_loss: 1.0494 - val_acc: 0.5936\n",
      "Epoch 1555/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0109 - acc: 0.5911 - val_loss: 1.0519 - val_acc: 0.5857\n",
      "Epoch 1556/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0082 - acc: 0.5918 - val_loss: 1.0595 - val_acc: 0.5837\n",
      "Epoch 1557/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0077 - acc: 0.5927 - val_loss: 1.0651 - val_acc: 0.5819\n",
      "Epoch 1558/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0192 - acc: 0.5906 - val_loss: 1.0696 - val_acc: 0.5813\n",
      "Epoch 1559/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0207 - acc: 0.5922 - val_loss: 1.0630 - val_acc: 0.5845\n",
      "Epoch 1560/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0107 - acc: 0.5910 - val_loss: 1.0517 - val_acc: 0.5889\n",
      "Epoch 1561/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0142 - acc: 0.5924 - val_loss: 1.0586 - val_acc: 0.5895\n",
      "Epoch 1562/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0152 - acc: 0.5907 - val_loss: 1.0608 - val_acc: 0.5840\n",
      "Epoch 1563/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0169 - acc: 0.5923 - val_loss: 1.0536 - val_acc: 0.5933\n",
      "Epoch 1564/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0163 - acc: 0.5937 - val_loss: 1.0440 - val_acc: 0.5959\n",
      "Epoch 1565/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0190 - acc: 0.5909 - val_loss: 1.0516 - val_acc: 0.5872\n",
      "Epoch 1566/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0041 - acc: 0.5982 - val_loss: 1.0639 - val_acc: 0.5906\n",
      "Epoch 1567/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0093 - acc: 0.5943 - val_loss: 1.0571 - val_acc: 0.5886\n",
      "Epoch 1568/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0098 - acc: 0.5939 - val_loss: 1.0560 - val_acc: 0.5892\n",
      "Epoch 1569/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0082 - acc: 0.5926 - val_loss: 1.0581 - val_acc: 0.5886\n",
      "Epoch 1570/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0076 - acc: 0.5928 - val_loss: 1.0485 - val_acc: 0.5843\n",
      "Epoch 1571/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0119 - acc: 0.5894 - val_loss: 1.0600 - val_acc: 0.5877\n",
      "Epoch 1572/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0204 - acc: 0.5883 - val_loss: 1.0569 - val_acc: 0.5904\n",
      "Epoch 1573/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0139 - acc: 0.5932 - val_loss: 1.0432 - val_acc: 0.6011\n",
      "Epoch 1574/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0111 - acc: 0.5927 - val_loss: 1.0641 - val_acc: 0.5840\n",
      "Epoch 1575/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0064 - acc: 0.5936 - val_loss: 1.0685 - val_acc: 0.5825\n",
      "Epoch 1576/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0129 - acc: 0.5994 - val_loss: 1.0690 - val_acc: 0.5735\n",
      "Epoch 1577/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0060 - acc: 0.5947 - val_loss: 1.0467 - val_acc: 0.5880\n",
      "Epoch 1578/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 1.0178 - acc: 0.5933 - val_loss: 1.0608 - val_acc: 0.5918\n",
      "Epoch 1579/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0074 - acc: 0.5932 - val_loss: 1.0590 - val_acc: 0.5880\n",
      "Epoch 1580/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0101 - acc: 0.5938 - val_loss: 1.0580 - val_acc: 0.5834\n",
      "Epoch 1581/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0059 - acc: 0.5933 - val_loss: 1.0661 - val_acc: 0.5837\n",
      "Epoch 1582/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0152 - acc: 0.5901 - val_loss: 1.0489 - val_acc: 0.5936\n",
      "Epoch 1583/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0074 - acc: 0.5946 - val_loss: 1.0701 - val_acc: 0.5761\n",
      "Epoch 1584/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0136 - acc: 0.5908 - val_loss: 1.0533 - val_acc: 0.5860\n",
      "Epoch 1585/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0049 - acc: 0.5954 - val_loss: 1.0539 - val_acc: 0.5898\n",
      "Epoch 1586/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0192 - acc: 0.5901 - val_loss: 1.0709 - val_acc: 0.5819\n",
      "Epoch 1587/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0127 - acc: 0.5909 - val_loss: 1.0583 - val_acc: 0.5874\n",
      "Epoch 1588/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0192 - acc: 0.5913 - val_loss: 1.0518 - val_acc: 0.5921\n",
      "Epoch 1589/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9988 - acc: 0.5925 - val_loss: 1.0545 - val_acc: 0.5918\n",
      "Epoch 1590/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0126 - acc: 0.5893 - val_loss: 1.0567 - val_acc: 0.5848\n",
      "Epoch 1591/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0104 - acc: 0.5933 - val_loss: 1.0595 - val_acc: 0.5915\n",
      "Epoch 1592/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0084 - acc: 0.6001 - val_loss: 1.0683 - val_acc: 0.5831\n",
      "Epoch 1593/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0094 - acc: 0.5960 - val_loss: 1.0654 - val_acc: 0.5848\n",
      "Epoch 1594/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0240 - acc: 0.5862 - val_loss: 1.0707 - val_acc: 0.5813\n",
      "Epoch 1595/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0091 - acc: 0.5953 - val_loss: 1.0409 - val_acc: 0.5918\n",
      "Epoch 1596/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0152 - acc: 0.5932 - val_loss: 1.0586 - val_acc: 0.5874\n",
      "Epoch 1597/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9981 - acc: 0.5976 - val_loss: 1.0438 - val_acc: 0.5994\n",
      "Epoch 1598/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0180 - acc: 0.5905 - val_loss: 1.0687 - val_acc: 0.5840\n",
      "Epoch 1599/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0164 - acc: 0.5942 - val_loss: 1.0520 - val_acc: 0.5874\n",
      "Epoch 1600/3000\n",
      "13766/13766 [==============================] - 1s 73us/step - loss: 1.0159 - acc: 0.5907 - val_loss: 1.0567 - val_acc: 0.5904\n",
      "Epoch 1601/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.0026 - acc: 0.5984 - val_loss: 1.0584 - val_acc: 0.5898\n",
      "Epoch 1602/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0160 - acc: 0.5946 - val_loss: 1.0527 - val_acc: 0.5927\n",
      "Epoch 1603/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0056 - acc: 0.5919 - val_loss: 1.0569 - val_acc: 0.5892\n",
      "Epoch 1604/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0185 - acc: 0.5936 - val_loss: 1.0544 - val_acc: 0.5880\n",
      "Epoch 1605/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0071 - acc: 0.5919 - val_loss: 1.0575 - val_acc: 0.5872\n",
      "Epoch 1606/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0081 - acc: 0.5942 - val_loss: 1.0671 - val_acc: 0.5918\n",
      "Epoch 1607/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0052 - acc: 0.5970 - val_loss: 1.0643 - val_acc: 0.5872\n",
      "Epoch 1608/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0161 - acc: 0.5903 - val_loss: 1.0491 - val_acc: 0.5883\n",
      "Epoch 1609/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0156 - acc: 0.5899 - val_loss: 1.0573 - val_acc: 0.5880\n",
      "Epoch 1610/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0077 - acc: 0.5976 - val_loss: 1.0563 - val_acc: 0.5822\n",
      "Epoch 1611/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0072 - acc: 0.5964 - val_loss: 1.0471 - val_acc: 0.5959\n",
      "Epoch 1612/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9944 - acc: 0.5984 - val_loss: 1.0527 - val_acc: 0.5880\n",
      "Epoch 1613/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0170 - acc: 0.5919 - val_loss: 1.0529 - val_acc: 0.5904\n",
      "Epoch 1614/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0080 - acc: 0.5928 - val_loss: 1.0584 - val_acc: 0.5857\n",
      "Epoch 1615/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0079 - acc: 0.5949 - val_loss: 1.0471 - val_acc: 0.5886\n",
      "Epoch 1616/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0108 - acc: 0.5932 - val_loss: 1.0397 - val_acc: 0.5970\n",
      "Epoch 1617/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0099 - acc: 0.5934 - val_loss: 1.0588 - val_acc: 0.5869\n",
      "Epoch 1618/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0099 - acc: 0.5968 - val_loss: 1.0605 - val_acc: 0.5904\n",
      "Epoch 1619/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0113 - acc: 0.5949 - val_loss: 1.0558 - val_acc: 0.5880\n",
      "Epoch 1620/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0053 - acc: 0.5973 - val_loss: 1.0432 - val_acc: 0.5924\n",
      "Epoch 1621/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0088 - acc: 0.5975 - val_loss: 1.0559 - val_acc: 0.5933\n",
      "Epoch 1622/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0073 - acc: 0.5933 - val_loss: 1.0559 - val_acc: 0.5857\n",
      "Epoch 1623/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0078 - acc: 0.5958 - val_loss: 1.0706 - val_acc: 0.5808\n",
      "Epoch 1624/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0132 - acc: 0.5965 - val_loss: 1.0519 - val_acc: 0.5906\n",
      "Epoch 1625/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0087 - acc: 0.5928 - val_loss: 1.0566 - val_acc: 0.5872\n",
      "Epoch 1626/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0139 - acc: 0.5944 - val_loss: 1.0676 - val_acc: 0.5819\n",
      "Epoch 1627/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0083 - acc: 0.5939 - val_loss: 1.0573 - val_acc: 0.5857\n",
      "Epoch 1628/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0105 - acc: 0.5981 - val_loss: 1.0505 - val_acc: 0.5886\n",
      "Epoch 1629/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0107 - acc: 0.5930 - val_loss: 1.0447 - val_acc: 0.5967\n",
      "Epoch 1630/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0001 - acc: 0.5986 - val_loss: 1.0419 - val_acc: 0.5962\n",
      "Epoch 1631/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0176 - acc: 0.5910 - val_loss: 1.0451 - val_acc: 0.5933\n",
      "Epoch 1632/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0065 - acc: 0.5920 - val_loss: 1.0612 - val_acc: 0.5933\n",
      "Epoch 1633/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0153 - acc: 0.5937 - val_loss: 1.0526 - val_acc: 0.5883\n",
      "Epoch 1634/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9984 - acc: 0.5995 - val_loss: 1.0490 - val_acc: 0.5895\n",
      "Epoch 1635/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0073 - acc: 0.5960 - val_loss: 1.0416 - val_acc: 0.5912\n",
      "Epoch 1636/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0099 - acc: 0.5923 - val_loss: 1.0447 - val_acc: 0.5901\n",
      "Epoch 1637/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0138 - acc: 0.5887 - val_loss: 1.0478 - val_acc: 0.5874\n",
      "Epoch 1638/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0119 - acc: 0.5915 - val_loss: 1.0451 - val_acc: 0.5898\n",
      "Epoch 1639/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0141 - acc: 0.5934 - val_loss: 1.0564 - val_acc: 0.5889\n",
      "Epoch 1640/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0164 - acc: 0.5899 - val_loss: 1.0479 - val_acc: 0.5933\n",
      "Epoch 1641/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0093 - acc: 0.5912 - val_loss: 1.0512 - val_acc: 0.5898\n",
      "Epoch 1642/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0026 - acc: 0.6002 - val_loss: 1.0514 - val_acc: 0.5915\n",
      "Epoch 1643/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0015 - acc: 0.5989 - val_loss: 1.0587 - val_acc: 0.5883\n",
      "Epoch 1644/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0101 - acc: 0.5960 - val_loss: 1.0452 - val_acc: 0.5941\n",
      "Epoch 1645/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0044 - acc: 0.5973 - val_loss: 1.0528 - val_acc: 0.5877\n",
      "Epoch 1646/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9972 - acc: 0.5956 - val_loss: 1.0482 - val_acc: 0.5953\n",
      "Epoch 1647/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0113 - acc: 0.5928 - val_loss: 1.0557 - val_acc: 0.5886\n",
      "Epoch 1648/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0146 - acc: 0.5939 - val_loss: 1.0500 - val_acc: 0.5880\n",
      "Epoch 1649/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0100 - acc: 0.5935 - val_loss: 1.0615 - val_acc: 0.5872\n",
      "Epoch 1650/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0103 - acc: 0.5979 - val_loss: 1.0508 - val_acc: 0.5941\n",
      "Epoch 1651/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0119 - acc: 0.5973 - val_loss: 1.0693 - val_acc: 0.5863\n",
      "Epoch 1652/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0119 - acc: 0.5941 - val_loss: 1.0554 - val_acc: 0.5904\n",
      "Epoch 1653/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0130 - acc: 0.5910 - val_loss: 1.0604 - val_acc: 0.5848\n",
      "Epoch 1654/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0068 - acc: 0.5973 - val_loss: 1.0559 - val_acc: 0.5936\n",
      "Epoch 1655/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0023 - acc: 0.5997 - val_loss: 1.0514 - val_acc: 0.5976\n",
      "Epoch 1656/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0047 - acc: 0.5947 - val_loss: 1.0399 - val_acc: 0.5921\n",
      "Epoch 1657/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0065 - acc: 0.5954 - val_loss: 1.0487 - val_acc: 0.5872\n",
      "Epoch 1658/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0088 - acc: 0.5963 - val_loss: 1.0474 - val_acc: 0.5947\n",
      "Epoch 1659/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0025 - acc: 0.5968 - val_loss: 1.0589 - val_acc: 0.5802\n",
      "Epoch 1660/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0095 - acc: 0.5911 - val_loss: 1.0611 - val_acc: 0.5837\n",
      "Epoch 1661/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0095 - acc: 0.5897 - val_loss: 1.0635 - val_acc: 0.5825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1662/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0054 - acc: 0.5963 - val_loss: 1.0524 - val_acc: 0.5857\n",
      "Epoch 1663/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0047 - acc: 0.5939 - val_loss: 1.0650 - val_acc: 0.5898\n",
      "Epoch 1664/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0120 - acc: 0.5957 - val_loss: 1.0560 - val_acc: 0.5843\n",
      "Epoch 1665/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0004 - acc: 0.5947 - val_loss: 1.0475 - val_acc: 0.5967\n",
      "Epoch 1666/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0014 - acc: 0.5951 - val_loss: 1.0525 - val_acc: 0.5880\n",
      "Epoch 1667/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0102 - acc: 0.5932 - val_loss: 1.0489 - val_acc: 0.5895\n",
      "Epoch 1668/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0133 - acc: 0.5928 - val_loss: 1.0519 - val_acc: 0.5845\n",
      "Epoch 1669/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0131 - acc: 0.5923 - val_loss: 1.0566 - val_acc: 0.5892\n",
      "Epoch 1670/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0058 - acc: 0.5936 - val_loss: 1.0565 - val_acc: 0.5857\n",
      "Epoch 1671/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0088 - acc: 0.5967 - val_loss: 1.0468 - val_acc: 0.5898\n",
      "Epoch 1672/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9987 - acc: 0.6010 - val_loss: 1.0555 - val_acc: 0.5840\n",
      "Epoch 1673/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0091 - acc: 0.5878 - val_loss: 1.0618 - val_acc: 0.5851\n",
      "Epoch 1674/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9960 - acc: 0.5989 - val_loss: 1.0436 - val_acc: 0.5906\n",
      "Epoch 1675/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0069 - acc: 0.5962 - val_loss: 1.0532 - val_acc: 0.5982\n",
      "Epoch 1676/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0132 - acc: 0.5925 - val_loss: 1.0507 - val_acc: 0.5918\n",
      "Epoch 1677/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0033 - acc: 0.5974 - val_loss: 1.0510 - val_acc: 0.5918\n",
      "Epoch 1678/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9985 - acc: 0.6010 - val_loss: 1.0602 - val_acc: 0.5851\n",
      "Epoch 1679/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0107 - acc: 0.5957 - val_loss: 1.0659 - val_acc: 0.5840\n",
      "Epoch 1680/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0146 - acc: 0.5922 - val_loss: 1.0609 - val_acc: 0.5892\n",
      "Epoch 1681/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0027 - acc: 0.5978 - val_loss: 1.0560 - val_acc: 0.5909\n",
      "Epoch 1682/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0158 - acc: 0.5906 - val_loss: 1.0509 - val_acc: 0.5880\n",
      "Epoch 1683/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0101 - acc: 0.5941 - val_loss: 1.0538 - val_acc: 0.5857\n",
      "Epoch 1684/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0107 - acc: 0.5937 - val_loss: 1.0509 - val_acc: 0.5901\n",
      "Epoch 1685/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0050 - acc: 0.5986 - val_loss: 1.0673 - val_acc: 0.5933\n",
      "Epoch 1686/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0107 - acc: 0.5972 - val_loss: 1.0580 - val_acc: 0.5845\n",
      "Epoch 1687/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0112 - acc: 0.5968 - val_loss: 1.0568 - val_acc: 0.5866\n",
      "Epoch 1688/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9992 - acc: 0.5978 - val_loss: 1.0484 - val_acc: 0.5947\n",
      "Epoch 1689/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0034 - acc: 0.6010 - val_loss: 1.0444 - val_acc: 0.5982\n",
      "Epoch 1690/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0180 - acc: 0.5882 - val_loss: 1.0512 - val_acc: 0.5854\n",
      "Epoch 1691/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 1.0013 - acc: 0.5987 - val_loss: 1.0439 - val_acc: 0.5904\n",
      "Epoch 1692/3000\n",
      "13766/13766 [==============================] - 1s 65us/step - loss: 1.0011 - acc: 0.5972 - val_loss: 1.0496 - val_acc: 0.5872\n",
      "Epoch 1693/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0143 - acc: 0.5917 - val_loss: 1.0479 - val_acc: 0.5915\n",
      "Epoch 1694/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0040 - acc: 0.5948 - val_loss: 1.0508 - val_acc: 0.5921\n",
      "Epoch 1695/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0038 - acc: 0.5975 - val_loss: 1.0652 - val_acc: 0.5877\n",
      "Epoch 1696/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0035 - acc: 0.5960 - val_loss: 1.0522 - val_acc: 0.5967\n",
      "Epoch 1697/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0075 - acc: 0.5939 - val_loss: 1.0563 - val_acc: 0.5854\n",
      "Epoch 1698/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0076 - acc: 0.5943 - val_loss: 1.0412 - val_acc: 0.5985\n",
      "Epoch 1699/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9957 - acc: 0.6005 - val_loss: 1.0553 - val_acc: 0.5904\n",
      "Epoch 1700/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0044 - acc: 0.5939 - val_loss: 1.0545 - val_acc: 0.5901\n",
      "Epoch 1701/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0054 - acc: 0.5996 - val_loss: 1.0443 - val_acc: 0.5944\n",
      "Epoch 1702/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0064 - acc: 0.5918 - val_loss: 1.0550 - val_acc: 0.5924\n",
      "Epoch 1703/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0047 - acc: 0.5978 - val_loss: 1.0525 - val_acc: 0.5837\n",
      "Epoch 1704/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0047 - acc: 0.5949 - val_loss: 1.0534 - val_acc: 0.5895\n",
      "Epoch 1705/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 1.0065 - acc: 0.5986 - val_loss: 1.0510 - val_acc: 0.5927\n",
      "Epoch 1706/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0081 - acc: 0.5963 - val_loss: 1.0490 - val_acc: 0.5883\n",
      "Epoch 1707/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0076 - acc: 0.5981 - val_loss: 1.0447 - val_acc: 0.5973\n",
      "Epoch 1708/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0105 - acc: 0.5947 - val_loss: 1.0546 - val_acc: 0.5901\n",
      "Epoch 1709/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0061 - acc: 0.6005 - val_loss: 1.0442 - val_acc: 0.5834\n",
      "Epoch 1710/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0103 - acc: 0.5963 - val_loss: 1.0497 - val_acc: 0.5970\n",
      "Epoch 1711/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0079 - acc: 0.5931 - val_loss: 1.0465 - val_acc: 0.5936\n",
      "Epoch 1712/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0011 - acc: 0.5971 - val_loss: 1.0634 - val_acc: 0.5933\n",
      "Epoch 1713/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0079 - acc: 0.5982 - val_loss: 1.0546 - val_acc: 0.5851\n",
      "Epoch 1714/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0036 - acc: 0.5960 - val_loss: 1.0522 - val_acc: 0.5848\n",
      "Epoch 1715/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0059 - acc: 0.5970 - val_loss: 1.0431 - val_acc: 0.5892\n",
      "Epoch 1716/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0034 - acc: 0.5971 - val_loss: 1.0540 - val_acc: 0.5889\n",
      "Epoch 1717/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0124 - acc: 0.5941 - val_loss: 1.0516 - val_acc: 0.5918\n",
      "Epoch 1718/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0054 - acc: 0.5968 - val_loss: 1.0508 - val_acc: 0.5915\n",
      "Epoch 1719/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0090 - acc: 0.5955 - val_loss: 1.0530 - val_acc: 0.5889\n",
      "Epoch 1720/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9979 - acc: 0.6005 - val_loss: 1.0512 - val_acc: 0.5947\n",
      "Epoch 1721/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9999 - acc: 0.5975 - val_loss: 1.0496 - val_acc: 0.5872\n",
      "Epoch 1722/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0007 - acc: 0.5960 - val_loss: 1.0452 - val_acc: 0.5976\n",
      "Epoch 1723/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0031 - acc: 0.5971 - val_loss: 1.0601 - val_acc: 0.5976\n",
      "Epoch 1724/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0066 - acc: 0.5949 - val_loss: 1.0508 - val_acc: 0.5834\n",
      "Epoch 1725/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0048 - acc: 0.5949 - val_loss: 1.0744 - val_acc: 0.5816\n",
      "Epoch 1726/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0057 - acc: 0.5891 - val_loss: 1.0529 - val_acc: 0.5880\n",
      "Epoch 1727/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0007 - acc: 0.5985 - val_loss: 1.0467 - val_acc: 0.5927\n",
      "Epoch 1728/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0029 - acc: 0.6043 - val_loss: 1.0518 - val_acc: 0.5880\n",
      "Epoch 1729/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0048 - acc: 0.5956 - val_loss: 1.0506 - val_acc: 0.5889\n",
      "Epoch 1730/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0143 - acc: 0.5933 - val_loss: 1.0532 - val_acc: 0.5895\n",
      "Epoch 1731/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0075 - acc: 0.5944 - val_loss: 1.0495 - val_acc: 0.5872\n",
      "Epoch 1732/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0048 - acc: 0.5975 - val_loss: 1.0433 - val_acc: 0.5918\n",
      "Epoch 1733/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9968 - acc: 0.6005 - val_loss: 1.0480 - val_acc: 0.5866\n",
      "Epoch 1734/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9965 - acc: 0.5988 - val_loss: 1.0494 - val_acc: 0.5918\n",
      "Epoch 1735/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0053 - acc: 0.5976 - val_loss: 1.0665 - val_acc: 0.5892\n",
      "Epoch 1736/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0015 - acc: 0.5936 - val_loss: 1.0524 - val_acc: 0.5819\n",
      "Epoch 1737/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0028 - acc: 0.5988 - val_loss: 1.0427 - val_acc: 0.5947\n",
      "Epoch 1738/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0103 - acc: 0.5951 - val_loss: 1.0526 - val_acc: 0.5877\n",
      "Epoch 1739/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0030 - acc: 0.5994 - val_loss: 1.0500 - val_acc: 0.5860\n",
      "Epoch 1740/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0033 - acc: 0.5957 - val_loss: 1.0516 - val_acc: 0.5869\n",
      "Epoch 1741/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9986 - acc: 0.5952 - val_loss: 1.0474 - val_acc: 0.6005\n",
      "Epoch 1742/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9971 - acc: 0.5988 - val_loss: 1.0423 - val_acc: 0.5906\n",
      "Epoch 1743/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0059 - acc: 0.5978 - val_loss: 1.0664 - val_acc: 0.5906\n",
      "Epoch 1744/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0151 - acc: 0.5898 - val_loss: 1.0607 - val_acc: 0.5950\n",
      "Epoch 1745/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0034 - acc: 0.5996 - val_loss: 1.0412 - val_acc: 0.5970\n",
      "Epoch 1746/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0002 - acc: 0.6017 - val_loss: 1.0487 - val_acc: 0.5965\n",
      "Epoch 1747/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9969 - acc: 0.5979 - val_loss: 1.0467 - val_acc: 0.5944\n",
      "Epoch 1748/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0029 - acc: 0.5953 - val_loss: 1.0557 - val_acc: 0.5860\n",
      "Epoch 1749/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0108 - acc: 0.6002 - val_loss: 1.0461 - val_acc: 0.5877\n",
      "Epoch 1750/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0095 - acc: 0.5938 - val_loss: 1.0508 - val_acc: 0.5889\n",
      "Epoch 1751/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0098 - acc: 0.5968 - val_loss: 1.0648 - val_acc: 0.5880\n",
      "Epoch 1752/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9974 - acc: 0.5959 - val_loss: 1.0529 - val_acc: 0.5909\n",
      "Epoch 1753/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0102 - acc: 0.5954 - val_loss: 1.0700 - val_acc: 0.5837\n",
      "Epoch 1754/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0003 - acc: 0.5967 - val_loss: 1.0646 - val_acc: 0.5854\n",
      "Epoch 1755/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9976 - acc: 0.5973 - val_loss: 1.0543 - val_acc: 0.5895\n",
      "Epoch 1756/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0040 - acc: 0.5966 - val_loss: 1.0464 - val_acc: 0.5956\n",
      "Epoch 1757/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0081 - acc: 0.5939 - val_loss: 1.0481 - val_acc: 0.5936\n",
      "Epoch 1758/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9984 - acc: 0.6012 - val_loss: 1.0385 - val_acc: 0.5912\n",
      "Epoch 1759/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0027 - acc: 0.6013 - val_loss: 1.0530 - val_acc: 0.5840\n",
      "Epoch 1760/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0080 - acc: 0.5952 - val_loss: 1.0342 - val_acc: 0.5918\n",
      "Epoch 1761/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0040 - acc: 0.5936 - val_loss: 1.0492 - val_acc: 0.5874\n",
      "Epoch 1762/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0046 - acc: 0.5965 - val_loss: 1.0581 - val_acc: 0.5863\n",
      "Epoch 1763/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0051 - acc: 0.5948 - val_loss: 1.0527 - val_acc: 0.5886\n",
      "Epoch 1764/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0028 - acc: 0.5959 - val_loss: 1.0345 - val_acc: 0.5999\n",
      "Epoch 1765/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0084 - acc: 0.5929 - val_loss: 1.0517 - val_acc: 0.5877\n",
      "Epoch 1766/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 1.0016 - acc: 0.5997 - val_loss: 1.0395 - val_acc: 0.5906\n",
      "Epoch 1767/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9912 - acc: 0.6026 - val_loss: 1.0486 - val_acc: 0.5886\n",
      "Epoch 1768/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9994 - acc: 0.5988 - val_loss: 1.0507 - val_acc: 0.5927\n",
      "Epoch 1769/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9970 - acc: 0.6032 - val_loss: 1.0546 - val_acc: 0.5877\n",
      "Epoch 1770/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0078 - acc: 0.5971 - val_loss: 1.0556 - val_acc: 0.5906\n",
      "Epoch 1771/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9959 - acc: 0.5997 - val_loss: 1.0647 - val_acc: 0.5790\n",
      "Epoch 1772/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0163 - acc: 0.5895 - val_loss: 1.0471 - val_acc: 0.5851\n",
      "Epoch 1773/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0021 - acc: 0.5938 - val_loss: 1.0678 - val_acc: 0.5819\n",
      "Epoch 1774/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9963 - acc: 0.5981 - val_loss: 1.0620 - val_acc: 0.5843\n",
      "Epoch 1775/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0108 - acc: 0.5945 - val_loss: 1.0532 - val_acc: 0.5880\n",
      "Epoch 1776/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0021 - acc: 0.5972 - val_loss: 1.0507 - val_acc: 0.5959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1777/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0037 - acc: 0.5970 - val_loss: 1.0518 - val_acc: 0.5933\n",
      "Epoch 1778/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0034 - acc: 0.5970 - val_loss: 1.0391 - val_acc: 0.5927\n",
      "Epoch 1779/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 1.0108 - acc: 0.5893 - val_loss: 1.0510 - val_acc: 0.5927\n",
      "Epoch 1780/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9948 - acc: 0.5952 - val_loss: 1.0507 - val_acc: 0.5901\n",
      "Epoch 1781/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0087 - acc: 0.5948 - val_loss: 1.0426 - val_acc: 0.5936\n",
      "Epoch 1782/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0082 - acc: 0.5976 - val_loss: 1.0467 - val_acc: 0.5892\n",
      "Epoch 1783/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9957 - acc: 0.6040 - val_loss: 1.0400 - val_acc: 0.5938\n",
      "Epoch 1784/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9950 - acc: 0.5981 - val_loss: 1.0605 - val_acc: 0.5872\n",
      "Epoch 1785/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0017 - acc: 0.5947 - val_loss: 1.0509 - val_acc: 0.5909\n",
      "Epoch 1786/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9971 - acc: 0.5950 - val_loss: 1.0569 - val_acc: 0.5924\n",
      "Epoch 1787/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9977 - acc: 0.6008 - val_loss: 1.0458 - val_acc: 0.5979\n",
      "Epoch 1788/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0089 - acc: 0.5927 - val_loss: 1.0619 - val_acc: 0.5840\n",
      "Epoch 1789/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0015 - acc: 0.5986 - val_loss: 1.0537 - val_acc: 0.5889\n",
      "Epoch 1790/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0002 - acc: 0.5978 - val_loss: 1.0457 - val_acc: 0.5906\n",
      "Epoch 1791/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0064 - acc: 0.5927 - val_loss: 1.0389 - val_acc: 0.5904\n",
      "Epoch 1792/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9981 - acc: 0.5964 - val_loss: 1.0506 - val_acc: 0.5802\n",
      "Epoch 1793/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9925 - acc: 0.6031 - val_loss: 1.0458 - val_acc: 0.5904\n",
      "Epoch 1794/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9971 - acc: 0.5975 - val_loss: 1.0552 - val_acc: 0.5848\n",
      "Epoch 1795/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0124 - acc: 0.5922 - val_loss: 1.0512 - val_acc: 0.5837\n",
      "Epoch 1796/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9991 - acc: 0.5976 - val_loss: 1.0582 - val_acc: 0.5854\n",
      "Epoch 1797/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0052 - acc: 0.5945 - val_loss: 1.0418 - val_acc: 0.5927\n",
      "Epoch 1798/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0046 - acc: 0.5963 - val_loss: 1.0523 - val_acc: 0.5901\n",
      "Epoch 1799/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9934 - acc: 0.6002 - val_loss: 1.0495 - val_acc: 0.5956\n",
      "Epoch 1800/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0015 - acc: 0.5952 - val_loss: 1.0583 - val_acc: 0.5909\n",
      "Epoch 1801/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9960 - acc: 0.6037 - val_loss: 1.0500 - val_acc: 0.5947\n",
      "Epoch 1802/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9972 - acc: 0.5979 - val_loss: 1.0438 - val_acc: 0.5944\n",
      "Epoch 1803/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9999 - acc: 0.6006 - val_loss: 1.0650 - val_acc: 0.5854\n",
      "Epoch 1804/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0063 - acc: 0.5922 - val_loss: 1.0491 - val_acc: 0.5936\n",
      "Epoch 1805/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0023 - acc: 0.5933 - val_loss: 1.0573 - val_acc: 0.5848\n",
      "Epoch 1806/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0065 - acc: 0.5997 - val_loss: 1.0523 - val_acc: 0.5918\n",
      "Epoch 1807/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9968 - acc: 0.6024 - val_loss: 1.0484 - val_acc: 0.5880\n",
      "Epoch 1808/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9944 - acc: 0.6024 - val_loss: 1.0426 - val_acc: 0.5927\n",
      "Epoch 1809/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0000 - acc: 0.5971 - val_loss: 1.0360 - val_acc: 0.5921\n",
      "Epoch 1810/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9919 - acc: 0.6015 - val_loss: 1.0547 - val_acc: 0.5869\n",
      "Epoch 1811/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9986 - acc: 0.5965 - val_loss: 1.0512 - val_acc: 0.5840\n",
      "Epoch 1812/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0011 - acc: 0.5973 - val_loss: 1.0464 - val_acc: 0.5857\n",
      "Epoch 1813/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0049 - acc: 0.5971 - val_loss: 1.0421 - val_acc: 0.6028\n",
      "Epoch 1814/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9921 - acc: 0.6028 - val_loss: 1.0530 - val_acc: 0.5950\n",
      "Epoch 1815/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9928 - acc: 0.6002 - val_loss: 1.0481 - val_acc: 0.5898\n",
      "Epoch 1816/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9940 - acc: 0.6026 - val_loss: 1.0490 - val_acc: 0.5889\n",
      "Epoch 1817/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0043 - acc: 0.6003 - val_loss: 1.0456 - val_acc: 0.5985\n",
      "Epoch 1818/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9959 - acc: 0.6034 - val_loss: 1.0457 - val_acc: 0.5959\n",
      "Epoch 1819/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0004 - acc: 0.5951 - val_loss: 1.0475 - val_acc: 0.5886\n",
      "Epoch 1820/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0072 - acc: 0.5944 - val_loss: 1.0498 - val_acc: 0.5930\n",
      "Epoch 1821/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0091 - acc: 0.5959 - val_loss: 1.0462 - val_acc: 0.5959\n",
      "Epoch 1822/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9991 - acc: 0.5971 - val_loss: 1.0505 - val_acc: 0.5982\n",
      "Epoch 1823/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0040 - acc: 0.6002 - val_loss: 1.0652 - val_acc: 0.5805\n",
      "Epoch 1824/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0004 - acc: 0.5976 - val_loss: 1.0586 - val_acc: 0.5909\n",
      "Epoch 1825/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0070 - acc: 0.5972 - val_loss: 1.0610 - val_acc: 0.5837\n",
      "Epoch 1826/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0021 - acc: 0.5980 - val_loss: 1.0522 - val_acc: 0.5941\n",
      "Epoch 1827/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9961 - acc: 0.6010 - val_loss: 1.0449 - val_acc: 0.5901\n",
      "Epoch 1828/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0007 - acc: 0.6055 - val_loss: 1.0544 - val_acc: 0.5927\n",
      "Epoch 1829/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9883 - acc: 0.6060 - val_loss: 1.0384 - val_acc: 0.5953\n",
      "Epoch 1830/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9973 - acc: 0.5959 - val_loss: 1.0612 - val_acc: 0.5877\n",
      "Epoch 1831/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0001 - acc: 0.5995 - val_loss: 1.0571 - val_acc: 0.5808\n",
      "Epoch 1832/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0001 - acc: 0.6025 - val_loss: 1.0419 - val_acc: 0.5904\n",
      "Epoch 1833/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9990 - acc: 0.6033 - val_loss: 1.0381 - val_acc: 0.5938\n",
      "Epoch 1834/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9982 - acc: 0.5944 - val_loss: 1.0348 - val_acc: 0.5953\n",
      "Epoch 1835/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 1.0004 - acc: 0.5972 - val_loss: 1.0379 - val_acc: 0.5976\n",
      "Epoch 1836/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9939 - acc: 0.6026 - val_loss: 1.0472 - val_acc: 0.5909\n",
      "Epoch 1837/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9937 - acc: 0.6000 - val_loss: 1.0554 - val_acc: 0.5889\n",
      "Epoch 1838/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9934 - acc: 0.5984 - val_loss: 1.0381 - val_acc: 0.6002\n",
      "Epoch 1839/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 1.0091 - acc: 0.5910 - val_loss: 1.0429 - val_acc: 0.5959\n",
      "Epoch 1840/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9997 - acc: 0.5968 - val_loss: 1.0478 - val_acc: 0.5918\n",
      "Epoch 1841/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9985 - acc: 0.5986 - val_loss: 1.0412 - val_acc: 0.5904\n",
      "Epoch 1842/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0121 - acc: 0.5918 - val_loss: 1.0516 - val_acc: 0.5912\n",
      "Epoch 1843/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9996 - acc: 0.5949 - val_loss: 1.0415 - val_acc: 0.5869\n",
      "Epoch 1844/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 1.0117 - acc: 0.5917 - val_loss: 1.0665 - val_acc: 0.5819\n",
      "Epoch 1845/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 1.0013 - acc: 0.6010 - val_loss: 1.0620 - val_acc: 0.5843\n",
      "Epoch 1846/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 1.0028 - acc: 0.5961 - val_loss: 1.0514 - val_acc: 0.5918\n",
      "Epoch 1847/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9870 - acc: 0.6026 - val_loss: 1.0505 - val_acc: 0.5857\n",
      "Epoch 1848/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9960 - acc: 0.5994 - val_loss: 1.0457 - val_acc: 0.5933\n",
      "Epoch 1849/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0014 - acc: 0.5952 - val_loss: 1.0509 - val_acc: 0.5962\n",
      "Epoch 1850/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9954 - acc: 0.5988 - val_loss: 1.0592 - val_acc: 0.5921\n",
      "Epoch 1851/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9972 - acc: 0.5970 - val_loss: 1.0529 - val_acc: 0.5938\n",
      "Epoch 1852/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9980 - acc: 0.5933 - val_loss: 1.0377 - val_acc: 0.5962\n",
      "Epoch 1853/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0002 - acc: 0.5978 - val_loss: 1.0441 - val_acc: 0.5973\n",
      "Epoch 1854/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0131 - acc: 0.5928 - val_loss: 1.0452 - val_acc: 0.5883\n",
      "Epoch 1855/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9980 - acc: 0.6027 - val_loss: 1.0392 - val_acc: 0.5886\n",
      "Epoch 1856/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9933 - acc: 0.6016 - val_loss: 1.0413 - val_acc: 0.5988\n",
      "Epoch 1857/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9948 - acc: 0.6003 - val_loss: 1.0520 - val_acc: 0.5906\n",
      "Epoch 1858/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0009 - acc: 0.5987 - val_loss: 1.0543 - val_acc: 0.5889\n",
      "Epoch 1859/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0019 - acc: 0.5957 - val_loss: 1.0574 - val_acc: 0.5918\n",
      "Epoch 1860/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0006 - acc: 0.6042 - val_loss: 1.0377 - val_acc: 0.5927\n",
      "Epoch 1861/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9982 - acc: 0.5992 - val_loss: 1.0432 - val_acc: 0.5953\n",
      "Epoch 1862/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0028 - acc: 0.5925 - val_loss: 1.0502 - val_acc: 0.5959\n",
      "Epoch 1863/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0092 - acc: 0.5939 - val_loss: 1.0471 - val_acc: 0.5813\n",
      "Epoch 1864/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9893 - acc: 0.6027 - val_loss: 1.0373 - val_acc: 0.5904\n",
      "Epoch 1865/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9899 - acc: 0.5996 - val_loss: 1.0486 - val_acc: 0.5886\n",
      "Epoch 1866/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9949 - acc: 0.6010 - val_loss: 1.0521 - val_acc: 0.5825\n",
      "Epoch 1867/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9966 - acc: 0.5970 - val_loss: 1.0394 - val_acc: 0.5938\n",
      "Epoch 1868/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9935 - acc: 0.6012 - val_loss: 1.0346 - val_acc: 0.5959\n",
      "Epoch 1869/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9879 - acc: 0.6026 - val_loss: 1.0560 - val_acc: 0.5834\n",
      "Epoch 1870/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0025 - acc: 0.5988 - val_loss: 1.0349 - val_acc: 0.5950\n",
      "Epoch 1871/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9996 - acc: 0.5973 - val_loss: 1.0416 - val_acc: 0.5944\n",
      "Epoch 1872/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9879 - acc: 0.6023 - val_loss: 1.0343 - val_acc: 0.6002\n",
      "Epoch 1873/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9896 - acc: 0.6011 - val_loss: 1.0484 - val_acc: 0.5973\n",
      "Epoch 1874/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9984 - acc: 0.5992 - val_loss: 1.0573 - val_acc: 0.5819\n",
      "Epoch 1875/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9922 - acc: 0.6022 - val_loss: 1.0533 - val_acc: 0.5901\n",
      "Epoch 1876/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9968 - acc: 0.6000 - val_loss: 1.0431 - val_acc: 0.5938\n",
      "Epoch 1877/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9908 - acc: 0.6039 - val_loss: 1.0502 - val_acc: 0.5909\n",
      "Epoch 1878/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 1.0014 - acc: 0.5979 - val_loss: 1.0404 - val_acc: 0.5956\n",
      "Epoch 1879/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9954 - acc: 0.5990 - val_loss: 1.0558 - val_acc: 0.5912\n",
      "Epoch 1880/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0007 - acc: 0.5965 - val_loss: 1.0529 - val_acc: 0.6008\n",
      "Epoch 1881/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0000 - acc: 0.6002 - val_loss: 1.0327 - val_acc: 0.6002\n",
      "Epoch 1882/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0035 - acc: 0.6023 - val_loss: 1.0475 - val_acc: 0.5898\n",
      "Epoch 1883/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9985 - acc: 0.6010 - val_loss: 1.0443 - val_acc: 0.5912\n",
      "Epoch 1884/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 1.0002 - acc: 0.5990 - val_loss: 1.0357 - val_acc: 0.5965\n",
      "Epoch 1885/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9990 - acc: 0.6003 - val_loss: 1.0304 - val_acc: 0.5906\n",
      "Epoch 1886/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9972 - acc: 0.6039 - val_loss: 1.0478 - val_acc: 0.5956\n",
      "Epoch 1887/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9926 - acc: 0.5999 - val_loss: 1.0321 - val_acc: 0.6008\n",
      "Epoch 1888/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9880 - acc: 0.6048 - val_loss: 1.0429 - val_acc: 0.5973\n",
      "Epoch 1889/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9972 - acc: 0.5968 - val_loss: 1.0293 - val_acc: 0.5973\n",
      "Epoch 1890/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9996 - acc: 0.5984 - val_loss: 1.0406 - val_acc: 0.5909\n",
      "Epoch 1891/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9996 - acc: 0.6023 - val_loss: 1.0510 - val_acc: 0.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1892/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9976 - acc: 0.6022 - val_loss: 1.0465 - val_acc: 0.5904\n",
      "Epoch 1893/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9945 - acc: 0.5997 - val_loss: 1.0360 - val_acc: 0.5912\n",
      "Epoch 1894/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0097 - acc: 0.5969 - val_loss: 1.0524 - val_acc: 0.5901\n",
      "Epoch 1895/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0008 - acc: 0.5968 - val_loss: 1.0381 - val_acc: 0.5918\n",
      "Epoch 1896/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0029 - acc: 0.5992 - val_loss: 1.0449 - val_acc: 0.5898\n",
      "Epoch 1897/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9935 - acc: 0.6044 - val_loss: 1.0438 - val_acc: 0.5965\n",
      "Epoch 1898/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9940 - acc: 0.6031 - val_loss: 1.0425 - val_acc: 0.5822\n",
      "Epoch 1899/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0003 - acc: 0.5960 - val_loss: 1.0308 - val_acc: 0.5967\n",
      "Epoch 1900/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0072 - acc: 0.5941 - val_loss: 1.0362 - val_acc: 0.5985\n",
      "Epoch 1901/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9948 - acc: 0.6043 - val_loss: 1.0446 - val_acc: 0.5892\n",
      "Epoch 1902/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9911 - acc: 0.6028 - val_loss: 1.0405 - val_acc: 0.5921\n",
      "Epoch 1903/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 1.0014 - acc: 0.5968 - val_loss: 1.0370 - val_acc: 0.5936\n",
      "Epoch 1904/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9938 - acc: 0.6025 - val_loss: 1.0449 - val_acc: 0.5962\n",
      "Epoch 1905/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0015 - acc: 0.5961 - val_loss: 1.0533 - val_acc: 0.5933\n",
      "Epoch 1906/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9982 - acc: 0.5986 - val_loss: 1.0428 - val_acc: 0.6055\n",
      "Epoch 1907/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9855 - acc: 0.6052 - val_loss: 1.0664 - val_acc: 0.5886\n",
      "Epoch 1908/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9988 - acc: 0.6032 - val_loss: 1.0389 - val_acc: 0.6008\n",
      "Epoch 1909/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0019 - acc: 0.5939 - val_loss: 1.0439 - val_acc: 0.5991\n",
      "Epoch 1910/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0025 - acc: 0.5966 - val_loss: 1.0511 - val_acc: 0.5936\n",
      "Epoch 1911/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0032 - acc: 0.5973 - val_loss: 1.0404 - val_acc: 0.5930\n",
      "Epoch 1912/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9974 - acc: 0.5984 - val_loss: 1.0360 - val_acc: 0.6020\n",
      "Epoch 1913/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9894 - acc: 0.6007 - val_loss: 1.0447 - val_acc: 0.5973\n",
      "Epoch 1914/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0047 - acc: 0.5994 - val_loss: 1.0402 - val_acc: 0.6017\n",
      "Epoch 1915/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0014 - acc: 0.5969 - val_loss: 1.0488 - val_acc: 0.5941\n",
      "Epoch 1916/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9917 - acc: 0.5999 - val_loss: 1.0551 - val_acc: 0.5866\n",
      "Epoch 1917/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9940 - acc: 0.6042 - val_loss: 1.0426 - val_acc: 0.5985\n",
      "Epoch 1918/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9866 - acc: 0.6036 - val_loss: 1.0513 - val_acc: 0.5994\n",
      "Epoch 1919/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9933 - acc: 0.6044 - val_loss: 1.0386 - val_acc: 0.6014\n",
      "Epoch 1920/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9953 - acc: 0.5981 - val_loss: 1.0514 - val_acc: 0.5933\n",
      "Epoch 1921/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9978 - acc: 0.6020 - val_loss: 1.0361 - val_acc: 0.6008\n",
      "Epoch 1922/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9974 - acc: 0.6026 - val_loss: 1.0543 - val_acc: 0.5930\n",
      "Epoch 1923/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9907 - acc: 0.6024 - val_loss: 1.0384 - val_acc: 0.5947\n",
      "Epoch 1924/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9971 - acc: 0.6011 - val_loss: 1.0436 - val_acc: 0.5924\n",
      "Epoch 1925/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9910 - acc: 0.6008 - val_loss: 1.0564 - val_acc: 0.5860\n",
      "Epoch 1926/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9905 - acc: 0.6029 - val_loss: 1.0584 - val_acc: 0.5886\n",
      "Epoch 1927/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9951 - acc: 0.6027 - val_loss: 1.0482 - val_acc: 0.5979\n",
      "Epoch 1928/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9981 - acc: 0.5989 - val_loss: 1.0361 - val_acc: 0.5976\n",
      "Epoch 1929/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9862 - acc: 0.6106 - val_loss: 1.0388 - val_acc: 0.5976\n",
      "Epoch 1930/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9915 - acc: 0.6007 - val_loss: 1.0442 - val_acc: 0.5956\n",
      "Epoch 1931/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 1.0014 - acc: 0.6018 - val_loss: 1.0439 - val_acc: 0.5912\n",
      "Epoch 1932/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9888 - acc: 0.6046 - val_loss: 1.0448 - val_acc: 0.5933\n",
      "Epoch 1933/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9994 - acc: 0.6045 - val_loss: 1.0404 - val_acc: 0.5933\n",
      "Epoch 1934/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9942 - acc: 0.6005 - val_loss: 1.0434 - val_acc: 0.5944\n",
      "Epoch 1935/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9959 - acc: 0.5988 - val_loss: 1.0487 - val_acc: 0.5967\n",
      "Epoch 1936/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9943 - acc: 0.6018 - val_loss: 1.0454 - val_acc: 0.5944\n",
      "Epoch 1937/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9955 - acc: 0.6016 - val_loss: 1.0424 - val_acc: 0.5889\n",
      "Epoch 1938/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9939 - acc: 0.6029 - val_loss: 1.0427 - val_acc: 0.5883\n",
      "Epoch 1939/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9984 - acc: 0.5990 - val_loss: 1.0466 - val_acc: 0.5906\n",
      "Epoch 1940/3000\n",
      "13766/13766 [==============================] - 1s 88us/step - loss: 0.9949 - acc: 0.6032 - val_loss: 1.0409 - val_acc: 0.5970\n",
      "Epoch 1941/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9995 - acc: 0.6035 - val_loss: 1.0303 - val_acc: 0.5962\n",
      "Epoch 1942/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9979 - acc: 0.6006 - val_loss: 1.0452 - val_acc: 0.5936\n",
      "Epoch 1943/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9984 - acc: 0.5991 - val_loss: 1.0343 - val_acc: 0.5915\n",
      "Epoch 1944/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9995 - acc: 0.6022 - val_loss: 1.0551 - val_acc: 0.5924\n",
      "Epoch 1945/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0075 - acc: 0.5982 - val_loss: 1.0524 - val_acc: 0.5909\n",
      "Epoch 1946/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9973 - acc: 0.5978 - val_loss: 1.0376 - val_acc: 0.6037\n",
      "Epoch 1947/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0011 - acc: 0.6020 - val_loss: 1.0561 - val_acc: 0.5924\n",
      "Epoch 1948/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0098 - acc: 0.5960 - val_loss: 1.0441 - val_acc: 0.5956\n",
      "Epoch 1949/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9872 - acc: 0.6062 - val_loss: 1.0451 - val_acc: 0.5938\n",
      "Epoch 1950/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9916 - acc: 0.6056 - val_loss: 1.0419 - val_acc: 0.5944\n",
      "Epoch 1951/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9911 - acc: 0.6006 - val_loss: 1.0366 - val_acc: 0.6034\n",
      "Epoch 1952/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0022 - acc: 0.5961 - val_loss: 1.0447 - val_acc: 0.5933\n",
      "Epoch 1953/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9981 - acc: 0.6042 - val_loss: 1.0421 - val_acc: 0.5985\n",
      "Epoch 1954/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9972 - acc: 0.6035 - val_loss: 1.0390 - val_acc: 0.5970\n",
      "Epoch 1955/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9950 - acc: 0.6013 - val_loss: 1.0406 - val_acc: 0.5936\n",
      "Epoch 1956/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9885 - acc: 0.6018 - val_loss: 1.0429 - val_acc: 0.5979\n",
      "Epoch 1957/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9936 - acc: 0.5976 - val_loss: 1.0397 - val_acc: 0.5994\n",
      "Epoch 1958/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 0.9775 - acc: 0.6103 - val_loss: 1.0345 - val_acc: 0.6046\n",
      "Epoch 1959/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9949 - acc: 0.6038 - val_loss: 1.0386 - val_acc: 0.5991\n",
      "Epoch 1960/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9988 - acc: 0.5998 - val_loss: 1.0348 - val_acc: 0.5973\n",
      "Epoch 1961/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9906 - acc: 0.6029 - val_loss: 1.0393 - val_acc: 0.5959\n",
      "Epoch 1962/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9995 - acc: 0.6040 - val_loss: 1.0456 - val_acc: 0.5936\n",
      "Epoch 1963/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9921 - acc: 0.6034 - val_loss: 1.0532 - val_acc: 0.5927\n",
      "Epoch 1964/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 1.0043 - acc: 0.5973 - val_loss: 1.0809 - val_acc: 0.5863\n",
      "Epoch 1965/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9954 - acc: 0.6027 - val_loss: 1.0415 - val_acc: 0.5909\n",
      "Epoch 1966/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9939 - acc: 0.6021 - val_loss: 1.0451 - val_acc: 0.5857\n",
      "Epoch 1967/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9857 - acc: 0.6004 - val_loss: 1.0431 - val_acc: 0.5970\n",
      "Epoch 1968/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9885 - acc: 0.6051 - val_loss: 1.0482 - val_acc: 0.5959\n",
      "Epoch 1969/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9937 - acc: 0.6074 - val_loss: 1.0416 - val_acc: 0.5927\n",
      "Epoch 1970/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9932 - acc: 0.6029 - val_loss: 1.0275 - val_acc: 0.5947\n",
      "Epoch 1971/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0092 - acc: 0.5961 - val_loss: 1.0406 - val_acc: 0.5959\n",
      "Epoch 1972/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9893 - acc: 0.6037 - val_loss: 1.0332 - val_acc: 0.5988\n",
      "Epoch 1973/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9784 - acc: 0.6098 - val_loss: 1.0339 - val_acc: 0.5976\n",
      "Epoch 1974/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9828 - acc: 0.6032 - val_loss: 1.0442 - val_acc: 0.5927\n",
      "Epoch 1975/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9945 - acc: 0.6039 - val_loss: 1.0423 - val_acc: 0.5991\n",
      "Epoch 1976/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9994 - acc: 0.6027 - val_loss: 1.0463 - val_acc: 0.5877\n",
      "Epoch 1977/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9906 - acc: 0.6067 - val_loss: 1.0373 - val_acc: 0.5904\n",
      "Epoch 1978/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9950 - acc: 0.6027 - val_loss: 1.0532 - val_acc: 0.5915\n",
      "Epoch 1979/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9908 - acc: 0.6066 - val_loss: 1.0339 - val_acc: 0.5991\n",
      "Epoch 1980/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9924 - acc: 0.6046 - val_loss: 1.0552 - val_acc: 0.5979\n",
      "Epoch 1981/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9981 - acc: 0.5993 - val_loss: 1.0645 - val_acc: 0.5843\n",
      "Epoch 1982/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9931 - acc: 0.6041 - val_loss: 1.0382 - val_acc: 0.5965\n",
      "Epoch 1983/3000\n",
      "13766/13766 [==============================] - 1s 62us/step - loss: 0.9959 - acc: 0.5972 - val_loss: 1.0531 - val_acc: 0.5874\n",
      "Epoch 1984/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9864 - acc: 0.6075 - val_loss: 1.0373 - val_acc: 0.6002\n",
      "Epoch 1985/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9973 - acc: 0.6005 - val_loss: 1.0492 - val_acc: 0.5950\n",
      "Epoch 1986/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9987 - acc: 0.6002 - val_loss: 1.0313 - val_acc: 0.6092\n",
      "Epoch 1987/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9923 - acc: 0.6007 - val_loss: 1.0401 - val_acc: 0.5950\n",
      "Epoch 1988/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9841 - acc: 0.6063 - val_loss: 1.0415 - val_acc: 0.5967\n",
      "Epoch 1989/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9913 - acc: 0.6013 - val_loss: 1.0353 - val_acc: 0.5933\n",
      "Epoch 1990/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9978 - acc: 0.6050 - val_loss: 1.0318 - val_acc: 0.6011\n",
      "Epoch 1991/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9887 - acc: 0.6064 - val_loss: 1.0302 - val_acc: 0.6026\n",
      "Epoch 1992/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9919 - acc: 0.6024 - val_loss: 1.0489 - val_acc: 0.5912\n",
      "Epoch 1993/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9907 - acc: 0.6019 - val_loss: 1.0386 - val_acc: 0.5933\n",
      "Epoch 1994/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9834 - acc: 0.6033 - val_loss: 1.0375 - val_acc: 0.5967\n",
      "Epoch 1995/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9869 - acc: 0.6057 - val_loss: 1.0346 - val_acc: 0.5918\n",
      "Epoch 1996/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9937 - acc: 0.6002 - val_loss: 1.0311 - val_acc: 0.5970\n",
      "Epoch 1997/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9855 - acc: 0.6101 - val_loss: 1.0355 - val_acc: 0.5991\n",
      "Epoch 1998/3000\n",
      "13766/13766 [==============================] - 1s 64us/step - loss: 0.9936 - acc: 0.5995 - val_loss: 1.0436 - val_acc: 0.5982\n",
      "Epoch 1999/3000\n",
      "13766/13766 [==============================] - 1s 64us/step - loss: 0.9944 - acc: 0.5997 - val_loss: 1.0482 - val_acc: 0.6023\n",
      "Epoch 2000/3000\n",
      "13766/13766 [==============================] - 1s 62us/step - loss: 0.9849 - acc: 0.6034 - val_loss: 1.0401 - val_acc: 0.6034\n",
      "Epoch 2001/3000\n",
      "13766/13766 [==============================] - 1s 75us/step - loss: 0.9983 - acc: 0.6013 - val_loss: 1.0543 - val_acc: 0.5904\n",
      "Epoch 2002/3000\n",
      "13766/13766 [==============================] - 1s 70us/step - loss: 0.9949 - acc: 0.6021 - val_loss: 1.0265 - val_acc: 0.5965\n",
      "Epoch 2003/3000\n",
      "13766/13766 [==============================] - 1s 69us/step - loss: 0.9912 - acc: 0.6075 - val_loss: 1.0426 - val_acc: 0.5967\n",
      "Epoch 2004/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 0.9887 - acc: 0.6058 - val_loss: 1.0532 - val_acc: 0.5828\n",
      "Epoch 2005/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 0.9977 - acc: 0.5984 - val_loss: 1.0426 - val_acc: 0.5883\n",
      "Epoch 2006/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 1.0035 - acc: 0.6032 - val_loss: 1.0405 - val_acc: 0.5991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2007/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9864 - acc: 0.6086 - val_loss: 1.0388 - val_acc: 0.5962\n",
      "Epoch 2008/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9971 - acc: 0.5999 - val_loss: 1.0450 - val_acc: 0.5909\n",
      "Epoch 2009/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9862 - acc: 0.6020 - val_loss: 1.0340 - val_acc: 0.5918\n",
      "Epoch 2010/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9864 - acc: 0.6028 - val_loss: 1.0462 - val_acc: 0.5845\n",
      "Epoch 2011/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 0.9950 - acc: 0.6015 - val_loss: 1.0371 - val_acc: 0.5965\n",
      "Epoch 2012/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 1.0008 - acc: 0.5953 - val_loss: 1.0312 - val_acc: 0.5936\n",
      "Epoch 2013/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9878 - acc: 0.6058 - val_loss: 1.0467 - val_acc: 0.5872\n",
      "Epoch 2014/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9938 - acc: 0.6019 - val_loss: 1.0323 - val_acc: 0.5991\n",
      "Epoch 2015/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9904 - acc: 0.6018 - val_loss: 1.0288 - val_acc: 0.5973\n",
      "Epoch 2016/3000\n",
      "13766/13766 [==============================] - 1s 62us/step - loss: 0.9920 - acc: 0.6020 - val_loss: 1.0270 - val_acc: 0.6011\n",
      "Epoch 2017/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9854 - acc: 0.6000 - val_loss: 1.0504 - val_acc: 0.5915\n",
      "Epoch 2018/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9936 - acc: 0.5981 - val_loss: 1.0382 - val_acc: 0.5967\n",
      "Epoch 2019/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9860 - acc: 0.6037 - val_loss: 1.0439 - val_acc: 0.5930\n",
      "Epoch 2020/3000\n",
      "13766/13766 [==============================] - 1s 68us/step - loss: 0.9895 - acc: 0.6027 - val_loss: 1.0456 - val_acc: 0.5994\n",
      "Epoch 2021/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9964 - acc: 0.6029 - val_loss: 1.0628 - val_acc: 0.5825\n",
      "Epoch 2022/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9954 - acc: 0.6029 - val_loss: 1.0444 - val_acc: 0.5892\n",
      "Epoch 2023/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9950 - acc: 0.6016 - val_loss: 1.0700 - val_acc: 0.5837\n",
      "Epoch 2024/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9915 - acc: 0.6038 - val_loss: 1.0355 - val_acc: 0.5985\n",
      "Epoch 2025/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9920 - acc: 0.6036 - val_loss: 1.0396 - val_acc: 0.5962\n",
      "Epoch 2026/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9965 - acc: 0.5984 - val_loss: 1.0290 - val_acc: 0.5927\n",
      "Epoch 2027/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9981 - acc: 0.5964 - val_loss: 1.0690 - val_acc: 0.5784\n",
      "Epoch 2028/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9954 - acc: 0.6010 - val_loss: 1.0498 - val_acc: 0.5944\n",
      "Epoch 2029/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9733 - acc: 0.6115 - val_loss: 1.0516 - val_acc: 0.5959\n",
      "Epoch 2030/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9878 - acc: 0.6029 - val_loss: 1.0354 - val_acc: 0.6005\n",
      "Epoch 2031/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9964 - acc: 0.6010 - val_loss: 1.0453 - val_acc: 0.5936\n",
      "Epoch 2032/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9864 - acc: 0.6049 - val_loss: 1.0441 - val_acc: 0.5947\n",
      "Epoch 2033/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9895 - acc: 0.6024 - val_loss: 1.0499 - val_acc: 0.5895\n",
      "Epoch 2034/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9859 - acc: 0.6038 - val_loss: 1.0504 - val_acc: 0.6014\n",
      "Epoch 2035/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 0.9816 - acc: 0.6055 - val_loss: 1.0372 - val_acc: 0.5930\n",
      "Epoch 2036/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 0.9871 - acc: 0.6029 - val_loss: 1.0408 - val_acc: 0.5898\n",
      "Epoch 2037/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9910 - acc: 0.6022 - val_loss: 1.0499 - val_acc: 0.5904\n",
      "Epoch 2038/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9974 - acc: 0.6015 - val_loss: 1.0589 - val_acc: 0.5889\n",
      "Epoch 2039/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9948 - acc: 0.6038 - val_loss: 1.0512 - val_acc: 0.5962\n",
      "Epoch 2040/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9989 - acc: 0.6030 - val_loss: 1.0424 - val_acc: 0.5909\n",
      "Epoch 2041/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9867 - acc: 0.6026 - val_loss: 1.0580 - val_acc: 0.5944\n",
      "Epoch 2042/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9926 - acc: 0.6021 - val_loss: 1.0300 - val_acc: 0.6046\n",
      "Epoch 2043/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9998 - acc: 0.5994 - val_loss: 1.0403 - val_acc: 0.5979\n",
      "Epoch 2044/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9944 - acc: 0.5992 - val_loss: 1.0392 - val_acc: 0.5947\n",
      "Epoch 2045/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9852 - acc: 0.6016 - val_loss: 1.0585 - val_acc: 0.5918\n",
      "Epoch 2046/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9958 - acc: 0.5985 - val_loss: 1.0437 - val_acc: 0.5976\n",
      "Epoch 2047/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9896 - acc: 0.6014 - val_loss: 1.0507 - val_acc: 0.5924\n",
      "Epoch 2048/3000\n",
      "13766/13766 [==============================] - 1s 64us/step - loss: 0.9898 - acc: 0.6041 - val_loss: 1.0387 - val_acc: 0.6026\n",
      "Epoch 2049/3000\n",
      "13766/13766 [==============================] - 1s 62us/step - loss: 1.0055 - acc: 0.5978 - val_loss: 1.0660 - val_acc: 0.5877\n",
      "Epoch 2050/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 0.9985 - acc: 0.5973 - val_loss: 1.0406 - val_acc: 0.5921\n",
      "Epoch 2051/3000\n",
      "13766/13766 [==============================] - 1s 70us/step - loss: 0.9910 - acc: 0.6045 - val_loss: 1.0347 - val_acc: 0.5994\n",
      "Epoch 2052/3000\n",
      "13766/13766 [==============================] - 1s 70us/step - loss: 1.0002 - acc: 0.6005 - val_loss: 1.0486 - val_acc: 0.5976\n",
      "Epoch 2053/3000\n",
      "13766/13766 [==============================] - 1s 62us/step - loss: 0.9971 - acc: 0.6032 - val_loss: 1.0508 - val_acc: 0.5886\n",
      "Epoch 2054/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9937 - acc: 0.6038 - val_loss: 1.0316 - val_acc: 0.5956\n",
      "Epoch 2055/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9911 - acc: 0.6016 - val_loss: 1.0481 - val_acc: 0.5933\n",
      "Epoch 2056/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9972 - acc: 0.6023 - val_loss: 1.0511 - val_acc: 0.5947\n",
      "Epoch 2057/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9972 - acc: 0.6033 - val_loss: 1.0461 - val_acc: 0.5927\n",
      "Epoch 2058/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 1.0026 - acc: 0.5997 - val_loss: 1.0485 - val_acc: 0.5906\n",
      "Epoch 2059/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9852 - acc: 0.6043 - val_loss: 1.0457 - val_acc: 0.5947\n",
      "Epoch 2060/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9967 - acc: 0.6059 - val_loss: 1.0683 - val_acc: 0.5828\n",
      "Epoch 2061/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9899 - acc: 0.6042 - val_loss: 1.0336 - val_acc: 0.6023\n",
      "Epoch 2062/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9980 - acc: 0.5960 - val_loss: 1.0512 - val_acc: 0.5936\n",
      "Epoch 2063/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9970 - acc: 0.6013 - val_loss: 1.0444 - val_acc: 0.5915\n",
      "Epoch 2064/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9911 - acc: 0.6020 - val_loss: 1.0371 - val_acc: 0.6002\n",
      "Epoch 2065/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9840 - acc: 0.6057 - val_loss: 1.0512 - val_acc: 0.5924\n",
      "Epoch 2066/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 1.0034 - acc: 0.6002 - val_loss: 1.0469 - val_acc: 0.5892\n",
      "Epoch 2067/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9959 - acc: 0.5968 - val_loss: 1.0375 - val_acc: 0.5979\n",
      "Epoch 2068/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9978 - acc: 0.6007 - val_loss: 1.0417 - val_acc: 0.5930\n",
      "Epoch 2069/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9908 - acc: 0.6030 - val_loss: 1.0262 - val_acc: 0.6002\n",
      "Epoch 2070/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9931 - acc: 0.6013 - val_loss: 1.0427 - val_acc: 0.5985\n",
      "Epoch 2071/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9931 - acc: 0.6049 - val_loss: 1.0367 - val_acc: 0.5982\n",
      "Epoch 2072/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9833 - acc: 0.6051 - val_loss: 1.0428 - val_acc: 0.5950\n",
      "Epoch 2073/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9982 - acc: 0.5975 - val_loss: 1.0454 - val_acc: 0.5886\n",
      "Epoch 2074/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9874 - acc: 0.6024 - val_loss: 1.0373 - val_acc: 0.5947\n",
      "Epoch 2075/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0106 - acc: 0.5949 - val_loss: 1.0546 - val_acc: 0.5877\n",
      "Epoch 2076/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0110 - acc: 0.5971 - val_loss: 1.0480 - val_acc: 0.5886\n",
      "Epoch 2077/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9888 - acc: 0.6028 - val_loss: 1.0397 - val_acc: 0.5988\n",
      "Epoch 2078/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 1.0021 - acc: 0.5963 - val_loss: 1.0553 - val_acc: 0.5851\n",
      "Epoch 2079/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9892 - acc: 0.6036 - val_loss: 1.0569 - val_acc: 0.5874\n",
      "Epoch 2080/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9888 - acc: 0.6013 - val_loss: 1.0537 - val_acc: 0.5909\n",
      "Epoch 2081/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9996 - acc: 0.5987 - val_loss: 1.0520 - val_acc: 0.5837\n",
      "Epoch 2082/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9819 - acc: 0.6041 - val_loss: 1.0464 - val_acc: 0.5927\n",
      "Epoch 2083/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9947 - acc: 0.6026 - val_loss: 1.0355 - val_acc: 0.6049\n",
      "Epoch 2084/3000\n",
      "13766/13766 [==============================] - 1s 68us/step - loss: 0.9935 - acc: 0.6009 - val_loss: 1.0305 - val_acc: 0.6060\n",
      "Epoch 2085/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9949 - acc: 0.6013 - val_loss: 1.0494 - val_acc: 0.5918\n",
      "Epoch 2086/3000\n",
      "13766/13766 [==============================] - 1s 64us/step - loss: 0.9910 - acc: 0.6013 - val_loss: 1.0448 - val_acc: 0.5994\n",
      "Epoch 2087/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9907 - acc: 0.6034 - val_loss: 1.0449 - val_acc: 0.5959\n",
      "Epoch 2088/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9916 - acc: 0.6006 - val_loss: 1.0422 - val_acc: 0.5965\n",
      "Epoch 2089/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9836 - acc: 0.6051 - val_loss: 1.0409 - val_acc: 0.6023\n",
      "Epoch 2090/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9799 - acc: 0.6058 - val_loss: 1.0405 - val_acc: 0.5941\n",
      "Epoch 2091/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9965 - acc: 0.6029 - val_loss: 1.0471 - val_acc: 0.5944\n",
      "Epoch 2092/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9977 - acc: 0.6042 - val_loss: 1.0531 - val_acc: 0.5947\n",
      "Epoch 2093/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9829 - acc: 0.6075 - val_loss: 1.0358 - val_acc: 0.6020\n",
      "Epoch 2094/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9920 - acc: 0.6047 - val_loss: 1.0497 - val_acc: 0.5956\n",
      "Epoch 2095/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9868 - acc: 0.6048 - val_loss: 1.0458 - val_acc: 0.5970\n",
      "Epoch 2096/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9882 - acc: 0.6059 - val_loss: 1.0454 - val_acc: 0.5956\n",
      "Epoch 2097/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9889 - acc: 0.6045 - val_loss: 1.0480 - val_acc: 0.5904\n",
      "Epoch 2098/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9944 - acc: 0.5977 - val_loss: 1.0433 - val_acc: 0.5985\n",
      "Epoch 2099/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9891 - acc: 0.6089 - val_loss: 1.0464 - val_acc: 0.5938\n",
      "Epoch 2100/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9955 - acc: 0.5994 - val_loss: 1.0399 - val_acc: 0.5976\n",
      "Epoch 2101/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9986 - acc: 0.6017 - val_loss: 1.0368 - val_acc: 0.5901\n",
      "Epoch 2102/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9982 - acc: 0.6040 - val_loss: 1.0295 - val_acc: 0.5982\n",
      "Epoch 2103/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9910 - acc: 0.6060 - val_loss: 1.0373 - val_acc: 0.6014\n",
      "Epoch 2104/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9940 - acc: 0.6026 - val_loss: 1.0407 - val_acc: 0.6023\n",
      "Epoch 2105/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9821 - acc: 0.6079 - val_loss: 1.0344 - val_acc: 0.6055\n",
      "Epoch 2106/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9908 - acc: 0.5991 - val_loss: 1.0407 - val_acc: 0.5999\n",
      "Epoch 2107/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9907 - acc: 0.6005 - val_loss: 1.0358 - val_acc: 0.5904\n",
      "Epoch 2108/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 1.0061 - acc: 0.5935 - val_loss: 1.0410 - val_acc: 0.5912\n",
      "Epoch 2109/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9961 - acc: 0.6028 - val_loss: 1.0340 - val_acc: 0.6028\n",
      "Epoch 2110/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9966 - acc: 0.5990 - val_loss: 1.0403 - val_acc: 0.5979\n",
      "Epoch 2111/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9965 - acc: 0.6042 - val_loss: 1.0472 - val_acc: 0.5936\n",
      "Epoch 2112/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9927 - acc: 0.6011 - val_loss: 1.0381 - val_acc: 0.5973\n",
      "Epoch 2113/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9933 - acc: 0.6052 - val_loss: 1.0368 - val_acc: 0.5985\n",
      "Epoch 2114/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 1.0013 - acc: 0.5968 - val_loss: 1.0356 - val_acc: 0.5912\n",
      "Epoch 2115/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9857 - acc: 0.6090 - val_loss: 1.0401 - val_acc: 0.6011\n",
      "Epoch 2116/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9984 - acc: 0.6019 - val_loss: 1.0453 - val_acc: 0.5936\n",
      "Epoch 2117/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9891 - acc: 0.6055 - val_loss: 1.0386 - val_acc: 0.5950\n",
      "Epoch 2118/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9826 - acc: 0.6035 - val_loss: 1.0626 - val_acc: 0.5895\n",
      "Epoch 2119/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9912 - acc: 0.6041 - val_loss: 1.0462 - val_acc: 0.5959\n",
      "Epoch 2120/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9928 - acc: 0.6024 - val_loss: 1.0391 - val_acc: 0.6052\n",
      "Epoch 2121/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9967 - acc: 0.5994 - val_loss: 1.0522 - val_acc: 0.5924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2122/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9861 - acc: 0.6016 - val_loss: 1.0368 - val_acc: 0.6005\n",
      "Epoch 2123/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9997 - acc: 0.6030 - val_loss: 1.0437 - val_acc: 0.6002\n",
      "Epoch 2124/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9864 - acc: 0.6066 - val_loss: 1.0413 - val_acc: 0.5912\n",
      "Epoch 2125/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9976 - acc: 0.5992 - val_loss: 1.0381 - val_acc: 0.5866\n",
      "Epoch 2126/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9889 - acc: 0.5984 - val_loss: 1.0575 - val_acc: 0.5845\n",
      "Epoch 2127/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9832 - acc: 0.6086 - val_loss: 1.0547 - val_acc: 0.5930\n",
      "Epoch 2128/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9775 - acc: 0.6066 - val_loss: 1.0312 - val_acc: 0.5944\n",
      "Epoch 2129/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9882 - acc: 0.6055 - val_loss: 1.0429 - val_acc: 0.5973\n",
      "Epoch 2130/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9906 - acc: 0.6071 - val_loss: 1.0385 - val_acc: 0.5927\n",
      "Epoch 2131/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9862 - acc: 0.6050 - val_loss: 1.0450 - val_acc: 0.5921\n",
      "Epoch 2132/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9760 - acc: 0.6096 - val_loss: 1.0404 - val_acc: 0.6014\n",
      "Epoch 2133/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9886 - acc: 0.6053 - val_loss: 1.0351 - val_acc: 0.5912\n",
      "Epoch 2134/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9940 - acc: 0.6066 - val_loss: 1.0408 - val_acc: 0.5962\n",
      "Epoch 2135/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9896 - acc: 0.6025 - val_loss: 1.0336 - val_acc: 0.5959\n",
      "Epoch 2136/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9820 - acc: 0.6093 - val_loss: 1.0294 - val_acc: 0.5950\n",
      "Epoch 2137/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9872 - acc: 0.6102 - val_loss: 1.0310 - val_acc: 0.5921\n",
      "Epoch 2138/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9906 - acc: 0.6055 - val_loss: 1.0321 - val_acc: 0.5941\n",
      "Epoch 2139/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9954 - acc: 0.6006 - val_loss: 1.0308 - val_acc: 0.5944\n",
      "Epoch 2140/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9851 - acc: 0.6045 - val_loss: 1.0325 - val_acc: 0.5985\n",
      "Epoch 2141/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9960 - acc: 0.6071 - val_loss: 1.0374 - val_acc: 0.5941\n",
      "Epoch 2142/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9929 - acc: 0.6005 - val_loss: 1.0446 - val_acc: 0.5941\n",
      "Epoch 2143/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9782 - acc: 0.6084 - val_loss: 1.0435 - val_acc: 0.5880\n",
      "Epoch 2144/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9981 - acc: 0.6013 - val_loss: 1.0462 - val_acc: 0.5947\n",
      "Epoch 2145/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9934 - acc: 0.6003 - val_loss: 1.0396 - val_acc: 0.5944\n",
      "Epoch 2146/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9901 - acc: 0.6070 - val_loss: 1.0385 - val_acc: 0.5927\n",
      "Epoch 2147/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9839 - acc: 0.6046 - val_loss: 1.0505 - val_acc: 0.5872\n",
      "Epoch 2148/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9892 - acc: 0.6012 - val_loss: 1.0441 - val_acc: 0.5857\n",
      "Epoch 2149/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9898 - acc: 0.6047 - val_loss: 1.0349 - val_acc: 0.5985\n",
      "Epoch 2150/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9834 - acc: 0.6069 - val_loss: 1.0365 - val_acc: 0.5933\n",
      "Epoch 2151/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9953 - acc: 0.6027 - val_loss: 1.0444 - val_acc: 0.6005\n",
      "Epoch 2152/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9954 - acc: 0.5987 - val_loss: 1.0330 - val_acc: 0.5985\n",
      "Epoch 2153/3000\n",
      "13766/13766 [==============================] - 1s 73us/step - loss: 0.9977 - acc: 0.6013 - val_loss: 1.0413 - val_acc: 0.5921\n",
      "Epoch 2154/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9853 - acc: 0.6005 - val_loss: 1.0332 - val_acc: 0.6005\n",
      "Epoch 2155/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9919 - acc: 0.6004 - val_loss: 1.0396 - val_acc: 0.5982\n",
      "Epoch 2156/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9971 - acc: 0.6010 - val_loss: 1.0401 - val_acc: 0.5979\n",
      "Epoch 2157/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9902 - acc: 0.6034 - val_loss: 1.0449 - val_acc: 0.5924\n",
      "Epoch 2158/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9861 - acc: 0.6032 - val_loss: 1.0397 - val_acc: 0.5941\n",
      "Epoch 2159/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9825 - acc: 0.6078 - val_loss: 1.0470 - val_acc: 0.5837\n",
      "Epoch 2160/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9922 - acc: 0.6015 - val_loss: 1.0563 - val_acc: 0.5802\n",
      "Epoch 2161/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9956 - acc: 0.6090 - val_loss: 1.0369 - val_acc: 0.5962\n",
      "Epoch 2162/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9848 - acc: 0.6042 - val_loss: 1.0340 - val_acc: 0.6020\n",
      "Epoch 2163/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9894 - acc: 0.6040 - val_loss: 1.0351 - val_acc: 0.5973\n",
      "Epoch 2164/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9824 - acc: 0.6081 - val_loss: 1.0269 - val_acc: 0.6037\n",
      "Epoch 2165/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9939 - acc: 0.6013 - val_loss: 1.0408 - val_acc: 0.5965\n",
      "Epoch 2166/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9855 - acc: 0.6045 - val_loss: 1.0526 - val_acc: 0.5889\n",
      "Epoch 2167/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 1.0041 - acc: 0.5943 - val_loss: 1.0440 - val_acc: 0.5860\n",
      "Epoch 2168/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9922 - acc: 0.5996 - val_loss: 1.0448 - val_acc: 0.5965\n",
      "Epoch 2169/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9789 - acc: 0.6096 - val_loss: 1.0379 - val_acc: 0.5959\n",
      "Epoch 2170/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9870 - acc: 0.6058 - val_loss: 1.0468 - val_acc: 0.5979\n",
      "Epoch 2171/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9826 - acc: 0.6065 - val_loss: 1.0504 - val_acc: 0.5915\n",
      "Epoch 2172/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9858 - acc: 0.6057 - val_loss: 1.0464 - val_acc: 0.5936\n",
      "Epoch 2173/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9864 - acc: 0.6055 - val_loss: 1.0575 - val_acc: 0.5874\n",
      "Epoch 2174/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9892 - acc: 0.6097 - val_loss: 1.0440 - val_acc: 0.5906\n",
      "Epoch 2175/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9921 - acc: 0.6058 - val_loss: 1.0330 - val_acc: 0.5976\n",
      "Epoch 2176/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9844 - acc: 0.6005 - val_loss: 1.0371 - val_acc: 0.5924\n",
      "Epoch 2177/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9779 - acc: 0.6063 - val_loss: 1.0239 - val_acc: 0.6002\n",
      "Epoch 2178/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9893 - acc: 0.6077 - val_loss: 1.0426 - val_acc: 0.5985\n",
      "Epoch 2179/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9879 - acc: 0.6042 - val_loss: 1.0499 - val_acc: 0.5915\n",
      "Epoch 2180/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9892 - acc: 0.6013 - val_loss: 1.0341 - val_acc: 0.5915\n",
      "Epoch 2181/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9816 - acc: 0.6058 - val_loss: 1.0239 - val_acc: 0.5999\n",
      "Epoch 2182/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9849 - acc: 0.6042 - val_loss: 1.0383 - val_acc: 0.5930\n",
      "Epoch 2183/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9852 - acc: 0.6081 - val_loss: 1.0452 - val_acc: 0.5941\n",
      "Epoch 2184/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9908 - acc: 0.6057 - val_loss: 1.0353 - val_acc: 0.5927\n",
      "Epoch 2185/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9925 - acc: 0.6029 - val_loss: 1.0416 - val_acc: 0.5956\n",
      "Epoch 2186/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9926 - acc: 0.6048 - val_loss: 1.0426 - val_acc: 0.5895\n",
      "Epoch 2187/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 1.0040 - acc: 0.6008 - val_loss: 1.0397 - val_acc: 0.5956\n",
      "Epoch 2188/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9922 - acc: 0.6000 - val_loss: 1.0373 - val_acc: 0.5944\n",
      "Epoch 2189/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9874 - acc: 0.6048 - val_loss: 1.0372 - val_acc: 0.5936\n",
      "Epoch 2190/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9813 - acc: 0.6076 - val_loss: 1.0372 - val_acc: 0.5991\n",
      "Epoch 2191/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9851 - acc: 0.6093 - val_loss: 1.0522 - val_acc: 0.5965\n",
      "Epoch 2192/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9885 - acc: 0.6073 - val_loss: 1.0439 - val_acc: 0.5970\n",
      "Epoch 2193/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9939 - acc: 0.6007 - val_loss: 1.0364 - val_acc: 0.5918\n",
      "Epoch 2194/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9874 - acc: 0.6077 - val_loss: 1.0396 - val_acc: 0.5982\n",
      "Epoch 2195/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9867 - acc: 0.6085 - val_loss: 1.0326 - val_acc: 0.5979\n",
      "Epoch 2196/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9896 - acc: 0.6043 - val_loss: 1.0592 - val_acc: 0.5793\n",
      "Epoch 2197/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9970 - acc: 0.6057 - val_loss: 1.0468 - val_acc: 0.5851\n",
      "Epoch 2198/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9868 - acc: 0.6086 - val_loss: 1.0325 - val_acc: 0.5904\n",
      "Epoch 2199/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9875 - acc: 0.6049 - val_loss: 1.0403 - val_acc: 0.5944\n",
      "Epoch 2200/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9819 - acc: 0.6059 - val_loss: 1.0389 - val_acc: 0.5956\n",
      "Epoch 2201/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9886 - acc: 0.6035 - val_loss: 1.0488 - val_acc: 0.5895\n",
      "Epoch 2202/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9896 - acc: 0.6082 - val_loss: 1.0383 - val_acc: 0.6005\n",
      "Epoch 2203/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9867 - acc: 0.6103 - val_loss: 1.0494 - val_acc: 0.5938\n",
      "Epoch 2204/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9805 - acc: 0.6074 - val_loss: 1.0447 - val_acc: 0.5985\n",
      "Epoch 2205/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9770 - acc: 0.6102 - val_loss: 1.0484 - val_acc: 0.5965\n",
      "Epoch 2206/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9880 - acc: 0.6055 - val_loss: 1.0474 - val_acc: 0.5965\n",
      "Epoch 2207/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9872 - acc: 0.6005 - val_loss: 1.0530 - val_acc: 0.5912\n",
      "Epoch 2208/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9887 - acc: 0.6010 - val_loss: 1.0368 - val_acc: 0.5997\n",
      "Epoch 2209/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9889 - acc: 0.6028 - val_loss: 1.0408 - val_acc: 0.5999\n",
      "Epoch 2210/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9947 - acc: 0.5981 - val_loss: 1.0628 - val_acc: 0.5877\n",
      "Epoch 2211/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9887 - acc: 0.6010 - val_loss: 1.0287 - val_acc: 0.6046\n",
      "Epoch 2212/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9892 - acc: 0.5982 - val_loss: 1.0483 - val_acc: 0.5967\n",
      "Epoch 2213/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9912 - acc: 0.6078 - val_loss: 1.0375 - val_acc: 0.5938\n",
      "Epoch 2214/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9969 - acc: 0.6010 - val_loss: 1.0435 - val_acc: 0.5976\n",
      "Epoch 2215/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9823 - acc: 0.6065 - val_loss: 1.0597 - val_acc: 0.5889\n",
      "Epoch 2216/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9981 - acc: 0.6018 - val_loss: 1.0406 - val_acc: 0.5909\n",
      "Epoch 2217/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9792 - acc: 0.6078 - val_loss: 1.0414 - val_acc: 0.5967\n",
      "Epoch 2218/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9934 - acc: 0.6023 - val_loss: 1.0378 - val_acc: 0.5950\n",
      "Epoch 2219/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9844 - acc: 0.6058 - val_loss: 1.0393 - val_acc: 0.5941\n",
      "Epoch 2220/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9805 - acc: 0.6087 - val_loss: 1.0416 - val_acc: 0.6002\n",
      "Epoch 2221/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9847 - acc: 0.6040 - val_loss: 1.0361 - val_acc: 0.5941\n",
      "Epoch 2222/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9822 - acc: 0.6090 - val_loss: 1.0387 - val_acc: 0.5991\n",
      "Epoch 2223/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9846 - acc: 0.6097 - val_loss: 1.0501 - val_acc: 0.5880\n",
      "Epoch 2224/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9820 - acc: 0.6058 - val_loss: 1.0530 - val_acc: 0.5936\n",
      "Epoch 2225/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9889 - acc: 0.6034 - val_loss: 1.0390 - val_acc: 0.6026\n",
      "Epoch 2226/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9837 - acc: 0.6046 - val_loss: 1.0447 - val_acc: 0.5912\n",
      "Epoch 2227/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9952 - acc: 0.6011 - val_loss: 1.0635 - val_acc: 0.5851\n",
      "Epoch 2228/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9868 - acc: 0.6069 - val_loss: 1.0502 - val_acc: 0.5915\n",
      "Epoch 2229/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 0.9793 - acc: 0.6108 - val_loss: 1.0517 - val_acc: 0.5895\n",
      "Epoch 2230/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 0.9930 - acc: 0.6039 - val_loss: 1.0305 - val_acc: 0.6017\n",
      "Epoch 2231/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9855 - acc: 0.6109 - val_loss: 1.0356 - val_acc: 0.5938\n",
      "Epoch 2232/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9819 - acc: 0.6060 - val_loss: 1.0384 - val_acc: 0.6023\n",
      "Epoch 2233/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 0.9703 - acc: 0.6140 - val_loss: 1.0289 - val_acc: 0.6005\n",
      "Epoch 2234/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9763 - acc: 0.6123 - val_loss: 1.0286 - val_acc: 0.6011\n",
      "Epoch 2235/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9889 - acc: 0.6056 - val_loss: 1.0477 - val_acc: 0.5950\n",
      "Epoch 2236/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 0.9994 - acc: 0.5997 - val_loss: 1.0390 - val_acc: 0.5997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2237/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9799 - acc: 0.6064 - val_loss: 1.0420 - val_acc: 0.5994\n",
      "Epoch 2238/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9941 - acc: 0.6050 - val_loss: 1.0398 - val_acc: 0.5982\n",
      "Epoch 2239/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9872 - acc: 0.6020 - val_loss: 1.0403 - val_acc: 0.5979\n",
      "Epoch 2240/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 0.9835 - acc: 0.6064 - val_loss: 1.0502 - val_acc: 0.5976\n",
      "Epoch 2241/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9900 - acc: 0.6065 - val_loss: 1.0448 - val_acc: 0.5988\n",
      "Epoch 2242/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 0.9910 - acc: 0.6053 - val_loss: 1.0498 - val_acc: 0.5962\n",
      "Epoch 2243/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9979 - acc: 0.5988 - val_loss: 1.0272 - val_acc: 0.6026\n",
      "Epoch 2244/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9869 - acc: 0.6032 - val_loss: 1.0450 - val_acc: 0.6017\n",
      "Epoch 2245/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9915 - acc: 0.6005 - val_loss: 1.0407 - val_acc: 0.6008\n",
      "Epoch 2246/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9745 - acc: 0.6070 - val_loss: 1.0426 - val_acc: 0.5912\n",
      "Epoch 2247/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9839 - acc: 0.6061 - val_loss: 1.0380 - val_acc: 0.5999\n",
      "Epoch 2248/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9859 - acc: 0.6090 - val_loss: 1.0382 - val_acc: 0.5959\n",
      "Epoch 2249/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9916 - acc: 0.6065 - val_loss: 1.0476 - val_acc: 0.5895\n",
      "Epoch 2250/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9940 - acc: 0.5991 - val_loss: 1.0477 - val_acc: 0.5912\n",
      "Epoch 2251/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9844 - acc: 0.6055 - val_loss: 1.0415 - val_acc: 0.5904\n",
      "Epoch 2252/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9766 - acc: 0.6096 - val_loss: 1.0408 - val_acc: 0.5967\n",
      "Epoch 2253/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9840 - acc: 0.6106 - val_loss: 1.0319 - val_acc: 0.5924\n",
      "Epoch 2254/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9823 - acc: 0.6122 - val_loss: 1.0384 - val_acc: 0.5953\n",
      "Epoch 2255/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9834 - acc: 0.6069 - val_loss: 1.0321 - val_acc: 0.6072\n",
      "Epoch 2256/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9786 - acc: 0.6062 - val_loss: 1.0483 - val_acc: 0.5857\n",
      "Epoch 2257/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9787 - acc: 0.6100 - val_loss: 1.0493 - val_acc: 0.5947\n",
      "Epoch 2258/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9874 - acc: 0.6061 - val_loss: 1.0417 - val_acc: 0.5959\n",
      "Epoch 2259/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9811 - acc: 0.6066 - val_loss: 1.0325 - val_acc: 0.5991\n",
      "Epoch 2260/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9794 - acc: 0.6072 - val_loss: 1.0394 - val_acc: 0.6014\n",
      "Epoch 2261/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9862 - acc: 0.5988 - val_loss: 1.0340 - val_acc: 0.6005\n",
      "Epoch 2262/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9849 - acc: 0.6054 - val_loss: 1.0602 - val_acc: 0.5866\n",
      "Epoch 2263/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9858 - acc: 0.6040 - val_loss: 1.0464 - val_acc: 0.5944\n",
      "Epoch 2264/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9841 - acc: 0.6028 - val_loss: 1.0270 - val_acc: 0.6028\n",
      "Epoch 2265/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9907 - acc: 0.6023 - val_loss: 1.0468 - val_acc: 0.5965\n",
      "Epoch 2266/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9961 - acc: 0.5978 - val_loss: 1.0310 - val_acc: 0.5985\n",
      "Epoch 2267/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9919 - acc: 0.6005 - val_loss: 1.0354 - val_acc: 0.5970\n",
      "Epoch 2268/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9811 - acc: 0.6053 - val_loss: 1.0266 - val_acc: 0.5976\n",
      "Epoch 2269/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9892 - acc: 0.6059 - val_loss: 1.0460 - val_acc: 0.5936\n",
      "Epoch 2270/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9818 - acc: 0.6059 - val_loss: 1.0323 - val_acc: 0.5985\n",
      "Epoch 2271/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9831 - acc: 0.6078 - val_loss: 1.0470 - val_acc: 0.5877\n",
      "Epoch 2272/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9854 - acc: 0.6021 - val_loss: 1.0382 - val_acc: 0.5973\n",
      "Epoch 2273/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9712 - acc: 0.6102 - val_loss: 1.0469 - val_acc: 0.5959\n",
      "Epoch 2274/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 0.9934 - acc: 0.6048 - val_loss: 1.0412 - val_acc: 0.5991\n",
      "Epoch 2275/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9790 - acc: 0.6106 - val_loss: 1.0439 - val_acc: 0.5930\n",
      "Epoch 2276/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9860 - acc: 0.6049 - val_loss: 1.0413 - val_acc: 0.5947\n",
      "Epoch 2277/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9904 - acc: 0.6040 - val_loss: 1.0404 - val_acc: 0.6008\n",
      "Epoch 2278/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9853 - acc: 0.6072 - val_loss: 1.0390 - val_acc: 0.5962\n",
      "Epoch 2279/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9880 - acc: 0.6067 - val_loss: 1.0397 - val_acc: 0.5991\n",
      "Epoch 2280/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9799 - acc: 0.6079 - val_loss: 1.0486 - val_acc: 0.5938\n",
      "Epoch 2281/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9853 - acc: 0.6034 - val_loss: 1.0322 - val_acc: 0.5912\n",
      "Epoch 2282/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9739 - acc: 0.6085 - val_loss: 1.0372 - val_acc: 0.6028\n",
      "Epoch 2283/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9696 - acc: 0.6111 - val_loss: 1.0411 - val_acc: 0.5906\n",
      "Epoch 2284/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9802 - acc: 0.6029 - val_loss: 1.0587 - val_acc: 0.5880\n",
      "Epoch 2285/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9848 - acc: 0.6048 - val_loss: 1.0219 - val_acc: 0.6005\n",
      "Epoch 2286/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9805 - acc: 0.6076 - val_loss: 1.0455 - val_acc: 0.5950\n",
      "Epoch 2287/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9835 - acc: 0.6080 - val_loss: 1.0459 - val_acc: 0.5956\n",
      "Epoch 2288/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9839 - acc: 0.6069 - val_loss: 1.0403 - val_acc: 0.5991\n",
      "Epoch 2289/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9814 - acc: 0.6071 - val_loss: 1.0440 - val_acc: 0.5965\n",
      "Epoch 2290/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9805 - acc: 0.6094 - val_loss: 1.0472 - val_acc: 0.5959\n",
      "Epoch 2291/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9812 - acc: 0.6069 - val_loss: 1.0486 - val_acc: 0.5956\n",
      "Epoch 2292/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9889 - acc: 0.6050 - val_loss: 1.0532 - val_acc: 0.5851\n",
      "Epoch 2293/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9811 - acc: 0.6047 - val_loss: 1.0296 - val_acc: 0.5941\n",
      "Epoch 2294/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9808 - acc: 0.6079 - val_loss: 1.0316 - val_acc: 0.6011\n",
      "Epoch 2295/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9889 - acc: 0.6032 - val_loss: 1.0415 - val_acc: 0.5950\n",
      "Epoch 2296/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9875 - acc: 0.6039 - val_loss: 1.0313 - val_acc: 0.5941\n",
      "Epoch 2297/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9803 - acc: 0.6082 - val_loss: 1.0366 - val_acc: 0.6008\n",
      "Epoch 2298/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9770 - acc: 0.6104 - val_loss: 1.0353 - val_acc: 0.5956\n",
      "Epoch 2299/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9810 - acc: 0.6090 - val_loss: 1.0385 - val_acc: 0.5985\n",
      "Epoch 2300/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9853 - acc: 0.6049 - val_loss: 1.0795 - val_acc: 0.5822\n",
      "Epoch 2301/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9883 - acc: 0.6047 - val_loss: 1.0587 - val_acc: 0.5988\n",
      "Epoch 2302/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9894 - acc: 0.6027 - val_loss: 1.0429 - val_acc: 0.5950\n",
      "Epoch 2303/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9880 - acc: 0.6074 - val_loss: 1.0477 - val_acc: 0.5965\n",
      "Epoch 2304/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9932 - acc: 0.6053 - val_loss: 1.0459 - val_acc: 0.6002\n",
      "Epoch 2305/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9905 - acc: 0.6030 - val_loss: 1.0649 - val_acc: 0.5938\n",
      "Epoch 2306/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9896 - acc: 0.6012 - val_loss: 1.0797 - val_acc: 0.5782\n",
      "Epoch 2307/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9823 - acc: 0.6095 - val_loss: 1.0505 - val_acc: 0.5979\n",
      "Epoch 2308/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9801 - acc: 0.6074 - val_loss: 1.0412 - val_acc: 0.5962\n",
      "Epoch 2309/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9851 - acc: 0.6028 - val_loss: 1.0348 - val_acc: 0.5997\n",
      "Epoch 2310/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9741 - acc: 0.6090 - val_loss: 1.0344 - val_acc: 0.5965\n",
      "Epoch 2311/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9882 - acc: 0.6024 - val_loss: 1.0406 - val_acc: 0.5909\n",
      "Epoch 2312/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9850 - acc: 0.6068 - val_loss: 1.0476 - val_acc: 0.5965\n",
      "Epoch 2313/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9856 - acc: 0.6045 - val_loss: 1.0312 - val_acc: 0.5965\n",
      "Epoch 2314/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9764 - acc: 0.6073 - val_loss: 1.0443 - val_acc: 0.5967\n",
      "Epoch 2315/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9851 - acc: 0.6066 - val_loss: 1.0414 - val_acc: 0.5985\n",
      "Epoch 2316/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 1.0009 - acc: 0.6008 - val_loss: 1.0664 - val_acc: 0.5845\n",
      "Epoch 2317/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9844 - acc: 0.6052 - val_loss: 1.0392 - val_acc: 0.5889\n",
      "Epoch 2318/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9847 - acc: 0.6046 - val_loss: 1.0378 - val_acc: 0.6020\n",
      "Epoch 2319/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9926 - acc: 0.6040 - val_loss: 1.0351 - val_acc: 0.6020\n",
      "Epoch 2320/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9816 - acc: 0.6030 - val_loss: 1.0354 - val_acc: 0.6043\n",
      "Epoch 2321/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9742 - acc: 0.6084 - val_loss: 1.0407 - val_acc: 0.6002\n",
      "Epoch 2322/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9757 - acc: 0.6122 - val_loss: 1.0451 - val_acc: 0.6011\n",
      "Epoch 2323/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9717 - acc: 0.6119 - val_loss: 1.0300 - val_acc: 0.6014\n",
      "Epoch 2324/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9795 - acc: 0.6097 - val_loss: 1.0344 - val_acc: 0.6043\n",
      "Epoch 2325/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9688 - acc: 0.6116 - val_loss: 1.0285 - val_acc: 0.6037\n",
      "Epoch 2326/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9754 - acc: 0.6100 - val_loss: 1.0334 - val_acc: 0.6040\n",
      "Epoch 2327/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9799 - acc: 0.6063 - val_loss: 1.0415 - val_acc: 0.6011\n",
      "Epoch 2328/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9901 - acc: 0.6042 - val_loss: 1.0352 - val_acc: 0.6020\n",
      "Epoch 2329/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9760 - acc: 0.6075 - val_loss: 1.0424 - val_acc: 0.6028\n",
      "Epoch 2330/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9809 - acc: 0.6087 - val_loss: 1.0465 - val_acc: 0.5912\n",
      "Epoch 2331/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9888 - acc: 0.6053 - val_loss: 1.0380 - val_acc: 0.5956\n",
      "Epoch 2332/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9944 - acc: 0.6009 - val_loss: 1.0384 - val_acc: 0.6005\n",
      "Epoch 2333/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9810 - acc: 0.6055 - val_loss: 1.0474 - val_acc: 0.6060\n",
      "Epoch 2334/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9809 - acc: 0.6082 - val_loss: 1.0568 - val_acc: 0.5950\n",
      "Epoch 2335/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9850 - acc: 0.6054 - val_loss: 1.0387 - val_acc: 0.5991\n",
      "Epoch 2336/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9643 - acc: 0.6172 - val_loss: 1.0376 - val_acc: 0.6014\n",
      "Epoch 2337/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9862 - acc: 0.6059 - val_loss: 1.0469 - val_acc: 0.5953\n",
      "Epoch 2338/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9764 - acc: 0.6069 - val_loss: 1.0355 - val_acc: 0.6139\n",
      "Epoch 2339/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9744 - acc: 0.6117 - val_loss: 1.0303 - val_acc: 0.5991\n",
      "Epoch 2340/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9768 - acc: 0.6058 - val_loss: 1.0479 - val_acc: 0.5892\n",
      "Epoch 2341/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9742 - acc: 0.6091 - val_loss: 1.0597 - val_acc: 0.5845\n",
      "Epoch 2342/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9832 - acc: 0.6045 - val_loss: 1.0468 - val_acc: 0.5930\n",
      "Epoch 2343/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9744 - acc: 0.6099 - val_loss: 1.0363 - val_acc: 0.6060\n",
      "Epoch 2344/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9734 - acc: 0.6127 - val_loss: 1.0458 - val_acc: 0.5988\n",
      "Epoch 2345/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9776 - acc: 0.6091 - val_loss: 1.0503 - val_acc: 0.5967\n",
      "Epoch 2346/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9764 - acc: 0.6092 - val_loss: 1.0603 - val_acc: 0.5877\n",
      "Epoch 2347/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9812 - acc: 0.6087 - val_loss: 1.0468 - val_acc: 0.6028\n",
      "Epoch 2348/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9919 - acc: 0.6058 - val_loss: 1.0487 - val_acc: 0.5906\n",
      "Epoch 2349/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9865 - acc: 0.6068 - val_loss: 1.0290 - val_acc: 0.5988\n",
      "Epoch 2350/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9836 - acc: 0.6032 - val_loss: 1.0448 - val_acc: 0.5976\n",
      "Epoch 2351/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9799 - acc: 0.6100 - val_loss: 1.0431 - val_acc: 0.5944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2352/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9771 - acc: 0.6054 - val_loss: 1.0575 - val_acc: 0.5909\n",
      "Epoch 2353/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9808 - acc: 0.6063 - val_loss: 1.0371 - val_acc: 0.6017\n",
      "Epoch 2354/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9841 - acc: 0.6074 - val_loss: 1.0461 - val_acc: 0.5988\n",
      "Epoch 2355/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9815 - acc: 0.6057 - val_loss: 1.0549 - val_acc: 0.5953\n",
      "Epoch 2356/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9756 - acc: 0.6081 - val_loss: 1.0448 - val_acc: 0.5944\n",
      "Epoch 2357/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9763 - acc: 0.6077 - val_loss: 1.0563 - val_acc: 0.5872\n",
      "Epoch 2358/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9828 - acc: 0.6054 - val_loss: 1.0390 - val_acc: 0.5999\n",
      "Epoch 2359/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9963 - acc: 0.6032 - val_loss: 1.0330 - val_acc: 0.6008\n",
      "Epoch 2360/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9772 - acc: 0.6125 - val_loss: 1.0382 - val_acc: 0.6026\n",
      "Epoch 2361/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9724 - acc: 0.6109 - val_loss: 1.0340 - val_acc: 0.5962\n",
      "Epoch 2362/3000\n",
      "13766/13766 [==============================] - 1s 70us/step - loss: 0.9751 - acc: 0.6068 - val_loss: 1.0448 - val_acc: 0.6014\n",
      "Epoch 2363/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9741 - acc: 0.6119 - val_loss: 1.0383 - val_acc: 0.5991\n",
      "Epoch 2364/3000\n",
      "13766/13766 [==============================] - 1s 61us/step - loss: 0.9726 - acc: 0.6091 - val_loss: 1.0391 - val_acc: 0.5950\n",
      "Epoch 2365/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9802 - acc: 0.6032 - val_loss: 1.0438 - val_acc: 0.5959\n",
      "Epoch 2366/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9814 - acc: 0.6079 - val_loss: 1.0291 - val_acc: 0.6023\n",
      "Epoch 2367/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9947 - acc: 0.6055 - val_loss: 1.0421 - val_acc: 0.5967\n",
      "Epoch 2368/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9767 - acc: 0.6080 - val_loss: 1.0370 - val_acc: 0.6046\n",
      "Epoch 2369/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9757 - acc: 0.6131 - val_loss: 1.0366 - val_acc: 0.5959\n",
      "Epoch 2370/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9871 - acc: 0.6062 - val_loss: 1.0464 - val_acc: 0.5927\n",
      "Epoch 2371/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9860 - acc: 0.6066 - val_loss: 1.0291 - val_acc: 0.6014\n",
      "Epoch 2372/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9755 - acc: 0.6087 - val_loss: 1.0363 - val_acc: 0.5988\n",
      "Epoch 2373/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9932 - acc: 0.6076 - val_loss: 1.0452 - val_acc: 0.5898\n",
      "Epoch 2374/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9811 - acc: 0.6076 - val_loss: 1.0376 - val_acc: 0.6063\n",
      "Epoch 2375/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9896 - acc: 0.6040 - val_loss: 1.0421 - val_acc: 0.5906\n",
      "Epoch 2376/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9889 - acc: 0.6035 - val_loss: 1.0188 - val_acc: 0.6020\n",
      "Epoch 2377/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9803 - acc: 0.6061 - val_loss: 1.0215 - val_acc: 0.6005\n",
      "Epoch 2378/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9863 - acc: 0.6068 - val_loss: 1.0325 - val_acc: 0.5941\n",
      "Epoch 2379/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9826 - acc: 0.6080 - val_loss: 1.0291 - val_acc: 0.6060\n",
      "Epoch 2380/3000\n",
      "13766/13766 [==============================] - 1s 63us/step - loss: 0.9915 - acc: 0.6012 - val_loss: 1.0245 - val_acc: 0.6026\n",
      "Epoch 2381/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9927 - acc: 0.6100 - val_loss: 1.0377 - val_acc: 0.5930\n",
      "Epoch 2382/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9747 - acc: 0.6127 - val_loss: 1.0275 - val_acc: 0.6014\n",
      "Epoch 2383/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9792 - acc: 0.6094 - val_loss: 1.0223 - val_acc: 0.6028\n",
      "Epoch 2384/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9710 - acc: 0.6127 - val_loss: 1.0457 - val_acc: 0.6002\n",
      "Epoch 2385/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9819 - acc: 0.6047 - val_loss: 1.0323 - val_acc: 0.6060\n",
      "Epoch 2386/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9856 - acc: 0.6076 - val_loss: 1.0317 - val_acc: 0.5933\n",
      "Epoch 2387/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9858 - acc: 0.6114 - val_loss: 1.0322 - val_acc: 0.5965\n",
      "Epoch 2388/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9826 - acc: 0.6027 - val_loss: 1.0379 - val_acc: 0.6020\n",
      "Epoch 2389/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9806 - acc: 0.6008 - val_loss: 1.0299 - val_acc: 0.6052\n",
      "Epoch 2390/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9814 - acc: 0.6075 - val_loss: 1.0281 - val_acc: 0.6043\n",
      "Epoch 2391/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9738 - acc: 0.6067 - val_loss: 1.0380 - val_acc: 0.6034\n",
      "Epoch 2392/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9747 - acc: 0.6073 - val_loss: 1.0210 - val_acc: 0.6031\n",
      "Epoch 2393/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9785 - acc: 0.6098 - val_loss: 1.0334 - val_acc: 0.6060\n",
      "Epoch 2394/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9863 - acc: 0.6057 - val_loss: 1.0379 - val_acc: 0.5988\n",
      "Epoch 2395/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9777 - acc: 0.6099 - val_loss: 1.0203 - val_acc: 0.6060\n",
      "Epoch 2396/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9801 - acc: 0.6088 - val_loss: 1.0437 - val_acc: 0.5994\n",
      "Epoch 2397/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9802 - acc: 0.6098 - val_loss: 1.0280 - val_acc: 0.6034\n",
      "Epoch 2398/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9580 - acc: 0.6135 - val_loss: 1.0488 - val_acc: 0.5947\n",
      "Epoch 2399/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9814 - acc: 0.6104 - val_loss: 1.0442 - val_acc: 0.5901\n",
      "Epoch 2400/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9796 - acc: 0.6103 - val_loss: 1.0325 - val_acc: 0.6037\n",
      "Epoch 2401/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9899 - acc: 0.6048 - val_loss: 1.0282 - val_acc: 0.5982\n",
      "Epoch 2402/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9775 - acc: 0.6088 - val_loss: 1.0236 - val_acc: 0.6017\n",
      "Epoch 2403/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9811 - acc: 0.6115 - val_loss: 1.0318 - val_acc: 0.5965\n",
      "Epoch 2404/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9720 - acc: 0.6155 - val_loss: 1.0272 - val_acc: 0.6034\n",
      "Epoch 2405/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9802 - acc: 0.6099 - val_loss: 1.0372 - val_acc: 0.6011\n",
      "Epoch 2406/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9806 - acc: 0.6122 - val_loss: 1.0322 - val_acc: 0.5994\n",
      "Epoch 2407/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9819 - acc: 0.6050 - val_loss: 1.0336 - val_acc: 0.6002\n",
      "Epoch 2408/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9920 - acc: 0.6085 - val_loss: 1.0378 - val_acc: 0.5979\n",
      "Epoch 2409/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9829 - acc: 0.6090 - val_loss: 1.0393 - val_acc: 0.5979\n",
      "Epoch 2410/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9839 - acc: 0.6040 - val_loss: 1.0238 - val_acc: 0.6043\n",
      "Epoch 2411/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9804 - acc: 0.6097 - val_loss: 1.0340 - val_acc: 0.5970\n",
      "Epoch 2412/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9835 - acc: 0.6096 - val_loss: 1.0277 - val_acc: 0.6031\n",
      "Epoch 2413/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9810 - acc: 0.6025 - val_loss: 1.0465 - val_acc: 0.5965\n",
      "Epoch 2414/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9763 - acc: 0.6138 - val_loss: 1.0291 - val_acc: 0.6046\n",
      "Epoch 2415/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9826 - acc: 0.6065 - val_loss: 1.0332 - val_acc: 0.6028\n",
      "Epoch 2416/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9770 - acc: 0.6086 - val_loss: 1.0227 - val_acc: 0.6066\n",
      "Epoch 2417/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9754 - acc: 0.6130 - val_loss: 1.0342 - val_acc: 0.5976\n",
      "Epoch 2418/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9841 - acc: 0.6092 - val_loss: 1.0615 - val_acc: 0.5869\n",
      "Epoch 2419/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9876 - acc: 0.6077 - val_loss: 1.0395 - val_acc: 0.5967\n",
      "Epoch 2420/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9849 - acc: 0.6079 - val_loss: 1.0536 - val_acc: 0.5965\n",
      "Epoch 2421/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9916 - acc: 0.6049 - val_loss: 1.0389 - val_acc: 0.5886\n",
      "Epoch 2422/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9871 - acc: 0.6058 - val_loss: 1.0333 - val_acc: 0.5994\n",
      "Epoch 2423/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9749 - acc: 0.6119 - val_loss: 1.0365 - val_acc: 0.5973\n",
      "Epoch 2424/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9784 - acc: 0.6102 - val_loss: 1.0386 - val_acc: 0.6055\n",
      "Epoch 2425/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9781 - acc: 0.6094 - val_loss: 1.0357 - val_acc: 0.6075\n",
      "Epoch 2426/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9891 - acc: 0.6052 - val_loss: 1.0381 - val_acc: 0.5912\n",
      "Epoch 2427/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 0.9762 - acc: 0.6104 - val_loss: 1.0313 - val_acc: 0.6026\n",
      "Epoch 2428/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9736 - acc: 0.6095 - val_loss: 1.0250 - val_acc: 0.6028\n",
      "Epoch 2429/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9725 - acc: 0.6127 - val_loss: 1.0253 - val_acc: 0.6002\n",
      "Epoch 2430/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9714 - acc: 0.6119 - val_loss: 1.0220 - val_acc: 0.6081\n",
      "Epoch 2431/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9730 - acc: 0.6125 - val_loss: 1.0345 - val_acc: 0.5950\n",
      "Epoch 2432/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9761 - acc: 0.6104 - val_loss: 1.0322 - val_acc: 0.5976\n",
      "Epoch 2433/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9824 - acc: 0.6109 - val_loss: 1.0252 - val_acc: 0.5991\n",
      "Epoch 2434/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9735 - acc: 0.6085 - val_loss: 1.0404 - val_acc: 0.5950\n",
      "Epoch 2435/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9738 - acc: 0.6131 - val_loss: 1.0419 - val_acc: 0.6026\n",
      "Epoch 2436/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9800 - acc: 0.6101 - val_loss: 1.0429 - val_acc: 0.5924\n",
      "Epoch 2437/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9749 - acc: 0.6093 - val_loss: 1.0389 - val_acc: 0.5921\n",
      "Epoch 2438/3000\n",
      "13766/13766 [==============================] - 1s 71us/step - loss: 0.9730 - acc: 0.6140 - val_loss: 1.0407 - val_acc: 0.6043\n",
      "Epoch 2439/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9883 - acc: 0.6061 - val_loss: 1.0285 - val_acc: 0.5999\n",
      "Epoch 2440/3000\n",
      "13766/13766 [==============================] - 1s 57us/step - loss: 0.9849 - acc: 0.6064 - val_loss: 1.0338 - val_acc: 0.5999\n",
      "Epoch 2441/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 0.9821 - acc: 0.6104 - val_loss: 1.0430 - val_acc: 0.5880\n",
      "Epoch 2442/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9827 - acc: 0.6095 - val_loss: 1.0426 - val_acc: 0.5886\n",
      "Epoch 2443/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9776 - acc: 0.6088 - val_loss: 1.0382 - val_acc: 0.5999\n",
      "Epoch 2444/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9847 - acc: 0.6077 - val_loss: 1.0353 - val_acc: 0.6005\n",
      "Epoch 2445/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9758 - acc: 0.6120 - val_loss: 1.0383 - val_acc: 0.5982\n",
      "Epoch 2446/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9632 - acc: 0.6164 - val_loss: 1.0318 - val_acc: 0.5967\n",
      "Epoch 2447/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9780 - acc: 0.6080 - val_loss: 1.0350 - val_acc: 0.6040\n",
      "Epoch 2448/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9842 - acc: 0.6097 - val_loss: 1.0423 - val_acc: 0.5965\n",
      "Epoch 2449/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9901 - acc: 0.6062 - val_loss: 1.0251 - val_acc: 0.6063\n",
      "Epoch 2450/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9824 - acc: 0.6069 - val_loss: 1.0545 - val_acc: 0.5933\n",
      "Epoch 2451/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9732 - acc: 0.6130 - val_loss: 1.0194 - val_acc: 0.6011\n",
      "Epoch 2452/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9664 - acc: 0.6100 - val_loss: 1.0176 - val_acc: 0.6069\n",
      "Epoch 2453/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9786 - acc: 0.6087 - val_loss: 1.0189 - val_acc: 0.6063\n",
      "Epoch 2454/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9743 - acc: 0.6121 - val_loss: 1.0253 - val_acc: 0.6046\n",
      "Epoch 2455/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9764 - acc: 0.6083 - val_loss: 1.0280 - val_acc: 0.6014\n",
      "Epoch 2456/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9810 - acc: 0.6102 - val_loss: 1.0215 - val_acc: 0.6005\n",
      "Epoch 2457/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9845 - acc: 0.6017 - val_loss: 1.0289 - val_acc: 0.6017\n",
      "Epoch 2458/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9683 - acc: 0.6105 - val_loss: 1.0206 - val_acc: 0.6072\n",
      "Epoch 2459/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9689 - acc: 0.6115 - val_loss: 1.0371 - val_acc: 0.5915\n",
      "Epoch 2460/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9751 - acc: 0.6086 - val_loss: 1.0358 - val_acc: 0.5970\n",
      "Epoch 2461/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9836 - acc: 0.6079 - val_loss: 1.0362 - val_acc: 0.5915\n",
      "Epoch 2462/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9822 - acc: 0.6050 - val_loss: 1.0287 - val_acc: 0.6081\n",
      "Epoch 2463/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9746 - acc: 0.6117 - val_loss: 1.0321 - val_acc: 0.5959\n",
      "Epoch 2464/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9802 - acc: 0.6072 - val_loss: 1.0405 - val_acc: 0.5982\n",
      "Epoch 2465/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9864 - acc: 0.6057 - val_loss: 1.0247 - val_acc: 0.6005\n",
      "Epoch 2466/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9683 - acc: 0.6148 - val_loss: 1.0326 - val_acc: 0.5965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2467/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9756 - acc: 0.6093 - val_loss: 1.0369 - val_acc: 0.5979\n",
      "Epoch 2468/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9741 - acc: 0.6077 - val_loss: 1.0429 - val_acc: 0.5941\n",
      "Epoch 2469/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9698 - acc: 0.6089 - val_loss: 1.0415 - val_acc: 0.5869\n",
      "Epoch 2470/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9897 - acc: 0.6033 - val_loss: 1.0365 - val_acc: 0.5962\n",
      "Epoch 2471/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9880 - acc: 0.6087 - val_loss: 1.0431 - val_acc: 0.5988\n",
      "Epoch 2472/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9784 - acc: 0.6129 - val_loss: 1.0299 - val_acc: 0.5985\n",
      "Epoch 2473/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9725 - acc: 0.6119 - val_loss: 1.0375 - val_acc: 0.5944\n",
      "Epoch 2474/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9767 - acc: 0.6150 - val_loss: 1.0363 - val_acc: 0.5967\n",
      "Epoch 2475/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9770 - acc: 0.6121 - val_loss: 1.0421 - val_acc: 0.5941\n",
      "Epoch 2476/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9777 - acc: 0.6116 - val_loss: 1.0503 - val_acc: 0.5915\n",
      "Epoch 2477/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9691 - acc: 0.6090 - val_loss: 1.0265 - val_acc: 0.6066\n",
      "Epoch 2478/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9745 - acc: 0.6140 - val_loss: 1.0306 - val_acc: 0.6023\n",
      "Epoch 2479/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9783 - acc: 0.6065 - val_loss: 1.0305 - val_acc: 0.6069\n",
      "Epoch 2480/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9719 - acc: 0.6121 - val_loss: 1.0410 - val_acc: 0.5953\n",
      "Epoch 2481/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9771 - acc: 0.6108 - val_loss: 1.0301 - val_acc: 0.6017\n",
      "Epoch 2482/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9862 - acc: 0.6109 - val_loss: 1.0265 - val_acc: 0.5997\n",
      "Epoch 2483/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9774 - acc: 0.6117 - val_loss: 1.0297 - val_acc: 0.6034\n",
      "Epoch 2484/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9778 - acc: 0.6055 - val_loss: 1.0396 - val_acc: 0.5994\n",
      "Epoch 2485/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9778 - acc: 0.6109 - val_loss: 1.0310 - val_acc: 0.5979\n",
      "Epoch 2486/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9749 - acc: 0.6071 - val_loss: 1.0403 - val_acc: 0.5941\n",
      "Epoch 2487/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9771 - acc: 0.6058 - val_loss: 1.0374 - val_acc: 0.5982\n",
      "Epoch 2488/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9828 - acc: 0.6095 - val_loss: 1.0300 - val_acc: 0.6011\n",
      "Epoch 2489/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9878 - acc: 0.6092 - val_loss: 1.0376 - val_acc: 0.5970\n",
      "Epoch 2490/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9793 - acc: 0.6110 - val_loss: 1.0334 - val_acc: 0.6002\n",
      "Epoch 2491/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9817 - acc: 0.6065 - val_loss: 1.0408 - val_acc: 0.5976\n",
      "Epoch 2492/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9811 - acc: 0.6087 - val_loss: 1.0275 - val_acc: 0.5997\n",
      "Epoch 2493/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9738 - acc: 0.6124 - val_loss: 1.0412 - val_acc: 0.5985\n",
      "Epoch 2494/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9715 - acc: 0.6125 - val_loss: 1.0387 - val_acc: 0.5973\n",
      "Epoch 2495/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9741 - acc: 0.6118 - val_loss: 1.0385 - val_acc: 0.5953\n",
      "Epoch 2496/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9779 - acc: 0.6109 - val_loss: 1.0366 - val_acc: 0.5994\n",
      "Epoch 2497/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9792 - acc: 0.6051 - val_loss: 1.0394 - val_acc: 0.6020\n",
      "Epoch 2498/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9820 - acc: 0.6074 - val_loss: 1.0383 - val_acc: 0.5962\n",
      "Epoch 2499/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9768 - acc: 0.6111 - val_loss: 1.0331 - val_acc: 0.5930\n",
      "Epoch 2500/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9737 - acc: 0.6124 - val_loss: 1.0388 - val_acc: 0.5950\n",
      "Epoch 2501/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9776 - acc: 0.6151 - val_loss: 1.0258 - val_acc: 0.6023\n",
      "Epoch 2502/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9844 - acc: 0.6053 - val_loss: 1.0342 - val_acc: 0.6008\n",
      "Epoch 2503/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9780 - acc: 0.6127 - val_loss: 1.0388 - val_acc: 0.6020\n",
      "Epoch 2504/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9707 - acc: 0.6125 - val_loss: 1.0392 - val_acc: 0.5962\n",
      "Epoch 2505/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9783 - acc: 0.6062 - val_loss: 1.0220 - val_acc: 0.6014\n",
      "Epoch 2506/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9711 - acc: 0.6129 - val_loss: 1.0298 - val_acc: 0.6087\n",
      "Epoch 2507/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9747 - acc: 0.6130 - val_loss: 1.0207 - val_acc: 0.6043\n",
      "Epoch 2508/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9744 - acc: 0.6118 - val_loss: 1.0238 - val_acc: 0.6052\n",
      "Epoch 2509/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9809 - acc: 0.6038 - val_loss: 1.0311 - val_acc: 0.6017\n",
      "Epoch 2510/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9772 - acc: 0.6119 - val_loss: 1.0395 - val_acc: 0.6063\n",
      "Epoch 2511/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9859 - acc: 0.6048 - val_loss: 1.0490 - val_acc: 0.5930\n",
      "Epoch 2512/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9765 - acc: 0.6040 - val_loss: 1.0421 - val_acc: 0.5872\n",
      "Epoch 2513/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9774 - acc: 0.6075 - val_loss: 1.0580 - val_acc: 0.5918\n",
      "Epoch 2514/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9771 - acc: 0.6079 - val_loss: 1.0531 - val_acc: 0.5938\n",
      "Epoch 2515/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9881 - acc: 0.6078 - val_loss: 1.0414 - val_acc: 0.5985\n",
      "Epoch 2516/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9792 - acc: 0.6108 - val_loss: 1.0449 - val_acc: 0.5857\n",
      "Epoch 2517/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9903 - acc: 0.6028 - val_loss: 1.0378 - val_acc: 0.5936\n",
      "Epoch 2518/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9727 - acc: 0.6119 - val_loss: 1.0490 - val_acc: 0.5956\n",
      "Epoch 2519/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9737 - acc: 0.6068 - val_loss: 1.0335 - val_acc: 0.6026\n",
      "Epoch 2520/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9746 - acc: 0.6140 - val_loss: 1.0286 - val_acc: 0.6002\n",
      "Epoch 2521/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9752 - acc: 0.6100 - val_loss: 1.0468 - val_acc: 0.5959\n",
      "Epoch 2522/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9829 - acc: 0.6099 - val_loss: 1.0347 - val_acc: 0.6008\n",
      "Epoch 2523/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9735 - acc: 0.6105 - val_loss: 1.0334 - val_acc: 0.6017\n",
      "Epoch 2524/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9827 - acc: 0.6111 - val_loss: 1.0292 - val_acc: 0.5999\n",
      "Epoch 2525/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9743 - acc: 0.6059 - val_loss: 1.0463 - val_acc: 0.5947\n",
      "Epoch 2526/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9784 - acc: 0.6069 - val_loss: 1.0472 - val_acc: 0.5962\n",
      "Epoch 2527/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9827 - acc: 0.6087 - val_loss: 1.0438 - val_acc: 0.5962\n",
      "Epoch 2528/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9799 - acc: 0.6045 - val_loss: 1.0184 - val_acc: 0.6069\n",
      "Epoch 2529/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9658 - acc: 0.6137 - val_loss: 1.0202 - val_acc: 0.6060\n",
      "Epoch 2530/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9816 - acc: 0.6106 - val_loss: 1.0320 - val_acc: 0.6026\n",
      "Epoch 2531/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9663 - acc: 0.6132 - val_loss: 1.0476 - val_acc: 0.5930\n",
      "Epoch 2532/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9721 - acc: 0.6088 - val_loss: 1.0327 - val_acc: 0.6034\n",
      "Epoch 2533/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9671 - acc: 0.6136 - val_loss: 1.0307 - val_acc: 0.6026\n",
      "Epoch 2534/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9701 - acc: 0.6079 - val_loss: 1.0305 - val_acc: 0.6028\n",
      "Epoch 2535/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9672 - acc: 0.6125 - val_loss: 1.0385 - val_acc: 0.6031\n",
      "Epoch 2536/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9667 - acc: 0.6116 - val_loss: 1.0369 - val_acc: 0.6028\n",
      "Epoch 2537/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9748 - acc: 0.6111 - val_loss: 1.0331 - val_acc: 0.6055\n",
      "Epoch 2538/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9800 - acc: 0.6074 - val_loss: 1.0285 - val_acc: 0.6028\n",
      "Epoch 2539/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9783 - acc: 0.6131 - val_loss: 1.0444 - val_acc: 0.5967\n",
      "Epoch 2540/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 0.9773 - acc: 0.6151 - val_loss: 1.0343 - val_acc: 0.5976\n",
      "Epoch 2541/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9821 - acc: 0.6124 - val_loss: 1.0343 - val_acc: 0.5959\n",
      "Epoch 2542/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9764 - acc: 0.6082 - val_loss: 1.0569 - val_acc: 0.5930\n",
      "Epoch 2543/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9742 - acc: 0.6140 - val_loss: 1.0427 - val_acc: 0.5956\n",
      "Epoch 2544/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9787 - acc: 0.6109 - val_loss: 1.0406 - val_acc: 0.5979\n",
      "Epoch 2545/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9678 - acc: 0.6137 - val_loss: 1.0394 - val_acc: 0.5965\n",
      "Epoch 2546/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9771 - acc: 0.6143 - val_loss: 1.0295 - val_acc: 0.5999\n",
      "Epoch 2547/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9741 - acc: 0.6086 - val_loss: 1.0368 - val_acc: 0.5965\n",
      "Epoch 2548/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9736 - acc: 0.6126 - val_loss: 1.0382 - val_acc: 0.5985\n",
      "Epoch 2549/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9742 - acc: 0.6151 - val_loss: 1.0342 - val_acc: 0.6023\n",
      "Epoch 2550/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9655 - acc: 0.6124 - val_loss: 1.0413 - val_acc: 0.5953\n",
      "Epoch 2551/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9763 - acc: 0.6098 - val_loss: 1.0323 - val_acc: 0.6011\n",
      "Epoch 2552/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9719 - acc: 0.6122 - val_loss: 1.0350 - val_acc: 0.6005\n",
      "Epoch 2553/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9714 - acc: 0.6126 - val_loss: 1.0454 - val_acc: 0.5970\n",
      "Epoch 2554/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9799 - acc: 0.6123 - val_loss: 1.0530 - val_acc: 0.5918\n",
      "Epoch 2555/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9918 - acc: 0.6045 - val_loss: 1.0547 - val_acc: 0.5895\n",
      "Epoch 2556/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9806 - acc: 0.6114 - val_loss: 1.0338 - val_acc: 0.6014\n",
      "Epoch 2557/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9767 - acc: 0.6109 - val_loss: 1.0372 - val_acc: 0.6043\n",
      "Epoch 2558/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9821 - acc: 0.6073 - val_loss: 1.0341 - val_acc: 0.5962\n",
      "Epoch 2559/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9720 - acc: 0.6130 - val_loss: 1.0288 - val_acc: 0.6020\n",
      "Epoch 2560/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9786 - acc: 0.6103 - val_loss: 1.0301 - val_acc: 0.5991\n",
      "Epoch 2561/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9744 - acc: 0.6095 - val_loss: 1.0351 - val_acc: 0.5976\n",
      "Epoch 2562/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9862 - acc: 0.6058 - val_loss: 1.0239 - val_acc: 0.6069\n",
      "Epoch 2563/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9738 - acc: 0.6129 - val_loss: 1.0372 - val_acc: 0.5988\n",
      "Epoch 2564/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9695 - acc: 0.6148 - val_loss: 1.0502 - val_acc: 0.5967\n",
      "Epoch 2565/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9786 - acc: 0.6046 - val_loss: 1.0317 - val_acc: 0.5979\n",
      "Epoch 2566/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9721 - acc: 0.6093 - val_loss: 1.0355 - val_acc: 0.5944\n",
      "Epoch 2567/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9648 - acc: 0.6114 - val_loss: 1.0332 - val_acc: 0.5956\n",
      "Epoch 2568/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9748 - acc: 0.6120 - val_loss: 1.0253 - val_acc: 0.6040\n",
      "Epoch 2569/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9786 - acc: 0.6050 - val_loss: 1.0285 - val_acc: 0.6037\n",
      "Epoch 2570/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9763 - acc: 0.6133 - val_loss: 1.0491 - val_acc: 0.6002\n",
      "Epoch 2571/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9794 - acc: 0.6127 - val_loss: 1.0556 - val_acc: 0.5938\n",
      "Epoch 2572/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9768 - acc: 0.6091 - val_loss: 1.0399 - val_acc: 0.5979\n",
      "Epoch 2573/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9879 - acc: 0.6043 - val_loss: 1.0498 - val_acc: 0.5991\n",
      "Epoch 2574/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9724 - acc: 0.6123 - val_loss: 1.0398 - val_acc: 0.6037\n",
      "Epoch 2575/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9815 - acc: 0.6086 - val_loss: 1.0505 - val_acc: 0.5953\n",
      "Epoch 2576/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9672 - acc: 0.6146 - val_loss: 1.0467 - val_acc: 0.5912\n",
      "Epoch 2577/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9688 - acc: 0.6147 - val_loss: 1.0297 - val_acc: 0.5973\n",
      "Epoch 2578/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9783 - acc: 0.6068 - val_loss: 1.0367 - val_acc: 0.6060\n",
      "Epoch 2579/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9690 - acc: 0.6109 - val_loss: 1.0318 - val_acc: 0.5994\n",
      "Epoch 2580/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9728 - acc: 0.6131 - val_loss: 1.0447 - val_acc: 0.6002\n",
      "Epoch 2581/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9747 - acc: 0.6120 - val_loss: 1.0358 - val_acc: 0.5985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2582/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9855 - acc: 0.6096 - val_loss: 1.0277 - val_acc: 0.6028\n",
      "Epoch 2583/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9679 - acc: 0.6140 - val_loss: 1.0376 - val_acc: 0.5924\n",
      "Epoch 2584/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9819 - acc: 0.6089 - val_loss: 1.0320 - val_acc: 0.6011\n",
      "Epoch 2585/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9714 - acc: 0.6153 - val_loss: 1.0374 - val_acc: 0.6034\n",
      "Epoch 2586/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9724 - acc: 0.6106 - val_loss: 1.0269 - val_acc: 0.6058\n",
      "Epoch 2587/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9853 - acc: 0.6044 - val_loss: 1.0360 - val_acc: 0.5965\n",
      "Epoch 2588/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9794 - acc: 0.6105 - val_loss: 1.0433 - val_acc: 0.5915\n",
      "Epoch 2589/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9850 - acc: 0.6046 - val_loss: 1.0353 - val_acc: 0.6005\n",
      "Epoch 2590/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9713 - acc: 0.6095 - val_loss: 1.0364 - val_acc: 0.6072\n",
      "Epoch 2591/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9725 - acc: 0.6161 - val_loss: 1.0298 - val_acc: 0.6049\n",
      "Epoch 2592/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9739 - acc: 0.6119 - val_loss: 1.0311 - val_acc: 0.6028\n",
      "Epoch 2593/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9745 - acc: 0.6116 - val_loss: 1.0248 - val_acc: 0.6072\n",
      "Epoch 2594/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9792 - acc: 0.6103 - val_loss: 1.0295 - val_acc: 0.6020\n",
      "Epoch 2595/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9786 - acc: 0.6082 - val_loss: 1.0283 - val_acc: 0.6060\n",
      "Epoch 2596/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9802 - acc: 0.6115 - val_loss: 1.0322 - val_acc: 0.5994\n",
      "Epoch 2597/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9628 - acc: 0.6145 - val_loss: 1.0304 - val_acc: 0.5979\n",
      "Epoch 2598/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9748 - acc: 0.6124 - val_loss: 1.0501 - val_acc: 0.5941\n",
      "Epoch 2599/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9724 - acc: 0.6190 - val_loss: 1.0343 - val_acc: 0.6060\n",
      "Epoch 2600/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9829 - acc: 0.6091 - val_loss: 1.0359 - val_acc: 0.6133\n",
      "Epoch 2601/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9794 - acc: 0.6101 - val_loss: 1.0396 - val_acc: 0.5956\n",
      "Epoch 2602/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9819 - acc: 0.6122 - val_loss: 1.0549 - val_acc: 0.5965\n",
      "Epoch 2603/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9730 - acc: 0.6132 - val_loss: 1.0321 - val_acc: 0.6087\n",
      "Epoch 2604/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9740 - acc: 0.6093 - val_loss: 1.0386 - val_acc: 0.6058\n",
      "Epoch 2605/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9682 - acc: 0.6122 - val_loss: 1.0339 - val_acc: 0.6049\n",
      "Epoch 2606/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9749 - acc: 0.6133 - val_loss: 1.0423 - val_acc: 0.5927\n",
      "Epoch 2607/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9855 - acc: 0.6063 - val_loss: 1.0299 - val_acc: 0.6028\n",
      "Epoch 2608/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9677 - acc: 0.6093 - val_loss: 1.0243 - val_acc: 0.6026\n",
      "Epoch 2609/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9779 - acc: 0.6079 - val_loss: 1.0556 - val_acc: 0.5950\n",
      "Epoch 2610/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9725 - acc: 0.6125 - val_loss: 1.0474 - val_acc: 0.5953\n",
      "Epoch 2611/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9879 - acc: 0.5992 - val_loss: 1.0498 - val_acc: 0.5927\n",
      "Epoch 2612/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9797 - acc: 0.6071 - val_loss: 1.0271 - val_acc: 0.6040\n",
      "Epoch 2613/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9641 - acc: 0.6144 - val_loss: 1.0333 - val_acc: 0.6011\n",
      "Epoch 2614/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9708 - acc: 0.6163 - val_loss: 1.0296 - val_acc: 0.6034\n",
      "Epoch 2615/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9819 - acc: 0.6092 - val_loss: 1.0246 - val_acc: 0.6046\n",
      "Epoch 2616/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9703 - acc: 0.6140 - val_loss: 1.0424 - val_acc: 0.5994\n",
      "Epoch 2617/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9735 - acc: 0.6103 - val_loss: 1.0203 - val_acc: 0.6078\n",
      "Epoch 2618/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9646 - acc: 0.6162 - val_loss: 1.0423 - val_acc: 0.6060\n",
      "Epoch 2619/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9775 - acc: 0.6130 - val_loss: 1.0475 - val_acc: 0.5950\n",
      "Epoch 2620/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9849 - acc: 0.6064 - val_loss: 1.0428 - val_acc: 0.5921\n",
      "Epoch 2621/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9768 - acc: 0.6074 - val_loss: 1.0429 - val_acc: 0.5979\n",
      "Epoch 2622/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9821 - acc: 0.6091 - val_loss: 1.0347 - val_acc: 0.6037\n",
      "Epoch 2623/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9761 - acc: 0.6105 - val_loss: 1.0460 - val_acc: 0.6072\n",
      "Epoch 2624/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9764 - acc: 0.6136 - val_loss: 1.0415 - val_acc: 0.6002\n",
      "Epoch 2625/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9769 - acc: 0.6143 - val_loss: 1.0504 - val_acc: 0.5994\n",
      "Epoch 2626/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9641 - acc: 0.6158 - val_loss: 1.0368 - val_acc: 0.5997\n",
      "Epoch 2627/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9692 - acc: 0.6158 - val_loss: 1.0342 - val_acc: 0.6052\n",
      "Epoch 2628/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9837 - acc: 0.6133 - val_loss: 1.0320 - val_acc: 0.5936\n",
      "Epoch 2629/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9715 - acc: 0.6137 - val_loss: 1.0364 - val_acc: 0.5906\n",
      "Epoch 2630/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9785 - acc: 0.6108 - val_loss: 1.0412 - val_acc: 0.5947\n",
      "Epoch 2631/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9761 - acc: 0.6047 - val_loss: 1.0524 - val_acc: 0.5936\n",
      "Epoch 2632/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9691 - acc: 0.6117 - val_loss: 1.0439 - val_acc: 0.5915\n",
      "Epoch 2633/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9734 - acc: 0.6140 - val_loss: 1.0284 - val_acc: 0.5994\n",
      "Epoch 2634/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9723 - acc: 0.6130 - val_loss: 1.0152 - val_acc: 0.6031\n",
      "Epoch 2635/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9742 - acc: 0.6077 - val_loss: 1.0218 - val_acc: 0.6072\n",
      "Epoch 2636/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9705 - acc: 0.6126 - val_loss: 1.0252 - val_acc: 0.6020\n",
      "Epoch 2637/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9710 - acc: 0.6146 - val_loss: 1.0528 - val_acc: 0.5985\n",
      "Epoch 2638/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9661 - acc: 0.6118 - val_loss: 1.0366 - val_acc: 0.6017\n",
      "Epoch 2639/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9750 - acc: 0.6115 - val_loss: 1.0332 - val_acc: 0.6084\n",
      "Epoch 2640/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9678 - acc: 0.6136 - val_loss: 1.0301 - val_acc: 0.6014\n",
      "Epoch 2641/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 0.9689 - acc: 0.6153 - val_loss: 1.0349 - val_acc: 0.6040\n",
      "Epoch 2642/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9692 - acc: 0.6158 - val_loss: 1.0273 - val_acc: 0.6040\n",
      "Epoch 2643/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 0.9742 - acc: 0.6126 - val_loss: 1.0411 - val_acc: 0.5959\n",
      "Epoch 2644/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9802 - acc: 0.6044 - val_loss: 1.0294 - val_acc: 0.6046\n",
      "Epoch 2645/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9752 - acc: 0.6108 - val_loss: 1.0199 - val_acc: 0.5973\n",
      "Epoch 2646/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 0.9763 - acc: 0.6125 - val_loss: 1.0344 - val_acc: 0.6002\n",
      "Epoch 2647/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9766 - acc: 0.6111 - val_loss: 1.0205 - val_acc: 0.6046\n",
      "Epoch 2648/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9729 - acc: 0.6114 - val_loss: 1.0385 - val_acc: 0.6040\n",
      "Epoch 2649/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9777 - acc: 0.6148 - val_loss: 1.0167 - val_acc: 0.6060\n",
      "Epoch 2650/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9778 - acc: 0.6158 - val_loss: 1.0165 - val_acc: 0.6034\n",
      "Epoch 2651/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9727 - acc: 0.6135 - val_loss: 1.0283 - val_acc: 0.6078\n",
      "Epoch 2652/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9807 - acc: 0.6090 - val_loss: 1.0235 - val_acc: 0.6078\n",
      "Epoch 2653/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9700 - acc: 0.6135 - val_loss: 1.0432 - val_acc: 0.6002\n",
      "Epoch 2654/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9717 - acc: 0.6090 - val_loss: 1.0240 - val_acc: 0.6049\n",
      "Epoch 2655/3000\n",
      "13766/13766 [==============================] - ETA: 0s - loss: 0.9620 - acc: 0.613 - 1s 44us/step - loss: 0.9621 - acc: 0.6146 - val_loss: 1.0368 - val_acc: 0.6026\n",
      "Epoch 2656/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9777 - acc: 0.6133 - val_loss: 1.0296 - val_acc: 0.6014\n",
      "Epoch 2657/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9705 - acc: 0.6148 - val_loss: 1.0370 - val_acc: 0.6008\n",
      "Epoch 2658/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9741 - acc: 0.6147 - val_loss: 1.0343 - val_acc: 0.6017\n",
      "Epoch 2659/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9667 - acc: 0.6141 - val_loss: 1.0453 - val_acc: 0.5991\n",
      "Epoch 2660/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9675 - acc: 0.6154 - val_loss: 1.0347 - val_acc: 0.6049\n",
      "Epoch 2661/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9758 - acc: 0.6139 - val_loss: 1.0288 - val_acc: 0.6060\n",
      "Epoch 2662/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9730 - acc: 0.6146 - val_loss: 1.0441 - val_acc: 0.5994\n",
      "Epoch 2663/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9729 - acc: 0.6158 - val_loss: 1.0335 - val_acc: 0.5979\n",
      "Epoch 2664/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9792 - acc: 0.6094 - val_loss: 1.0248 - val_acc: 0.6011\n",
      "Epoch 2665/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9749 - acc: 0.6073 - val_loss: 1.0250 - val_acc: 0.6037\n",
      "Epoch 2666/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9675 - acc: 0.6171 - val_loss: 1.0339 - val_acc: 0.6031\n",
      "Epoch 2667/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9674 - acc: 0.6161 - val_loss: 1.0395 - val_acc: 0.5979\n",
      "Epoch 2668/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9810 - acc: 0.6042 - val_loss: 1.0316 - val_acc: 0.5950\n",
      "Epoch 2669/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9670 - acc: 0.6109 - val_loss: 1.0416 - val_acc: 0.5959\n",
      "Epoch 2670/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9719 - acc: 0.6110 - val_loss: 1.0351 - val_acc: 0.6014\n",
      "Epoch 2671/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9661 - acc: 0.6154 - val_loss: 1.0391 - val_acc: 0.6026\n",
      "Epoch 2672/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9704 - acc: 0.6149 - val_loss: 1.0326 - val_acc: 0.6060\n",
      "Epoch 2673/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9712 - acc: 0.6099 - val_loss: 1.0436 - val_acc: 0.5994\n",
      "Epoch 2674/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9790 - acc: 0.6141 - val_loss: 1.0470 - val_acc: 0.5938\n",
      "Epoch 2675/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9749 - acc: 0.6145 - val_loss: 1.0219 - val_acc: 0.6156\n",
      "Epoch 2676/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9824 - acc: 0.6095 - val_loss: 1.0318 - val_acc: 0.6028\n",
      "Epoch 2677/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9808 - acc: 0.6093 - val_loss: 1.0263 - val_acc: 0.6017\n",
      "Epoch 2678/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9687 - acc: 0.6145 - val_loss: 1.0258 - val_acc: 0.5979\n",
      "Epoch 2679/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9662 - acc: 0.6156 - val_loss: 1.0419 - val_acc: 0.5988\n",
      "Epoch 2680/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9707 - acc: 0.6107 - val_loss: 1.0265 - val_acc: 0.5988\n",
      "Epoch 2681/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9709 - acc: 0.6150 - val_loss: 1.0333 - val_acc: 0.6072\n",
      "Epoch 2682/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9872 - acc: 0.6064 - val_loss: 1.0447 - val_acc: 0.6008\n",
      "Epoch 2683/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9607 - acc: 0.6194 - val_loss: 1.0310 - val_acc: 0.6008\n",
      "Epoch 2684/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9631 - acc: 0.6146 - val_loss: 1.0318 - val_acc: 0.6069\n",
      "Epoch 2685/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9750 - acc: 0.6114 - val_loss: 1.0324 - val_acc: 0.5997\n",
      "Epoch 2686/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9579 - acc: 0.6119 - val_loss: 1.0317 - val_acc: 0.6084\n",
      "Epoch 2687/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9744 - acc: 0.6140 - val_loss: 1.0365 - val_acc: 0.6058\n",
      "Epoch 2688/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9737 - acc: 0.6111 - val_loss: 1.0293 - val_acc: 0.6034\n",
      "Epoch 2689/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9624 - acc: 0.6152 - val_loss: 1.0398 - val_acc: 0.5982\n",
      "Epoch 2690/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9664 - acc: 0.6127 - val_loss: 1.0284 - val_acc: 0.6066\n",
      "Epoch 2691/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9762 - acc: 0.6106 - val_loss: 1.0278 - val_acc: 0.6055\n",
      "Epoch 2692/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9731 - acc: 0.6051 - val_loss: 1.0275 - val_acc: 0.6063\n",
      "Epoch 2693/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9716 - acc: 0.6093 - val_loss: 1.0226 - val_acc: 0.6058\n",
      "Epoch 2694/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9604 - acc: 0.6165 - val_loss: 1.0255 - val_acc: 0.6142\n",
      "Epoch 2695/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9747 - acc: 0.6104 - val_loss: 1.0272 - val_acc: 0.6040\n",
      "Epoch 2696/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9694 - acc: 0.6196 - val_loss: 1.0261 - val_acc: 0.6060\n",
      "Epoch 2697/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9771 - acc: 0.6130 - val_loss: 1.0333 - val_acc: 0.6046\n",
      "Epoch 2698/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9757 - acc: 0.6120 - val_loss: 1.0356 - val_acc: 0.6005\n",
      "Epoch 2699/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9671 - acc: 0.6165 - val_loss: 1.0345 - val_acc: 0.6089\n",
      "Epoch 2700/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9707 - acc: 0.6128 - val_loss: 1.0258 - val_acc: 0.6034\n",
      "Epoch 2701/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9768 - acc: 0.6125 - val_loss: 1.0320 - val_acc: 0.6023\n",
      "Epoch 2702/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9670 - acc: 0.6162 - val_loss: 1.0460 - val_acc: 0.5930\n",
      "Epoch 2703/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9752 - acc: 0.6079 - val_loss: 1.0344 - val_acc: 0.5962\n",
      "Epoch 2704/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9743 - acc: 0.6089 - val_loss: 1.0530 - val_acc: 0.5938\n",
      "Epoch 2705/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9622 - acc: 0.6146 - val_loss: 1.0329 - val_acc: 0.6139\n",
      "Epoch 2706/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9789 - acc: 0.6093 - val_loss: 1.0319 - val_acc: 0.5999\n",
      "Epoch 2707/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9654 - acc: 0.6145 - val_loss: 1.0262 - val_acc: 0.6023\n",
      "Epoch 2708/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9789 - acc: 0.6110 - val_loss: 1.0164 - val_acc: 0.6107\n",
      "Epoch 2709/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9704 - acc: 0.6106 - val_loss: 1.0147 - val_acc: 0.6078\n",
      "Epoch 2710/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9886 - acc: 0.6017 - val_loss: 1.0350 - val_acc: 0.5999\n",
      "Epoch 2711/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9804 - acc: 0.6111 - val_loss: 1.0291 - val_acc: 0.6020\n",
      "Epoch 2712/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9775 - acc: 0.6101 - val_loss: 1.0259 - val_acc: 0.6037\n",
      "Epoch 2713/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9721 - acc: 0.6133 - val_loss: 1.0171 - val_acc: 0.6081\n",
      "Epoch 2714/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9668 - acc: 0.6136 - val_loss: 1.0384 - val_acc: 0.5985\n",
      "Epoch 2715/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9763 - acc: 0.6089 - val_loss: 1.0446 - val_acc: 0.5988\n",
      "Epoch 2716/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9717 - acc: 0.6131 - val_loss: 1.0352 - val_acc: 0.6002\n",
      "Epoch 2717/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9647 - acc: 0.6114 - val_loss: 1.0361 - val_acc: 0.5991\n",
      "Epoch 2718/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9714 - acc: 0.6119 - val_loss: 1.0297 - val_acc: 0.6055\n",
      "Epoch 2719/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9793 - acc: 0.6090 - val_loss: 1.0287 - val_acc: 0.6031\n",
      "Epoch 2720/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9688 - acc: 0.6132 - val_loss: 1.0261 - val_acc: 0.5985\n",
      "Epoch 2721/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9737 - acc: 0.6129 - val_loss: 1.0277 - val_acc: 0.5982\n",
      "Epoch 2722/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9705 - acc: 0.6212 - val_loss: 1.0286 - val_acc: 0.6002\n",
      "Epoch 2723/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9693 - acc: 0.6125 - val_loss: 1.0390 - val_acc: 0.5956\n",
      "Epoch 2724/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9679 - acc: 0.6147 - val_loss: 1.0243 - val_acc: 0.6063\n",
      "Epoch 2725/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9711 - acc: 0.6135 - val_loss: 1.0284 - val_acc: 0.6011\n",
      "Epoch 2726/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9675 - acc: 0.6169 - val_loss: 1.0400 - val_acc: 0.6008\n",
      "Epoch 2727/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9742 - acc: 0.6103 - val_loss: 1.0310 - val_acc: 0.6005\n",
      "Epoch 2728/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9766 - acc: 0.6133 - val_loss: 1.0473 - val_acc: 0.5991\n",
      "Epoch 2729/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9761 - acc: 0.6104 - val_loss: 1.0356 - val_acc: 0.5994\n",
      "Epoch 2730/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9767 - acc: 0.6142 - val_loss: 1.0245 - val_acc: 0.6034\n",
      "Epoch 2731/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9646 - acc: 0.6154 - val_loss: 1.0242 - val_acc: 0.6078\n",
      "Epoch 2732/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9683 - acc: 0.6091 - val_loss: 1.0260 - val_acc: 0.6055\n",
      "Epoch 2733/3000\n",
      "13766/13766 [==============================] - 1s 40us/step - loss: 0.9906 - acc: 0.6057 - val_loss: 1.0353 - val_acc: 0.5988\n",
      "Epoch 2734/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9818 - acc: 0.6078 - val_loss: 1.0295 - val_acc: 0.6072\n",
      "Epoch 2735/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9696 - acc: 0.6147 - val_loss: 1.0274 - val_acc: 0.6055\n",
      "Epoch 2736/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9782 - acc: 0.6131 - val_loss: 1.0228 - val_acc: 0.6028\n",
      "Epoch 2737/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9645 - acc: 0.6191 - val_loss: 1.0303 - val_acc: 0.6034\n",
      "Epoch 2738/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9736 - acc: 0.6140 - val_loss: 1.0410 - val_acc: 0.5976\n",
      "Epoch 2739/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9625 - acc: 0.6109 - val_loss: 1.0296 - val_acc: 0.6005\n",
      "Epoch 2740/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9722 - acc: 0.6123 - val_loss: 1.0288 - val_acc: 0.6014\n",
      "Epoch 2741/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9723 - acc: 0.6115 - val_loss: 1.0280 - val_acc: 0.6028\n",
      "Epoch 2742/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9667 - acc: 0.6137 - val_loss: 1.0405 - val_acc: 0.5985\n",
      "Epoch 2743/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9813 - acc: 0.6061 - val_loss: 1.0194 - val_acc: 0.6026\n",
      "Epoch 2744/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9678 - acc: 0.6124 - val_loss: 1.0200 - val_acc: 0.6095\n",
      "Epoch 2745/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9653 - acc: 0.6153 - val_loss: 1.0286 - val_acc: 0.6046\n",
      "Epoch 2746/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9685 - acc: 0.6137 - val_loss: 1.0307 - val_acc: 0.5994\n",
      "Epoch 2747/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9687 - acc: 0.6138 - val_loss: 1.0220 - val_acc: 0.6092\n",
      "Epoch 2748/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9628 - acc: 0.6156 - val_loss: 1.0259 - val_acc: 0.5988\n",
      "Epoch 2749/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9728 - acc: 0.6099 - val_loss: 1.0303 - val_acc: 0.6072\n",
      "Epoch 2750/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9724 - acc: 0.6120 - val_loss: 1.0311 - val_acc: 0.6046\n",
      "Epoch 2751/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9693 - acc: 0.6153 - val_loss: 1.0403 - val_acc: 0.5959\n",
      "Epoch 2752/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9770 - acc: 0.6087 - val_loss: 1.0186 - val_acc: 0.6023\n",
      "Epoch 2753/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9616 - acc: 0.6127 - val_loss: 1.0244 - val_acc: 0.6043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2754/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9686 - acc: 0.6178 - val_loss: 1.0321 - val_acc: 0.6058\n",
      "Epoch 2755/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9600 - acc: 0.6153 - val_loss: 1.0289 - val_acc: 0.6049\n",
      "Epoch 2756/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9753 - acc: 0.6114 - val_loss: 1.0363 - val_acc: 0.6020\n",
      "Epoch 2757/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9721 - acc: 0.6110 - val_loss: 1.0257 - val_acc: 0.6087\n",
      "Epoch 2758/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9690 - acc: 0.6118 - val_loss: 1.0202 - val_acc: 0.6124\n",
      "Epoch 2759/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9696 - acc: 0.6098 - val_loss: 1.0362 - val_acc: 0.6002\n",
      "Epoch 2760/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9653 - acc: 0.6169 - val_loss: 1.0270 - val_acc: 0.6002\n",
      "Epoch 2761/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9729 - acc: 0.6061 - val_loss: 1.0212 - val_acc: 0.6095\n",
      "Epoch 2762/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9620 - acc: 0.6216 - val_loss: 1.0338 - val_acc: 0.5973\n",
      "Epoch 2763/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9776 - acc: 0.6085 - val_loss: 1.0282 - val_acc: 0.5985\n",
      "Epoch 2764/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9752 - acc: 0.6157 - val_loss: 1.0194 - val_acc: 0.6121\n",
      "Epoch 2765/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9658 - acc: 0.6159 - val_loss: 1.0290 - val_acc: 0.5956\n",
      "Epoch 2766/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9621 - acc: 0.6159 - val_loss: 1.0441 - val_acc: 0.5965\n",
      "Epoch 2767/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9726 - acc: 0.6112 - val_loss: 1.0296 - val_acc: 0.6002\n",
      "Epoch 2768/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9626 - acc: 0.6194 - val_loss: 1.0503 - val_acc: 0.6017\n",
      "Epoch 2769/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9773 - acc: 0.6071 - val_loss: 1.0343 - val_acc: 0.5999\n",
      "Epoch 2770/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9681 - acc: 0.6173 - val_loss: 1.0199 - val_acc: 0.6078\n",
      "Epoch 2771/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9697 - acc: 0.6164 - val_loss: 1.0235 - val_acc: 0.6034\n",
      "Epoch 2772/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9654 - acc: 0.6117 - val_loss: 1.0257 - val_acc: 0.6055\n",
      "Epoch 2773/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9702 - acc: 0.6130 - val_loss: 1.0357 - val_acc: 0.5956\n",
      "Epoch 2774/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9626 - acc: 0.6149 - val_loss: 1.0389 - val_acc: 0.5956\n",
      "Epoch 2775/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9688 - acc: 0.6159 - val_loss: 1.0274 - val_acc: 0.6005\n",
      "Epoch 2776/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9696 - acc: 0.6103 - val_loss: 1.0378 - val_acc: 0.5982\n",
      "Epoch 2777/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9742 - acc: 0.6074 - val_loss: 1.0287 - val_acc: 0.5985\n",
      "Epoch 2778/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9790 - acc: 0.6109 - val_loss: 1.0275 - val_acc: 0.6031\n",
      "Epoch 2779/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9695 - acc: 0.6076 - val_loss: 1.0338 - val_acc: 0.5936\n",
      "Epoch 2780/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9698 - acc: 0.6119 - val_loss: 1.0333 - val_acc: 0.5997\n",
      "Epoch 2781/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9716 - acc: 0.6074 - val_loss: 1.0258 - val_acc: 0.6046\n",
      "Epoch 2782/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9574 - acc: 0.6202 - val_loss: 1.0206 - val_acc: 0.6084\n",
      "Epoch 2783/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9764 - acc: 0.6059 - val_loss: 1.0327 - val_acc: 0.5979\n",
      "Epoch 2784/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9647 - acc: 0.6194 - val_loss: 1.0496 - val_acc: 0.5970\n",
      "Epoch 2785/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9739 - acc: 0.6119 - val_loss: 1.0441 - val_acc: 0.5965\n",
      "Epoch 2786/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9683 - acc: 0.6153 - val_loss: 1.0220 - val_acc: 0.6028\n",
      "Epoch 2787/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9830 - acc: 0.6056 - val_loss: 1.0381 - val_acc: 0.6060\n",
      "Epoch 2788/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9746 - acc: 0.6132 - val_loss: 1.0338 - val_acc: 0.6049\n",
      "Epoch 2789/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9639 - acc: 0.6138 - val_loss: 1.0346 - val_acc: 0.6005\n",
      "Epoch 2790/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9688 - acc: 0.6140 - val_loss: 1.0434 - val_acc: 0.6005\n",
      "Epoch 2791/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9769 - acc: 0.6077 - val_loss: 1.0342 - val_acc: 0.5997\n",
      "Epoch 2792/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9660 - acc: 0.6164 - val_loss: 1.0284 - val_acc: 0.6060\n",
      "Epoch 2793/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9739 - acc: 0.6155 - val_loss: 1.0294 - val_acc: 0.6101\n",
      "Epoch 2794/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9766 - acc: 0.6082 - val_loss: 1.0357 - val_acc: 0.5930\n",
      "Epoch 2795/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9623 - acc: 0.6181 - val_loss: 1.0226 - val_acc: 0.6084\n",
      "Epoch 2796/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9690 - acc: 0.6146 - val_loss: 1.0393 - val_acc: 0.5959\n",
      "Epoch 2797/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9713 - acc: 0.6138 - val_loss: 1.0238 - val_acc: 0.6026\n",
      "Epoch 2798/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9724 - acc: 0.6146 - val_loss: 1.0428 - val_acc: 0.5906\n",
      "Epoch 2799/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9658 - acc: 0.6143 - val_loss: 1.0343 - val_acc: 0.6081\n",
      "Epoch 2800/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9665 - acc: 0.6147 - val_loss: 1.0337 - val_acc: 0.6060\n",
      "Epoch 2801/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9716 - acc: 0.6122 - val_loss: 1.0398 - val_acc: 0.6052\n",
      "Epoch 2802/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9765 - acc: 0.6073 - val_loss: 1.0184 - val_acc: 0.6069\n",
      "Epoch 2803/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9669 - acc: 0.6175 - val_loss: 1.0279 - val_acc: 0.6119\n",
      "Epoch 2804/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9811 - acc: 0.6058 - val_loss: 1.0354 - val_acc: 0.6002\n",
      "Epoch 2805/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9781 - acc: 0.6130 - val_loss: 1.0379 - val_acc: 0.6060\n",
      "Epoch 2806/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9685 - acc: 0.6164 - val_loss: 1.0238 - val_acc: 0.6084\n",
      "Epoch 2807/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9645 - acc: 0.6144 - val_loss: 1.0277 - val_acc: 0.6078\n",
      "Epoch 2808/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9755 - acc: 0.6137 - val_loss: 1.0185 - val_acc: 0.6113\n",
      "Epoch 2809/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9704 - acc: 0.6121 - val_loss: 1.0242 - val_acc: 0.6124\n",
      "Epoch 2810/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9710 - acc: 0.6158 - val_loss: 1.0288 - val_acc: 0.6034\n",
      "Epoch 2811/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9703 - acc: 0.6143 - val_loss: 1.0209 - val_acc: 0.6060\n",
      "Epoch 2812/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9688 - acc: 0.6167 - val_loss: 1.0161 - val_acc: 0.6110\n",
      "Epoch 2813/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9666 - acc: 0.6183 - val_loss: 1.0398 - val_acc: 0.6020\n",
      "Epoch 2814/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9695 - acc: 0.6144 - val_loss: 1.0356 - val_acc: 0.5927\n",
      "Epoch 2815/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9713 - acc: 0.6087 - val_loss: 1.0402 - val_acc: 0.5988\n",
      "Epoch 2816/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9690 - acc: 0.6125 - val_loss: 1.0307 - val_acc: 0.6095\n",
      "Epoch 2817/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9697 - acc: 0.6175 - val_loss: 1.0190 - val_acc: 0.6055\n",
      "Epoch 2818/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9749 - acc: 0.6097 - val_loss: 1.0278 - val_acc: 0.6026\n",
      "Epoch 2819/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9620 - acc: 0.6125 - val_loss: 1.0300 - val_acc: 0.6063\n",
      "Epoch 2820/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9658 - acc: 0.6147 - val_loss: 1.0260 - val_acc: 0.6020\n",
      "Epoch 2821/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9722 - acc: 0.6110 - val_loss: 1.0250 - val_acc: 0.6028\n",
      "Epoch 2822/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9661 - acc: 0.6166 - val_loss: 1.0224 - val_acc: 0.6072\n",
      "Epoch 2823/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9675 - acc: 0.6156 - val_loss: 1.0273 - val_acc: 0.6052\n",
      "Epoch 2824/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9750 - acc: 0.6136 - val_loss: 1.0323 - val_acc: 0.6014\n",
      "Epoch 2825/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9703 - acc: 0.6125 - val_loss: 1.0254 - val_acc: 0.6034\n",
      "Epoch 2826/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9736 - acc: 0.6117 - val_loss: 1.0350 - val_acc: 0.6031\n",
      "Epoch 2827/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9811 - acc: 0.6063 - val_loss: 1.0433 - val_acc: 0.5965\n",
      "Epoch 2828/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9690 - acc: 0.6154 - val_loss: 1.0226 - val_acc: 0.6092\n",
      "Epoch 2829/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9731 - acc: 0.6111 - val_loss: 1.0261 - val_acc: 0.6055\n",
      "Epoch 2830/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9648 - acc: 0.6152 - val_loss: 1.0282 - val_acc: 0.6081\n",
      "Epoch 2831/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9632 - acc: 0.6138 - val_loss: 1.0298 - val_acc: 0.6049\n",
      "Epoch 2832/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9700 - acc: 0.6151 - val_loss: 1.0445 - val_acc: 0.6034\n",
      "Epoch 2833/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9626 - acc: 0.6173 - val_loss: 1.0524 - val_acc: 0.6011\n",
      "Epoch 2834/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9692 - acc: 0.6165 - val_loss: 1.0403 - val_acc: 0.6063\n",
      "Epoch 2835/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9664 - acc: 0.6120 - val_loss: 1.0331 - val_acc: 0.6060\n",
      "Epoch 2836/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9718 - acc: 0.6111 - val_loss: 1.0291 - val_acc: 0.6046\n",
      "Epoch 2837/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9884 - acc: 0.6036 - val_loss: 1.0222 - val_acc: 0.6084\n",
      "Epoch 2838/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9613 - acc: 0.6166 - val_loss: 1.0465 - val_acc: 0.6008\n",
      "Epoch 2839/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9720 - acc: 0.6118 - val_loss: 1.0287 - val_acc: 0.6026\n",
      "Epoch 2840/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9636 - acc: 0.6159 - val_loss: 1.0411 - val_acc: 0.6011\n",
      "Epoch 2841/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9617 - acc: 0.6210 - val_loss: 1.0271 - val_acc: 0.6075\n",
      "Epoch 2842/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9655 - acc: 0.6151 - val_loss: 1.0334 - val_acc: 0.6005\n",
      "Epoch 2843/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9662 - acc: 0.6178 - val_loss: 1.0385 - val_acc: 0.6002\n",
      "Epoch 2844/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9683 - acc: 0.6133 - val_loss: 1.0357 - val_acc: 0.5991\n",
      "Epoch 2845/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9797 - acc: 0.6088 - val_loss: 1.0427 - val_acc: 0.6008\n",
      "Epoch 2846/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9730 - acc: 0.6098 - val_loss: 1.0403 - val_acc: 0.5959\n",
      "Epoch 2847/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9735 - acc: 0.6138 - val_loss: 1.0310 - val_acc: 0.6060\n",
      "Epoch 2848/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9745 - acc: 0.6182 - val_loss: 1.0158 - val_acc: 0.6119\n",
      "Epoch 2849/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9593 - acc: 0.6181 - val_loss: 1.0210 - val_acc: 0.6078\n",
      "Epoch 2850/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9656 - acc: 0.6152 - val_loss: 1.0334 - val_acc: 0.6055\n",
      "Epoch 2851/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9680 - acc: 0.6159 - val_loss: 1.0314 - val_acc: 0.6049\n",
      "Epoch 2852/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9751 - acc: 0.6133 - val_loss: 1.0241 - val_acc: 0.6072\n",
      "Epoch 2853/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9697 - acc: 0.6140 - val_loss: 1.0287 - val_acc: 0.6052\n",
      "Epoch 2854/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9676 - acc: 0.6138 - val_loss: 1.0428 - val_acc: 0.5965\n",
      "Epoch 2855/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9626 - acc: 0.6162 - val_loss: 1.0330 - val_acc: 0.6075\n",
      "Epoch 2856/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9661 - acc: 0.6119 - val_loss: 1.0401 - val_acc: 0.5953\n",
      "Epoch 2857/3000\n",
      "13766/13766 [==============================] - 1s 66us/step - loss: 0.9730 - acc: 0.6112 - val_loss: 1.0414 - val_acc: 0.6037\n",
      "Epoch 2858/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9730 - acc: 0.6130 - val_loss: 1.0368 - val_acc: 0.6043\n",
      "Epoch 2859/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9671 - acc: 0.6142 - val_loss: 1.0194 - val_acc: 0.6098\n",
      "Epoch 2860/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9635 - acc: 0.6166 - val_loss: 1.0229 - val_acc: 0.6133\n",
      "Epoch 2861/3000\n",
      "13766/13766 [==============================] - 1s 67us/step - loss: 0.9675 - acc: 0.6146 - val_loss: 1.0297 - val_acc: 0.6124\n",
      "Epoch 2862/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9647 - acc: 0.6134 - val_loss: 1.0257 - val_acc: 0.6060\n",
      "Epoch 2863/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9791 - acc: 0.6090 - val_loss: 1.0201 - val_acc: 0.6095\n",
      "Epoch 2864/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9630 - acc: 0.6169 - val_loss: 1.0382 - val_acc: 0.5991\n",
      "Epoch 2865/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9635 - acc: 0.6119 - val_loss: 1.0281 - val_acc: 0.6055\n",
      "Epoch 2866/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9626 - acc: 0.6188 - val_loss: 1.0219 - val_acc: 0.5999\n",
      "Epoch 2867/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9570 - acc: 0.6186 - val_loss: 1.0208 - val_acc: 0.5997\n",
      "Epoch 2868/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9666 - acc: 0.6189 - val_loss: 1.0286 - val_acc: 0.6078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2869/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9645 - acc: 0.6133 - val_loss: 1.0192 - val_acc: 0.6078\n",
      "Epoch 2870/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9676 - acc: 0.6127 - val_loss: 1.0307 - val_acc: 0.6104\n",
      "Epoch 2871/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9602 - acc: 0.6212 - val_loss: 1.0254 - val_acc: 0.6011\n",
      "Epoch 2872/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9725 - acc: 0.6072 - val_loss: 1.0230 - val_acc: 0.6023\n",
      "Epoch 2873/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9700 - acc: 0.6172 - val_loss: 1.0225 - val_acc: 0.6049\n",
      "Epoch 2874/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9703 - acc: 0.6145 - val_loss: 1.0218 - val_acc: 0.6049\n",
      "Epoch 2875/3000\n",
      "13766/13766 [==============================] - 1s 60us/step - loss: 0.9692 - acc: 0.6103 - val_loss: 1.0227 - val_acc: 0.6072\n",
      "Epoch 2876/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9617 - acc: 0.6142 - val_loss: 1.0302 - val_acc: 0.6078\n",
      "Epoch 2877/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9714 - acc: 0.6117 - val_loss: 1.0275 - val_acc: 0.6011\n",
      "Epoch 2878/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9639 - acc: 0.6151 - val_loss: 1.0302 - val_acc: 0.6153\n",
      "Epoch 2879/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9645 - acc: 0.6164 - val_loss: 1.0490 - val_acc: 0.5988\n",
      "Epoch 2880/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9705 - acc: 0.6143 - val_loss: 1.0335 - val_acc: 0.6081\n",
      "Epoch 2881/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9694 - acc: 0.6149 - val_loss: 1.0498 - val_acc: 0.5909\n",
      "Epoch 2882/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9731 - acc: 0.6131 - val_loss: 1.0334 - val_acc: 0.5997\n",
      "Epoch 2883/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9597 - acc: 0.6180 - val_loss: 1.0331 - val_acc: 0.6087\n",
      "Epoch 2884/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9710 - acc: 0.6108 - val_loss: 1.0309 - val_acc: 0.6058\n",
      "Epoch 2885/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9598 - acc: 0.6172 - val_loss: 1.0335 - val_acc: 0.6008\n",
      "Epoch 2886/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9678 - acc: 0.6146 - val_loss: 1.0289 - val_acc: 0.6060\n",
      "Epoch 2887/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9572 - acc: 0.6178 - val_loss: 1.0520 - val_acc: 0.6034\n",
      "Epoch 2888/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9805 - acc: 0.6117 - val_loss: 1.0289 - val_acc: 0.6031\n",
      "Epoch 2889/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9679 - acc: 0.6146 - val_loss: 1.0454 - val_acc: 0.5997\n",
      "Epoch 2890/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9651 - acc: 0.6153 - val_loss: 1.0195 - val_acc: 0.6034\n",
      "Epoch 2891/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9667 - acc: 0.6122 - val_loss: 1.0352 - val_acc: 0.6087\n",
      "Epoch 2892/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9683 - acc: 0.6132 - val_loss: 1.0378 - val_acc: 0.6023\n",
      "Epoch 2893/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9610 - acc: 0.6167 - val_loss: 1.0328 - val_acc: 0.6069\n",
      "Epoch 2894/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9647 - acc: 0.6193 - val_loss: 1.0600 - val_acc: 0.5982\n",
      "Epoch 2895/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9717 - acc: 0.6121 - val_loss: 1.0252 - val_acc: 0.6043\n",
      "Epoch 2896/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9706 - acc: 0.6126 - val_loss: 1.0326 - val_acc: 0.6005\n",
      "Epoch 2897/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9726 - acc: 0.6144 - val_loss: 1.0216 - val_acc: 0.6081\n",
      "Epoch 2898/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9635 - acc: 0.6156 - val_loss: 1.0310 - val_acc: 0.6031\n",
      "Epoch 2899/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9679 - acc: 0.6155 - val_loss: 1.0302 - val_acc: 0.6026\n",
      "Epoch 2900/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9600 - acc: 0.6199 - val_loss: 1.0386 - val_acc: 0.6002\n",
      "Epoch 2901/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9579 - acc: 0.6167 - val_loss: 1.0485 - val_acc: 0.5924\n",
      "Epoch 2902/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9693 - acc: 0.6150 - val_loss: 1.0332 - val_acc: 0.6046\n",
      "Epoch 2903/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9742 - acc: 0.6112 - val_loss: 1.0380 - val_acc: 0.5982\n",
      "Epoch 2904/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9704 - acc: 0.6196 - val_loss: 1.0283 - val_acc: 0.6078\n",
      "Epoch 2905/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9544 - acc: 0.6190 - val_loss: 1.0268 - val_acc: 0.6075\n",
      "Epoch 2906/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9584 - acc: 0.6194 - val_loss: 1.0435 - val_acc: 0.6014\n",
      "Epoch 2907/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9661 - acc: 0.6167 - val_loss: 1.0255 - val_acc: 0.6104\n",
      "Epoch 2908/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9650 - acc: 0.6160 - val_loss: 1.0306 - val_acc: 0.6081\n",
      "Epoch 2909/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9694 - acc: 0.6174 - val_loss: 1.0343 - val_acc: 0.6089\n",
      "Epoch 2910/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9648 - acc: 0.6125 - val_loss: 1.0444 - val_acc: 0.6049\n",
      "Epoch 2911/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9730 - acc: 0.6122 - val_loss: 1.0464 - val_acc: 0.6095\n",
      "Epoch 2912/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9543 - acc: 0.6199 - val_loss: 1.0362 - val_acc: 0.6060\n",
      "Epoch 2913/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9633 - acc: 0.6184 - val_loss: 1.0358 - val_acc: 0.5999\n",
      "Epoch 2914/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9651 - acc: 0.6135 - val_loss: 1.0357 - val_acc: 0.6040\n",
      "Epoch 2915/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9717 - acc: 0.6186 - val_loss: 1.0209 - val_acc: 0.6107\n",
      "Epoch 2916/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9488 - acc: 0.6208 - val_loss: 1.0283 - val_acc: 0.6150\n",
      "Epoch 2917/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9600 - acc: 0.6175 - val_loss: 1.0281 - val_acc: 0.6087\n",
      "Epoch 2918/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9738 - acc: 0.6130 - val_loss: 1.0314 - val_acc: 0.5970\n",
      "Epoch 2919/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9795 - acc: 0.6172 - val_loss: 1.0344 - val_acc: 0.6008\n",
      "Epoch 2920/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9721 - acc: 0.6119 - val_loss: 1.0283 - val_acc: 0.6084\n",
      "Epoch 2921/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9594 - acc: 0.6181 - val_loss: 1.0313 - val_acc: 0.6130\n",
      "Epoch 2922/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9649 - acc: 0.6134 - val_loss: 1.0397 - val_acc: 0.6008\n",
      "Epoch 2923/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9682 - acc: 0.6119 - val_loss: 1.0321 - val_acc: 0.6052\n",
      "Epoch 2924/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9590 - acc: 0.6209 - val_loss: 1.0302 - val_acc: 0.6040\n",
      "Epoch 2925/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9645 - acc: 0.6164 - val_loss: 1.0376 - val_acc: 0.6145\n",
      "Epoch 2926/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9702 - acc: 0.6141 - val_loss: 1.0332 - val_acc: 0.5976\n",
      "Epoch 2927/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9623 - acc: 0.6146 - val_loss: 1.0276 - val_acc: 0.6011\n",
      "Epoch 2928/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9646 - acc: 0.6176 - val_loss: 1.0382 - val_acc: 0.6005\n",
      "Epoch 2929/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9677 - acc: 0.6119 - val_loss: 1.0158 - val_acc: 0.6060\n",
      "Epoch 2930/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9684 - acc: 0.6135 - val_loss: 1.0248 - val_acc: 0.6008\n",
      "Epoch 2931/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9679 - acc: 0.6132 - val_loss: 1.0247 - val_acc: 0.6040\n",
      "Epoch 2932/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9622 - acc: 0.6146 - val_loss: 1.0366 - val_acc: 0.6055\n",
      "Epoch 2933/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9643 - acc: 0.6154 - val_loss: 1.0483 - val_acc: 0.6023\n",
      "Epoch 2934/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9762 - acc: 0.6116 - val_loss: 1.0287 - val_acc: 0.6075\n",
      "Epoch 2935/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9758 - acc: 0.6152 - val_loss: 1.0345 - val_acc: 0.6081\n",
      "Epoch 2936/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9696 - acc: 0.6154 - val_loss: 1.0208 - val_acc: 0.6107\n",
      "Epoch 2937/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9645 - acc: 0.6207 - val_loss: 1.0270 - val_acc: 0.6055\n",
      "Epoch 2938/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9753 - acc: 0.6068 - val_loss: 1.0320 - val_acc: 0.6089\n",
      "Epoch 2939/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9498 - acc: 0.6218 - val_loss: 1.0342 - val_acc: 0.6127\n",
      "Epoch 2940/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9562 - acc: 0.6176 - val_loss: 1.0427 - val_acc: 0.6037\n",
      "Epoch 2941/3000\n",
      "13766/13766 [==============================] - 1s 41us/step - loss: 0.9759 - acc: 0.6140 - val_loss: 1.0422 - val_acc: 0.5973\n",
      "Epoch 2942/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9609 - acc: 0.6218 - val_loss: 1.0382 - val_acc: 0.6049\n",
      "Epoch 2943/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9591 - acc: 0.6217 - val_loss: 1.0318 - val_acc: 0.6066\n",
      "Epoch 2944/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9733 - acc: 0.6130 - val_loss: 1.0358 - val_acc: 0.6092\n",
      "Epoch 2945/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9643 - acc: 0.6160 - val_loss: 1.0307 - val_acc: 0.6168\n",
      "Epoch 2946/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9723 - acc: 0.6077 - val_loss: 1.0335 - val_acc: 0.6028\n",
      "Epoch 2947/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9766 - acc: 0.6117 - val_loss: 1.0416 - val_acc: 0.5967\n",
      "Epoch 2948/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9695 - acc: 0.6135 - val_loss: 1.0402 - val_acc: 0.5965\n",
      "Epoch 2949/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9640 - acc: 0.6159 - val_loss: 1.0348 - val_acc: 0.6031\n",
      "Epoch 2950/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9686 - acc: 0.6109 - val_loss: 1.0238 - val_acc: 0.6104\n",
      "Epoch 2951/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9647 - acc: 0.6146 - val_loss: 1.0279 - val_acc: 0.6034\n",
      "Epoch 2952/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9699 - acc: 0.6146 - val_loss: 1.0250 - val_acc: 0.6101\n",
      "Epoch 2953/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9577 - acc: 0.6175 - val_loss: 1.0299 - val_acc: 0.6075\n",
      "Epoch 2954/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9498 - acc: 0.6205 - val_loss: 1.0264 - val_acc: 0.6069\n",
      "Epoch 2955/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9687 - acc: 0.6127 - val_loss: 1.0375 - val_acc: 0.6002\n",
      "Epoch 2956/3000\n",
      "13766/13766 [==============================] - 1s 42us/step - loss: 0.9605 - acc: 0.6144 - val_loss: 1.0434 - val_acc: 0.5959\n",
      "Epoch 2957/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9657 - acc: 0.6134 - val_loss: 1.0270 - val_acc: 0.5982\n",
      "Epoch 2958/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9628 - acc: 0.6172 - val_loss: 1.0382 - val_acc: 0.6040\n",
      "Epoch 2959/3000\n",
      "13766/13766 [==============================] - 1s 72us/step - loss: 0.9676 - acc: 0.6146 - val_loss: 1.0274 - val_acc: 0.6014\n",
      "Epoch 2960/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9665 - acc: 0.6205 - val_loss: 1.0393 - val_acc: 0.6023\n",
      "Epoch 2961/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9584 - acc: 0.6173 - val_loss: 1.0268 - val_acc: 0.6087\n",
      "Epoch 2962/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9629 - acc: 0.6204 - val_loss: 1.0331 - val_acc: 0.6066\n",
      "Epoch 2963/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9687 - acc: 0.6138 - val_loss: 1.0284 - val_acc: 0.6078\n",
      "Epoch 2964/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9659 - acc: 0.6137 - val_loss: 1.0293 - val_acc: 0.5991\n",
      "Epoch 2965/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9691 - acc: 0.6164 - val_loss: 1.0407 - val_acc: 0.6037\n",
      "Epoch 2966/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9695 - acc: 0.6156 - val_loss: 1.0360 - val_acc: 0.5967\n",
      "Epoch 2967/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9781 - acc: 0.6111 - val_loss: 1.0360 - val_acc: 0.6043\n",
      "Epoch 2968/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9615 - acc: 0.6148 - val_loss: 1.0461 - val_acc: 0.5970\n",
      "Epoch 2969/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9580 - acc: 0.6170 - val_loss: 1.0381 - val_acc: 0.5985\n",
      "Epoch 2970/3000\n",
      "13766/13766 [==============================] - 1s 47us/step - loss: 0.9645 - acc: 0.6145 - val_loss: 1.0369 - val_acc: 0.6023\n",
      "Epoch 2971/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9685 - acc: 0.6159 - val_loss: 1.0183 - val_acc: 0.6060\n",
      "Epoch 2972/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9613 - acc: 0.6162 - val_loss: 1.0296 - val_acc: 0.6043\n",
      "Epoch 2973/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9601 - acc: 0.6194 - val_loss: 1.0278 - val_acc: 0.6092\n",
      "Epoch 2974/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9804 - acc: 0.6109 - val_loss: 1.0223 - val_acc: 0.6049\n",
      "Epoch 2975/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9630 - acc: 0.6138 - val_loss: 1.0186 - val_acc: 0.6092\n",
      "Epoch 2976/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9559 - acc: 0.6198 - val_loss: 1.0306 - val_acc: 0.6060\n",
      "Epoch 2977/3000\n",
      "13766/13766 [==============================] - 1s 45us/step - loss: 0.9629 - acc: 0.6151 - val_loss: 1.0293 - val_acc: 0.6037\n",
      "Epoch 2978/3000\n",
      "13766/13766 [==============================] - 1s 43us/step - loss: 0.9741 - acc: 0.6099 - val_loss: 1.0464 - val_acc: 0.6002\n",
      "Epoch 2979/3000\n",
      "13766/13766 [==============================] - 1s 46us/step - loss: 0.9644 - acc: 0.6144 - val_loss: 1.0370 - val_acc: 0.6055\n",
      "Epoch 2980/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9585 - acc: 0.6151 - val_loss: 1.0422 - val_acc: 0.6017\n",
      "Epoch 2981/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9629 - acc: 0.6175 - val_loss: 1.0399 - val_acc: 0.6026\n",
      "Epoch 2982/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9638 - acc: 0.6125 - val_loss: 1.0244 - val_acc: 0.6092\n",
      "Epoch 2983/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9626 - acc: 0.6127 - val_loss: 1.0258 - val_acc: 0.6069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2984/3000\n",
      "13766/13766 [==============================] - 1s 44us/step - loss: 0.9804 - acc: 0.6087 - val_loss: 1.0257 - val_acc: 0.6104\n",
      "Epoch 2985/3000\n",
      "13766/13766 [==============================] - 1s 48us/step - loss: 0.9626 - acc: 0.6140 - val_loss: 1.0287 - val_acc: 0.6005\n",
      "Epoch 2986/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9618 - acc: 0.6132 - val_loss: 1.0276 - val_acc: 0.6026\n",
      "Epoch 2987/3000\n",
      "13766/13766 [==============================] - 1s 55us/step - loss: 0.9641 - acc: 0.6177 - val_loss: 1.0402 - val_acc: 0.6034\n",
      "Epoch 2988/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9573 - acc: 0.6228 - val_loss: 1.0310 - val_acc: 0.6081\n",
      "Epoch 2989/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9501 - acc: 0.6178 - val_loss: 1.0330 - val_acc: 0.6087\n",
      "Epoch 2990/3000\n",
      "13766/13766 [==============================] - 1s 53us/step - loss: 0.9664 - acc: 0.6143 - val_loss: 1.0329 - val_acc: 0.6069\n",
      "Epoch 2991/3000\n",
      "13766/13766 [==============================] - 1s 54us/step - loss: 0.9558 - acc: 0.6203 - val_loss: 1.0321 - val_acc: 0.6063\n",
      "Epoch 2992/3000\n",
      "13766/13766 [==============================] - 1s 58us/step - loss: 0.9651 - acc: 0.6167 - val_loss: 1.0152 - val_acc: 0.6078\n",
      "Epoch 2993/3000\n",
      "13766/13766 [==============================] - 1s 59us/step - loss: 0.9659 - acc: 0.6140 - val_loss: 1.0485 - val_acc: 0.6008\n",
      "Epoch 2994/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9717 - acc: 0.6106 - val_loss: 1.0492 - val_acc: 0.5999\n",
      "Epoch 2995/3000\n",
      "13766/13766 [==============================] - 1s 56us/step - loss: 0.9755 - acc: 0.6117 - val_loss: 1.0312 - val_acc: 0.5997\n",
      "Epoch 2996/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9618 - acc: 0.6178 - val_loss: 1.0356 - val_acc: 0.6046\n",
      "Epoch 2997/3000\n",
      "13766/13766 [==============================] - 1s 49us/step - loss: 0.9563 - acc: 0.6217 - val_loss: 1.0348 - val_acc: 0.6026\n",
      "Epoch 2998/3000\n",
      "13766/13766 [==============================] - 1s 51us/step - loss: 0.9536 - acc: 0.6194 - val_loss: 1.0251 - val_acc: 0.6136\n",
      "Epoch 2999/3000\n",
      "13766/13766 [==============================] - 1s 52us/step - loss: 0.9539 - acc: 0.6227 - val_loss: 1.0255 - val_acc: 0.6095\n",
      "Epoch 3000/3000\n",
      "13766/13766 [==============================] - 1s 50us/step - loss: 0.9705 - acc: 0.6137 - val_loss: 1.0307 - val_acc: 0.6002\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42,stratify=Y)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "Y_train=Y_train.to_numpy()\n",
    "Y_train = Y_train.reshape(len(Y_train), 1)\n",
    "Y_train = onehot_encoder.fit_transform(Y_train)\n",
    "old=Y_test\n",
    "Y_test =Y_test.to_numpy()\n",
    "Y_test = Y_test.reshape(len(Y_test), 1)\n",
    "Y_test = onehot_encoder.transform(Y_test)\n",
    "\n",
    "# c_weight = {0: 1.75, 1: 1, 2: 2}\n",
    "\n",
    "opt=optimizers.Adam(lr=0.001);\n",
    "# 0.001\n",
    "model1 = keras.models.Sequential()\n",
    "model1.add(keras.layers.Dense(units=256, activation='relu',input_dim=X_train.shape[1]))\n",
    "# model1.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model1.add(keras.layers.Dropout(0.1))\n",
    "model1.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model1.add(keras.layers.Dropout(0.1))\n",
    "model1.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model1.add(keras.layers.Dropout(0.1))\n",
    "model1.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "model1.add(keras.layers.Dropout(0.1))\n",
    "model1.add(keras.layers.Dense(units=16, activation='relu'))\n",
    "model1.add(keras.layers.Dropout(0.1))\n",
    "model1.add(keras.layers.Dense(units=8, activation='relu'))\n",
    "model1.add(keras.layers.Dropout(0.1))\n",
    "model1.add(keras.layers.Dense(units=5, activation='softmax'))\n",
    "model1.summary()\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'],)\n",
    "history=model1.fit(X_train, Y_train,\n",
    "  batch_size=128,\n",
    "  epochs=3000,\n",
    "  verbose=1,\n",
    "  class_weight=class_weights,\n",
    "  validation_data=(X_test, Y_test),\n",
    "#   callbacks = [EarlyStopping(monitor='val_loss', patience=5)],\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdd3hUZfbA8e+ZVHpHkWJAwQIoJRTLKqgINqzrYkdcWV1F/FlWsGIvay+roqIiIigqoCIgKjZAqUqvgoTee0LK+f1x7yQzk5nJJMxkUs7nefJk7nvbe5kwZ94uqooxxhgTKU+8M2CMMaZ8scBhjDGmWCxwGGOMKRYLHMYYY4rFAocxxphiscBhjDGmWCxwGBOGiLwnIo9FeOxqETkr1nkyJt4scBhjjCkWCxzGVAIikhjvPJiKwwKHKffcKqK7ReQPEdknIu+IyGEi8rWI7BGRKSJSx+f43iKyUER2ishUETnOZ197EZnjnjcaSA241/kiMs89d5qInBBhHs8TkbkisltE1orIkID9p7rX2+nu7+umVxGR50RkjYjsEpGf3bRuIpIR5N/hLPf1EBEZIyIjRGQ30FdEOovIdPceG0TkVRFJ9jm/tYh8IyLbRWSTiNwrIoeLyH4RqedzXEcR2SIiSZE8u6l4LHCYiuJSoAfQCrgA+Bq4F6iP83d+G4CItAI+Am4HGgATgC9EJNn9EB0LfADUBT5xr4t7bgdgGPAvoB7wJjBeRFIiyN8+4FqgNnAecLOIXORet5mb31fcPLUD5rnnPQt0BE528/QfIC/Cf5MLgTHuPT8EcoH/c/9NTgLOBP7t5qEGMAWYCBwBHA18q6obganA5T7XvRoYparZEebDVDAWOExF8YqqblLVdcBPwK+qOldVs4DPgfbucf8AvlLVb9wPvmeBKjgfzF2BJOBFVc1W1THATJ973Ai8qaq/qmquqr4PZLnnhaWqU1V1vqrmqeofOMHrdHf3VcAUVf3Ive82VZ0nIh6gHzBQVde595zmPlMkpqvqWPeeB1R1tqrOUNUcVV2NE/i8eTgf2Kiqz6lqpqruUdVf3X3v4wQLRCQBuAInuJpKygKHqSg2+bw+EGS7uvv6CGCNd4eq5gFrgcbuvnXqP/PnGp/XRwJ3ulU9O0VkJ9DUPS8sEekiIt+7VTy7gJtwvvnjXmNlkNPq41SVBdsXibUBeWglIl+KyEa3+uqJCPIAMA44XkRa4JTqdqnqbyXMk6kALHCYymY9TgAAQEQE50NzHbABaOymeTXzeb0WeFxVa/v8VFXVjyK470hgPNBUVWsBbwDe+6wFjgpyzlYgM8S+fUBVn+dIwKnm8hU49fXrwBKgparWxKnKKyoPqGom8DFOyegarLRR6VngMJXNx8B5InKm27h7J0510zRgOpAD3CYiiSJyCdDZ59y3gJvc0oOISDW30btGBPetAWxX1UwR6Qxc6bPvQ+AsEbncvW89EWnnloaGAc+LyBEikiAiJ7ltKsuAVPf+ScD9QFFtLTWA3cBeETkWuNln35fA4SJyu4ikiEgNEenis3840BfoDYyI4HlNBWaBw1QqqroUp77+FZxv9BcAF6jqQVU9CFyC8wG5A6c95DOfc2fhtHO86u5f4R4biX8Dj4jIHuBBnADmve5fwLk4QWw7TsP4ie7uu4D5OG0t24GnAY+q7nKv+TZOaWkf4NfLKoi7cALWHpwgONonD3twqqEuADYCy4HuPvt/wWmUn+O2j5hKTGwhJ2NMJETkO2Ckqr4d77yY+LLAYYwpkoh0Ar7BaaPZE+/8mPiyqipjTFgi8j7OGI/bLWgYsBKHMcaYYrIShzHGmGKpFBOf1a9fX9PS0uKdDWOMKVdmz569VVUDxwdVjsCRlpbGrFmz4p0NY4wpV0RkTbB0q6oyxhhTLBY4jDHGFIsFDmOMMcUS0zYOEekFvAQkAG+r6lNBjrkcGIIzIdvvqnqliLTDmZCtJs4aAo+r6mj3+PdwpoLe5V6ir6rOC7xuUbKzs8nIyCAzM7PYz1WepKam0qRJE5KSbM0dY0x0xCxwuLN1voYz/00GMFNExqvqIp9jWgKDgVNUdYeINHR37QeuVdXlInIEMFtEJqnqTnf/3e5aCSWWkZFBjRo1SEtLw38y1IpDVdm2bRsZGRk0b9483tkxxlQQsayq6gysUNVV7uRxo3BWJPN1I/Caqu4AUNXN7u9lqrrcfb0e2EzhKaMPSWZmJvXq1auwQQNARKhXr16FL1UZY0pXLANHY/wXkslw03y1AlqJyC8iMsOt2vLjTkGdjP8iM4+Ls770C6GW7RSR/iIyS0RmbdmyJWgGK3LQ8KoMz2iMKV2xDBzBPrEC5zdJBFoC3XCWo3xbRGrnX0CkEc6iMde7axOAU7V1LNAJZw3me4LdXFWHqmq6qqY3aBDVwooxxpRpa7fv58s/1jNtxdaYXD+WgSMDZ2U1ryY4q68FHjPOXWf5T2ApTiBBRGoCXwH3q+oM7wmqukEdWcC7+C+0U27s3LmT//3vf8U+79xzz2Xnzp1FH2iMKdMys3PJ2LH/kK+zZts+bnhvJvsP5uSnnfX8D9w6ci5Xvv0rO/YdPOR7BIpl4JgJtBSR5iKSDPTBWTrT11jcxWJEpD5O1dUq9/jPgeGq+onvCW4pxLvk50XAghg+Q8yEChy5ublhz5swYQK1a9cOe4wxpuyZvHAjgz+bn79968i5nPr094SaaHbVlr0M/dGpoZ+6dDNnPjeVgzl5+fsXrNvF2z+t4vT/TuXbJZt5ccpysnOd/Vk+x+XGYCLbmPWqUtUcEbkVmITTHXeYqi4UkUeAWao63t13togswul2e7eqbhORq4HTgHoi0te9pLfb7Yci0gCnKmwecFOsniGWBg0axMqVK2nXrh1JSUlUr16dRo0aMW/ePBYtWsRFF13E2rVryczMZODAgfTv3x8omD5l7969nHPOOZx66qlMmzaNxo0bM27cOKpUqRLnJzPG+Nq+7yB1qyXT/4PZADx5SVsApizeBMCvf27ng+lreOWK9ng8BTX8f39jOtv2HeTak9K47/MFrNt5gE27M6mRmsj0ldu4+cM5fvcZ+uMqhv64ivvOPc4v3RODds6YjuNQ1QnAhIC0B31eK3CH++N7zAhCrGusqmdEO58Pf7GQRet3R/Waxx9Rk4cuaB1y/1NPPcWCBQuYN28eU6dO5bzzzmPBggX53WaHDRtG3bp1OXDgAJ06deLSSy+lXr16ftdYvnw5H330EW+99RaXX345n376KVdffXVUn8MYE9zEBRvplFaHetWDL/X+7i9/8vAXzuiDl/q0y09/84eV9Gx9eP52n6FOTfzAs1rS6rCC5ev3ZDpVT6qwbucBAHLylHaPfBM2X49PWOy3nZsX/RKHjRwvIzp37uw31uLll1/mxBNPpGvXrqxdu5bly5cXOqd58+a0a+f8QXbs2JHVq1eXVnaNqdR27c/mphGz6fd+6MlTvUED4KflBY3UT369hKve/rXQ8Re++guLN+ym33sz2ZeVQ55bxTR23rr8Y56ZuKTYeY3FmkuVYnbcooQrGZSWatWq5b+eOnUqU6ZMYfr06VStWpVu3boFHYuRklLwTSchIYEDBw6USl6NKau+X7qZnFylx/GHxfQ+B922hIzthRu3c/OUz+ZkFErz5S1B+DqQncs5L/0EwOn/nUqOe45vu8jXCzYGzU8VMjlIErkkFM5PDAKHlTjipEaNGuzZE3wVzl27dlGnTh2qVq3KkiVLmDFjRtDjjDH+rn93JjcOj2wJhW8WbeKhcSXrW7Nog1O1vW3fQc56/gfW7zxAXp6Sk5vHp3MyuHvMH37Hfz53XbDLhLR1b1axjl+c2o93kp4Nui8WVVVW4oiTevXqccopp9CmTRuqVKnCYYcVfEPq1asXb7zxBieccALHHHMMXbt2jWNOjakYXpqynMZ1qnBZxyYA+QHm4QvbsGt/Nnmq1KmWzPJNe2hUuwrVU5yPx9/+3M62vVl0P7YhqUkJbNyVyXXDfsu/7orNezn5qe/87tVOVjAmeQgnZb3KFqLTC/JUz3ySyOH7vPYANJEt7NVUduK0i3RL+B2yC58Xi9XBLXDE0ciRI4Omp6Sk8PXXXwfd523HqF+/PgsWFHxbuuuuu6KeP2PKijXb9tGsbtVDmgnhhSnLALisYxO/b+HPTFzC/6Y63V7/fPJcerzwI12a12XotekkeoTL35xe7HvdkDiBRMmjW8I81uQdxm96XNEnFWFE8pMApGU6nxs/pwwE4MKsR8KeZyUOY0ylM2/tTi567RcevbA115yUFvbYhxPf5brEb4Bd5OYp63ceoGndqn4D7f7x5nSOP6Jm/rY3aAD8nuFMuv3rn9s58eHJYe/V1bOI1XmHsZF6hfbluq0Ajye+Q7I4Y7POy3qChRo+/8EczjZaeDaE3D8u5cGg6Sd7FtDdM49cPb3Y9yyKBQ5jTJm2bofTkDxt5TbS0+rSvH41UpMKNwKv3rrPDRrw5R/rGfTpfPZm5RQ67tc/t/Prn9uD3uv9aasjzteo5MfYrVU4IeudQvvy3MDhDRoAXTyLWZiblr99hmcOB0ni57y2+WntZTmJ5DJTj81PG5PyME2k+FOHjEx+AoBNKdH/mLfGcWNMVE1ZtImlG4N3/CiJKsnOx9T6nQc456WfuNftZaSq+V1N127fT7dnp+afc+vIuUGDRlGK24hdU4L3ZMwL8tEqAVP1DUt+lhHJT9JJnC627WU5n6c8xCcpBVVPLya9WqKg4euwmqmHdH4wFjiMMRF5+6dV/LXNqfJZvGG33/QXvv45fBY9X/wxomvuy8rJnyYj0LSVW8nNUx4ctxCAP7fuA5yqq6cnLqH54Am89O1yFqzbxY79gfMxxaBFuBjytHBbzPGe1UGPPcbjTCJ+U+IX+WlVcbrfX5QwLeg5aRK66gqgjazyyUz4aYxKwgKHMaZIO/Yd5LGvFnP1O7+yzv3m3/vVn3nrx1Vs3r6NtEFfMWlh8DEGoWzZk0Xrhybl926a+9cOLnt9Gtv2ZjH0x5Vc+davtHloEhluVdVudyT1qq37eN1tl3hxynLOf+VnVmze63ftwG/3pS03yEfrpQk/A5BEDpd4/APrBZ5p9Ewo6EbcVv4kieAlpmmDzmBqyp1B982+YAu12cOXKff7ZCb6kxxaG4cxpkjej+E9mdns2u/0+VyycQ/fT/yEG797gpM89/GvD2DRIz3DXuftn1aRp8rHszLyP+ynLt3Cx7PW8h937EPHx6bkH38gO7Jvy3d8/LvfdgJ55JTwe/FhbKezZwlf5J1crPPqsYs9VOUgSWjQVSUc/0kcxY2JBTMxJZDHzT6lDYDRKY+yT4NPZXLEilGh8/DNQOYF1kzlHoSk6M5hZyWOOCnptOoAL774Ivv3H/p0zMaURILPRHxdPc60GumyFID7x4YeUJedm8djXy3miQlLCpUQ/hMwYO5QecKUOI6Vv1ideiWtZTUAXycPom/CxPz9I5Kf5JXkV0khsm/qAxI+owqZzE69mWkpA+jp+Y28EIGjoyz1CxoADye9z/GeNYWOrSYhBgF+eXtE+cqnwasCD4UFjjixwGHKq4Qwnxrrg0yl4fX4V4tD7ovU0pRr+b/EMUUe5yH4h2V9djExZRAA1yZM5sOkxznO8xdDkoYzNvkBqrOfI9zG6Jrs56HE96mG80y9Pb9whseZkXZ16pX517wzaQyLU/s515fdvJn8YtDGcYBPUx6O8EmjKC/6gcOqquLEd1r1Hj160LBhQz7++GOysrK4+OKLefjhh9m3bx+XX345GRkZ5Obm8sADD7Bp0ybWr19P9+7dqV+/Pt9//328H8WUY1k5uTzx1WJuP6sVdaolFz5AFbIPoOp0f1Wg54s/hbzejFX+3VynLt3Mj8u28kC3urSbeRep3IigHKBkPX1SJIeBiZ/xQs5lQfYWlDLaeVYyI+94vw/4z3JP5VxPweSCHT3LONqz3u+cR5Pezf+mPzHlHurJHo6sk0q/Lf/g5eTXAPgyt0uR+bw2MfwMtqUqBiUOCxwAXw+CjfOLPq44Dm8L5zwVcrfvtOqTJ09mzJgx/Pbbb6gqvXv35scff2TLli0cccQRfPXVV4Azh1WtWrV4/vnn+f7776lfv35082wqnXHz1vP+9DVk5ylPXNzWb9/Py7fSOmM0dX64l21XOvOl7XTbNxqwg63UCnndFA4ybf4y+n7ozOrcdtZgLk6YxlatxT8Tv+a3vGNYnNeMh3KuD3kND3nUY3fEU3bUpaAL8Kjkxzg6c7jf/kvcxmkv36DhVZuCKrR64lzvjD3jOEpOzU8/P6HwzLZlmlqvqgpp8uTJTJ48mfbt29OhQweWLFnC8uXLadu2LVOmTOGee+7hp59+olat0P9RjfE1ccEG2j0ymawc/w+NH5dtYfGG3azYvJfM7Fwy3cZnjzhTU1z+xnS+XbyJ/sNncfU7v7LkO2dZnIfe8zbeKqd65jMz9ZawVUbDk5/i5E875W/nutUlbdwuqZ09S/MH63m1krX4lhr+kziaman/ph67inzeDrKMOan+a7o9nTS0yPMCpR9ZJ2j6jbUimzixTIpBd1wrcUDYkkFpUFUGDx7Mv/71r0L7Zs+ezYQJExg8eDBnn302Dz4YfHoBY3w9+uVidu7PZvPuLJrWrcquA9k8/tUiPp5VMN33sUmb2ZmdANRjxIy/uKX70fy2eju/rS6obhLxb2S+LmEyDye9D8BZnrlMcSfcuzNpDM1kM3fnOB/eXTz+60Z4u8eGanvoJEv4JOURHsq+jvdznZ5Z3T1zAagnu9mm/l+aqpJJW/mT3/QYFE/QIHa+p/glgxoZU4Om/yNvQtD0cqG8NY6LSC8RWSoiK0RkUIhjLheRRSKyUERG+qRfJyLL3Z/rfNI7ish895ovy6HMehZHvtOq9+zZk2HDhrF3r1NMXrduHZs3b2b9+vVUrVqVq6++mrvuuos5c+YUOteYYLz/K3LylMzsXE58eLJf0ACYmHA7M1IH5G+f9KT/DK9Q8IF/nPwFwAmeVYWO8fp7YuFBfz8mD+SfCV/lX6ezZ2nQc49zexW19fyZn+ZtYJ6ccg+rU6/0a69YlNqP0SmPcl2CM59UshQe85AiQaaKLSE5WI7/v8WgqipmJQ4RSQBeA3oAGcBMERmvqot8jmkJDAZOUdUdItLQTa8LPASk45RdZ7vn7gBeB/oDM3CWpe0FBJ9KtgzznVb9nHPO4corr+Skk04CoHr16owYMYIVK1Zw99134/F4SEpK4vXXXwegf//+nHPOOTRq1Mgax8sBVeWFb5ZxcYcmNK9fregTnJNgznBo+3dIrhr20K/+2ICiJCd4ONtdktQbOK56awbrdxVeBKwo9dhFss8AtAeTPmCZNgk7PgHgioRvWZx3ZP52M88W7vd8yNjc4GMiPkh6gr7Z9/CIW4ppKQXBLdggukAPVR/Lz7vbUIXirV9RqZSzqqrOwApVXQUgIqOAC4FFPsfcCLzmBgRUdbOb3hP4RlW3u+d+A/QSkalATVWd7qYPBy6iHAYOKDyt+sCBA/22jzrqKHr2LDygasCAAQwYMKBQuimbNu3O4uXvVvD5vHX89J8zIjtpxRT44jZ043y+anoH57RplD9+Ii9P+d/UFVxzUhobdh3glpFz/E6tWy2Z7fsOUo0DjMu8mQGeAazIa0wuwg5qFrpVCge5IWECQ3PPJ4dEenhm8Vby84WOG5H8JGNyT/NLayzb/LafTCo84R9AumdZ0PS/JSxgiL6fv32iZxUXeKaxWg/Pbw8JR7J2MyXlP0UeV6mVs6VjGwNrfbYzgMB+bK0AROQXIAEYoqoTQ5zb2P3JCJJeiIj0xymZ0KxZsxI/hDHRkpUdvq45/aEv6Fl/K48PuB6ynBXm5i1Zzthf3qZaeiO6X3IjAMc9OJGsnDyenbyMw4NMYLd9nzNw7ThZQwPZxV2JH+d/cHvXcvDVP+FL7kwaw16qMDy3Z9CgEUwiOVyaELprrq9wE/VdkzjFb/uV5FdZp4WnKjclFIPa/FgGjmC5DQx9iUBLoBvQBPhJRNqEOTeSazqJqkOBoQDp6enxnbjGVGregdZF/REOznuTS7f9BLt6sGrLPlrgrE39dvJz8Ac84DmJzs3rkuUzueDG3ZkcL6tRhDM8c6kl+3gi50pA8tefTvBrkFaSyeEgSfkp3m6ptyd+ml9lFIlWnuLNJFscgSUZU0z3b4E1v0D1w6DeUVG/fCwDRwbQ1Ge7CRDYcToDmKGq2cCfIrIUJ5Bk4AQT33OnuulNirhmxFT1kFYUKw80FutGmuB+/C+IB/7mTkB3cB/k5SLizDnkfS8Wb9jNZa9P47u7utGgegpZOXkkJ3poI27DcOZunvtmOa8FjMf7fMZixszwgDt47r7EEfypjXgioHpondbnBM9KNmldAGr5jE24M/ETBiSO5djMd/PTLnRnYK0r/tOABHNZQmSz3poYSK0NmTsjOzYhCY7qHrOsxLJX1UygpYg0F5FkoA8wPuCYsUB3ABGpj1N1tQqYBJwtInVEpA5wNjBJVTcAe0Skq9ub6lpgXEkyl5qayrZt2yr0B6uqsm3bNlJToz8fvwniu8fg24K1FHY90Qqecr479Un4jndzBgPw3s9/cnj2X3y3ZDNPT1zCcQ9OpMcLP5CI24iZXTBth+8srwtS/8ni1H5MSB6MhzxuTJxQKGiAM/fRpQk/8+9E579bC0/BrLVXJTjVQlWtMTl2rvdpch0wp/D+7vcXTotErSbB07sNLpwW4y/EMStxqGqOiNyKEwQSgGGqulBEHgFmqep4CgLEIiAXuFtVtwGIyKM4wQfgEW9DOXAz8B5QBadRvEQN402aNCEjI4MtW7aU7AHLidTUVJo0CfEHZ2Jm0+5MDnO/6e/78RWeSno7f1/nHeN4OuU5RvxZjTfnOqOiV23Zx1GpzhoL6z+9h9eSZxa+qOt4zxo6SvDG5qJ4SxX/SQw9w6o5RA0KVu8jMcgMt+n94PvHir7O2Y/BZJ8g4/2SKwlOF9trxkLD46DG4eBJhO8edfZf8nbha0VZTAcAquoEnC6zvmkP+rxW4A73J/DcYcCwIOmzgDaHmrekpCSaN29+qJcxldyCdbuokpzAUQ2q56fNXL2dx9/8gLHuZ0bazEf9zmlywBnL8LeFQ1idupmjM4eT4/NfMXn70uCteT58V4kriT6JUw/pfBPCVWP8g4VvV9heT8PKb6FKbbhlJmxZAt8+DNtWFL5Ol5vh5AFQtwWMutLplr3JWdAK8TiBI7WWEzQATrsLjjwZkqtDoxNi93wum3LEmENw/is/c+ZzP/il/f2N6YxNCT7Cf/qKrWRsd2Y2PtLj9D4fm/wgLaSgqa6+7M5/fV7Cb9HOsomllj0g2Xesjk9VeNNOcNUn4EmABq3g+N4wYHb46x17ntPQffFQnxKH92M7oJr9yJNLJWiABQ5jIDcbtq2M6NAPZqyh/SOTWbZpD2xbmT+Fxsez1hZxpuOat38ptFRqG89qBiV+VLw8m9g4tVDlR8ncNg9OHwS1CwZD0qh98GPT/lY4zbeNIjEZPJ6CqUM8Tm+5eC5yaIHDVC4H98GQWrDwc1g7E3JzYNK98EoH2OM2Iq/8zjlmX+GxBw+MXcCO/dnc+OLH8EoH7kj8BIC3P/0q/xjfqTECJYSYq6mm2PoqMVU3wi6pZ9wPZzxQsP23u+BMn9LjER0KXtcM03ZYtzl0H+wEgJt+hkvfcT78g+n7Jdy/uWA7pSZ07BvkQDdStOrl/K5xWLgniSkLHKZy2emWDD7pC++cBT885QQKgMzdTsD44GJne12QHjGuw9gBQCd37qXzIpxqe0TyE0GDRFfPoS9yZMLwbbAOx5PgtBd4tb+qoHs1QP2WBa+73wtDdsEVo8Nf8/C20DbY+iE+fNtFBq+FBscUPsZb4jj9HrhzWeheVqXAZsc1lUtgN8VNCwtXAXhpHgdWz2L7Z3eyJyuXz48s+ObpcWeN7eJZwpGykUwNsghSEJ08y5iZ16rE2TdFaNoF1gYJ4sF6NwGk1IIO18D0V+GkWwvv9wR8RJ73PBx/EbToVjCHWCt3WqBg5xdHQgqknRJ6f5+RMON1qN8qdOmllFiJw1RuezfDdmfG152Z/pPB/f7tR1R570wa757HsVnzab7IWQGuT8J3jEou6E75Q8od1ChGVVN7CdKLpjxpdlLhtOQakZ177rNw3AUlu+/hbYs+5tjzAhLEqWo6978hPtgVqrhrcCQECf7ewNHCHUyXUh2OPdd/4kkRp+TR8/Gi8xfOA5vhms9D729wDFzwYtyDBljgMJXFgZ0w5eHC7RbrChboue49/8V6Ttw81m87z+0j6zsmw8s72C4SiRL99RFi4rJCveEdNY8onBZptUnnG+EfI+DKT0If0+G64OnXl2DI1pCdTlVTtfrOB3uKu65H43Tnt18pM0hrs7cHU5+RwQfzVVIWOEyFsH3PfrbtLTwaetqKraQN+ooDE+6Hn5+H984NeY1G+4KvFVGgYk9PU0iwWRVOGQjnvxjsYP/NGkGCi6/aYSYeDVaiAUiJpFRTxHtUy50T9bxnnUbmPh+FH2XtDRzJVWMy51N5ZYHDlH25OTBvJKz+Gbb4fLhnzIYNf8Dvo6n7XCOuffwtGH4R7HbGROw/mMOVb//K3zx/kLmx6MbnN5KDfSAWOMGzKmyPqQonWOBI7wephadmL7TKnCfBv6dQIO83/botCu87sU/B6/s2Ft4PcM4zcMHLoa9fp3nwqT3S+7n70+DK0XDkSQXVUC0LL2GAJBROM9Y4bsqBX9+AyfcVbLe72qku+fEZZ7vVOQDcmzgSVi2En1+Ec59h4gLnQ+eD5KcgCjPLRLI+RKkZMMfpQhxTbuA4/kJIqga/j3RmWwXoegvMeM3n0IAgI57QDdLgTMIHzpcCX+k3+JcAkqoEP79zf5gTZibfY8+D0+8Oct6Nzo+vxh2cNgpfx18Ii8ZBks3zFowFDlPm6d7N/hUQ80b4H7BxPlAwIeC+DUs5uHUjd3z8e+lkMB6qN4z9PbzBICEZLn7d+fHq+bhTMnjTO3gtIHAE9lALlOxO0VK9AdwwCZ4/ztk+P8haIA3hzbkAACAASURBVMdfCNUaOK//byEkVXWCS7ASQqrbhpFaO/z9i3Lxm06JJTnCFRsrGQscpsxbsnE3x4U7YLf/WtrV1k4l8ZU2dPfcTg9PEVM6xFurXrBsYvHPC1bff/kH8PE1h56nfIFTXPgQcaa3OPUOp/Qwf0zA/iJqwavVd6bRaNGt6IFslw8veO3bCF+zETTpBBnuhJA3THFKD7kHQzewRyqpijMtiAnKAocpu1QhcycH1i8q+lggSQqqPVIkm3eT/xurnEVPNOrQj+4Bf3/P6Sp6wUvOh/hqn5X5rp/orCg48nL/8+5dD0+EacTOb7cI03h81kPO7y1LYbvPtC2BzzXw94KR+V4n/iP0dUuiaSfnd2BVlIk6axw38bd/O/z2VkHVyIEdTtpPz8HTaXTIjGxUdqcQ61qXWT0eLajrL4mabg+hboOcoAHOVBV9v/Q/7siTgo9ELqoa5kh3MFr7q4vOy0X/g36T4MyH/NNvm+e0x9RJg2Zdi75OcR3qoDtTIhY4TOnKOQhPNHbWGfA2jI67FSbcBevnOttPp8Ezzdkz77O4ZbNUdP136PEPx57vv33pO/BvN4A2OtH57Q063gFsvq7+1FmX4Xan/Se/9OBtAwgkHrh9AbS7Co46Awb+AXWOdBqNmweZhC9QcjUnMHjnUfI2cNdtHtturK0vit21TUgWOEzpeqE1HNwL016B7x9nycbd7NjqTik+/jb2bStYx3rN1n1xyuQhaHaS80GeEqTLaiBPQui2gH/4dABo0c2Z66jhsdD7FWcBH4A27vxH1eoXPv/os+CEvxeMl/CW5qrWc34f445n6XITNGztlAxqN3VKDtd87gSNEgnTLhJOsBliTZllbRymdO3z6du/YR63fDuKb1Pcksam+VR75fj83WWq+2ukug2GFqc7c2C9fnJBemD3VXC+lYfqsurbJdW3vaDDtQWvu98Hp/5fQTVVOEnuFBmHt4WbfimYXuOcp4s+tzgiaRcJ5prPnentfZ1YicbMlDMWOEzJrJ8H+7fB0Wc632bfOdsZVXzc+UWf67XyO75N+S52eSwVAqhTLbR+DqSd6iQf1tqZTvvDy52SQq8nCgLH1Z8VDDo7ZSD86DbiXzEKqjV0uqj63SLEt3ePJ7KgAU4PpOsnOj2hfOdZijZvCeeU24p3XkKSf3tP4LgKU6bENHCISC/gJZw1x99W1acC9vcF/gt46ydeVdW3RaQ78ILPoccCfVR1rIi8B5wOeP+y+qrqvNg9hQlq6OnO7yG7nO6PGb85U5U/WHgNi3w/BemjX961vshZ26NZV6dqyNfhbeHOICPWjz6z4HVKDac9Ibk6VKsX/B7FrfYJ5cgQU3lEU2qt0v/Qv2OxjfAuZTELHCKSALwG9AAygJkiMl5VA/tWjlZVv64Rqvo90M69Tl1gBTDZ55C7VTWg47iJP6d+e09mNlWSEkhM8PnA27PJWV+5Iun9KrS70ukdVbtpZOfUa1k4raj2hEivXVkFm3TRxFQsG8c7AytUdZWqHgRGAReW4DqXAV+rqi2RVlZ567XdBti2QyYz4KO5Bft3b4DnyvBgqoatS3Zeh2ucBu5IP9jv3QA3Tyv+fc5+rOhjjClFsQwcjQHfhZgz3LRAl4rIHyIyRkSC/Q/sAwQuyPy4e84LIhK0dVFE+ovILBGZtWVLFCYqMsEt+BRGXOpuFEw78bU7TxS5OfB8hKuvxcu/I/gwrxqiGqk4kqs660cXV6j5moyJk1gGjmDdKgKn2/wCSFPVE4ApgN+sZSLSCGgLTPJJHozT5tEJqAvcE+zmqjpUVdNVNb1BgwbBDjHRMKYfrPnFea0K6+fxQ/Lt9E2Y6CzD+mgUPnBLQ+BKb34EOv2z1LLiJ9y61sbESSwDRwbgW4JoAqz3PUBVt6mqdxGFt4COAde4HPhcVbN9ztmgjizgXZwqMXMocrKcD/mZhRcoKh6FoadzpGczQ5KGF314CWzREAPYDtV/VhVeKKiZ25224fHOOs+l7a4VcMuM0r+vMUWIZeCYCbQUkeYikoxT5eS3TJpbovDqDQR2QbmCgGoq7zkiIsBFwIIo57vyObDD+f3DM/HNRwR+z2vBpVkPFX1gcaXWgip1/dP6fQ1XjIZrx/nP9nr6IGf21Fir3iDCxYuMKV0x61WlqjkicitONVMCMExVF4rII8AsVR0P3CYivYEcYDvQ13u+iKThlFh+CLj0hyLSAKcqbB5wU6yewYSQfSBut/4o9wzyivt9p1pD/4GHALf8Bq+FKKzWb+XsBzimV+H93QcX7/7GVDAxHcehqhOACQFpD/q8HozTZhHs3NUEaUxX1TOim0vjZ90c2Lay8JgEr02L4PVSGA8QxOyrFvLtO79TnQg72DVOh63LChqXfYNFsEn//EZrV7JlYo0pBhs5bvy95Y5o9g0cuTlOI3fTrrA2fnXuHdPqM/WubmzZmwXvFXFw7WbQZ6Sz1sPL7Z00T6KzfsNJt8Q6q8ZUaBY4KqpvH3VGCh99VuF9OQcBLTxP0t5NfptPTFjMhmmjeOVM97h4BI2q9ZypTQDEQ1r9VNLqV3PmXsre74yNEIFXOzlVaPu3OjPL9vmw4BodroUpQ5zJAP85JczNJP8+xpjQLHBUVD89Cz8RfPqHF9s4QSLc1BBZe/jyx9+Ylvpi4VamKJud15KOnuX525dmPcSnKe4o826DnSnXwb+BesAc2LuxYN6lgX8U7AusZjrldjj5tqKXM613tDMZYacbgu9PqQnHnBPBExlTsdlXq8pk82KY80FByWLbytDHPtmEaanFnKiuCIOy/0la5ki+zu3kl/5gdl+/7U3UhUF/OTO/+i4B6lsSqNkIjmhfsO3xFPwEBg6R4EGjRiM4a4j/NXo9EXr9iMFr4ZKhIZ/PmMrCShyVwfq5zgps/wtYge2VDvDgjlLLxqhcp/3klZyLae1ZQ7PaKbBrLfeeexx8W3DcT/ec6XSPPWuI/wWi3WB955LoXs+YSsJKHBXd9lUwtBu80zP4/tFXFyzyE3POB/8iTePzv03IX43ulKP9R/ZLUVVKxpi4ssBR0X3uDnPZujT4/qVfRXUuqYEH/x1y3/TBZzDr/rP4W8v6XHPSkQUBSwQa+OTBpsg2pkyzwFHR5a/IVjrCDc5rVKsK9aun8MENXahbLdlZKQ+gan245Ve46A0naARbQ9sYU2ZY4Civti53pisvSikHjoa1ClaXe7LVqPAH93gUbpvrNHQDtLsCHtpeshlkjTGlxgJHefVqeugqJt82i3WzSyc/rvsu7gLA7ipNufWSs6CZO8r8P38WPjghEeq2KPqix18UxRwaYw6V9aqqaHKyYPyAmN/mtZze9PLM5ChPQann4BVjSG55JnS5mZrp/SA1CfpNPPSbXfYu6DuHfh1jTFRYiaOiGFLLGT39WEP4Y3RMb7Whehv+9fD7vJfr31Mr+ZgeTkP3OU9Bgyiu+OfxOKUTY0yZYIGjvNu2Enatc15vXRaTW+SpcFTmB/kD9w6vmUxigocRuWdxZtZ/Y3JPY0zZZV/jyrtXOsT8Fi/lXEIuCTyQ3Y9zEmYibZ0JEBUPKzXYasDGmIrMAocJ6a7sf/FF7klkkQTAVmrB/ZshwXo9GVOZWVWVCWlSbieySKZx7YIutiSm5E/9cWePKLZjGGPKDQscldBNB28Puz8tcyRpmSPZQ9Wwxw04syWrnzoPznwQjjozmlk0xpRhMQ0cItJLRJaKyAoRGRRkf18R2SIi89yff/rsy/VJH++T3lxEfhWR5SIy2l3PvHKZ8fohnT4xrzPnZT3hl3Z/9vUALM5rGvI8T6g5Bv92J1zz2SHlyRhTfsSsjUNEEoDXgB5ABjBTRMar6qKAQ0er6q1BLnFAVdsFSX8aeEFVR4nIG8ANwKF9kpYXuTmQtRu+f7LEl/g9zxlwt1DT6HfwLoYlP8vXuZ0YkduDUbndaVqnGn8+fCbfLNrEM5OWsmLzXu7o0Yp61ZNpUb96tJ7EGFOOxbJxvDOwQlVXAYjIKOBCIDBwRExEBDgDuNJNeh8YQmUJHF8OhLkjin3aVq1JfdkNQJ+D9+enf5fXgYuyHmGxNgMgh0R6ntAEEeHs1odzduvDo5NvY0yFEsvA0RhY67OdAXQJctylInIasAz4P1X1npMqIrOAHOApVR0L1AN2qmqOzzWD9gcVkf5Af4BmzZod6rOUDSUIGt/kduTL3C68lPw/vsztwgFS8/etfOJcVm3ZS2KCh4Xrd3HryLn0PvGIaObYGFMBxTJwBKsRD1z44QvgI1XNEpGbcEoQZ7j7mqnqehFpAXwnIvOB3RFc00lUHQoMBUhPTy+tBSeia800mPshNEkv8Yyxa7QhC7Q5AFNyO/rtS/AILQ+rAUDz+tU4/wQLGsaYokUUOETkU2AY8LVqxNOtZgC+La1NgPW+B6jqNp/Nt3DaL7z71ru/V4nIVKA98ClQW0QS3VJHoWtWKO+661vPK35Jw+svbchKbcyxme+SSUqUMmaMqcwi7VX1Ok67wnIReUpEIln5ZybQ0u0FlQz0Acb7HiAijXw2ewOL3fQ6IpLivq4PnAIsUlUFvgcuc8+5DhgX4TOUH/u2wf7th3SJYTm9uOHgnXyQ2wOATFJITvAw4oYuNKlThX93C7GutjHGFCGiEoeqTgGmiEgt4ArgGxFZi1NKGKGq2UHOyRGRW4FJQAIwTFUXisgjwCxVHQ/cJiK9cdoxtgN93dOPA94UkTyc4PaUT2+se4BRIvIYMBeoWNOmzh0B42455Ms8knNt/uuX+rSjZmoSp7VqQIJH+PmeM8KcaYwx4YlGuN60iNQDrgauwake+hA4FWirqt1ilcFoSE9P11mzZsU7G5EZUisql0nLHAnAFZ2b8eQlbaNyTWNM5SIis1U1PTA90jaOz4BjgQ+AC1TVuwjDaLfnk4mG+WOiermGNVKsSsoYE3WR9qp6VVW/C7YjWDQyJfTpDSU+dXZeS5LJZnpea57KuQKAsbecwhG1q0Qrd8YYA0QeOI4TkTmquhOcxmvgClX9X+yyZiI1MucM7s35Z6F0CxrGmFiItFfVjd6gAaCqO4AbY5MlU1x5QYbMnNAkOm0lxhgTKNISh0dExO0O652HqvJNLlhG5fnE/7G3nMKabfs4qUW9OObIGFORRRo4JgEfu5MKKnATMDFmuTLF4i1xpB9Zh3ZNa9Ouae0458gYU5FFGjjuAf4F3Iwzlchk4O1YZapSmjM85K41eQ050rM55P6dVOfzf59M28ZWPWWMib1IBwDm4Ywerxyz0JY2VRg/IOiuXBVOP/giq1OvDLo/p+fT3Nz+WlJSwy+6ZIwx0RJR47iItBSRMSKySERWeX9inblK4+X2IXeNyT3db7ttpn9BL/GkmyxoGGNKVaS9qt7FKW3kAN2B4TiDAc2hWjMddvwZcvcvea39totaztUYY2It0jaOKqr6rduzag0wRER+Ah6KYd4qtlU/wAcXg+aGPWx83smF0j7pPJq/V5sP7a+OVe6MMSakSANHpoh4cGbHvRVYBzSMXbYqgZ+eLTJodMl8lcBlTa7peiTnn3UcJPeKYeaMMSa0SKuqbgeqArcBHXEmO7wuVpmqFCKYXDKXhILXSdWh4fE8elEbqiQnhDnLGGNiq8gShzvY73JVvRvYC1wf81xVBnnhSxvgPyI84b51scyNMcZErMjAoaq5ItLRd+S4OQRzhoMnEbL3F3losKlEjDEm3iJt45gLjBORT4B93kRV/SwmuarIQozXCCaHBN64uiMtD6sewwwZY0zxRBo46gLbAN+l4xSwwBFFL+ZcQntZwQM519NSMji97VH0anN4vLNljDF+Ih05bu0a0TDh7rC7x+SexovqLKf+lx7GuVjNoDGm7Il0BcB3ofCnmKr2K+K8XsBLOGuOv62qTwXs7wv8F6d7LzgLRr0tIu1wBhzWBHKBx1V1tHvOe8DpwC73nL6qOi+S54i734aG3Z2h/j2crUXJGFMWRVpV9aXP61TgYpx1x0Nye2O9BvQAMoCZIjJeVRcFHDpaVW8NSNsPXKuqy0XkCGC2iEzyWRPkblWN7jqrceZdIxzgrOMaMmXxZgscxpgyKdKqqk99t0XkI2BKEad1Blao6ir3nFHAhUBg4Ah2v2U+r9eLyGagAbAz9FkVQ+PaVXj5ivYMGDmXe889Lt7ZMcaYQiIdABioJdCsiGMaA2t9tjPctECXisgf7iSKTQN3ikhnnEWjVvokP+6e84KIpAS7uYj0F5FZIjJry5YtRWS17Phl0BlUTU7knb6daFbP5qUyxpQ9kc6Ou0dEdnt/gC9w1ugIe1qQtMDKly+ANFU9AacE837AfRvhTKZ4vTu1O8Bg4FigE05vr6D5UNWhqpququkNGjQoIqsxlJMF3z0GUx4utOuvvDjmyxhjSijSqqoaJbh2BuBbgmhCQLuIqm7z2XwLeNq7ISI1ga+A+1V1hs85G9yXWW6j/V0lyFvpmfE/+PG/QXc9nXMFryW/nL99VZeiCnHGGBN/kfaquhj4TlV3udu1gW6qOjbMaTOBliLSHKfXVB/AbzUiEWnkEwh6A4vd9GTgc2C4qn4S7BwREeAiYEEkzxA3e0NXk/kWv1Y/dV7s82KMMVEQaRvHQ96gAeD2bgo7pbqq5gC34qxXvhj4WFUXisgjItLbPew2EVkoIr/jTKDY102/HDgN6Csi89yfdu6+D0VkPjAfqA88FuEzlL4ty2DGayF3q7c2r+XZpZQhY4w5dJF2xw0WYCKZ52oCMCEg7UGf14Nx2iwCzxsBjAhxzTOCpZdJm8IXhrJIcl5UqVMKmTHGmOiItMQxS0SeF5GjRKSFiLwAzI5lxiqDqXnteDT7ajg3eBuIMcaURZEGjgHAQWA08DFwALglVpmqMCT07LZdMl8lDw/a9RZIrVWKmTLGmEMTaa+qfcCgGOel4gkx9PuF7EvZRF0AHrzg+NLMkTHGHLJIx3F84/ak8m7XEZFJsctWxXVC5lBeyr003tkwxpgSi7Sqqr7PPFGo6g5szfGiHdheKCkn4v4IxhhTNkUaOPJEJH90moikEWS2XONj/3b46s5CyTnuOuKpSR7OP6FRaefKGGMOWaRff+8DfhaRH9zt04D+sclSBTG8d9DkbDdwLHn0nNLMjTHGRE2kjeMTRSQdJ1jMA8bh9KwyoWycHzRZ8TDngR6lnBljjImeSKcc+ScwEGe+qXlAV2A6/kvJmiIsyEtj6WO9SElMiHdWjDGmxCJt4xiIMxvtGlXtDrQHys9c5WXE+QefsKBhjCn3Ig0cmaqaCSAiKaq6BDgmdtmqWFblHc6NB+/g9FY2jboxpvyLtHE8wx3HMRb4RkR2UMTSsZXa4i/8Nu/LuYHpea3pf3hJZqc3xpiyJdLG8Yvdl0NE5HugFjAxZrkqz2a+A1/dEXRXz9aHlXJmjDEm+oo9Gk1Vfyj6qEosRNAA6Hhk3VLMiDHGxEZJ1xw3xfRw79bxzoIxxkSFBY5SICiXdmwS72wYY0xUWOAoBed3bEH1FJujyhhTMcQ0cIhILxFZKiIrRKTQtOwi0ldEtvgsD/tPn33Xichy9+c6n/SOIjLfvebL7trjZUPANOpf5nbhP9k30qxtt/jkxxhjYiBmX4NFJAF4DegBZAAzRWS8qi4KOHS0qt4acG5dnDXN03EmU5ztnrsDeB1n6pMZOMvS9gK+jtVzFMsXA/02h2T3ZSu16F2GYpsxxhyqWJY4OgMrVHWVqh4ERgEXRnhuT+AbVd3uBotvgF4i0gioqarTVVWB4cBFsch8icx5329zK87KfnWrJccjN8YYExOxDByNgbU+2xluWqBLReQPERkjIk2LOLex+7qoayIi/UVklojM2rIlfrOjjO7fleOPqBm3+xtjTLTFMnAEq58JXMPjCyBNVU8ApgDer+yhzo3kmk6i6lBVTVfV9AYN4jfVR5cW9eJ2b2OMiYVYBo4MoKnPdhMCpilR1W2qmuVuvgV0LOLcDPd1yGuWJU9e0jbeWTDGmKiLZeCYCbQUkeYikgz0Acb7HuC2WXj1Bha7rycBZ7trm9cBzgYmqeoGYI+IdHV7U12LszZI/AX0qDom8z26HWOTGhpjKp6Y9apS1RwRuRUnCCQAw1R1oYg8AsxS1fHAbSLSG8gBtgN93XO3i8ijOMEH4BFV9S7gfTPwHlAFpzdV2ehR9XBtv81cPCQn2DAZY0zFE9NRaao6AafLrG/agz6vBwODQ5w7DBgWJH0W0Ca6OY2+XDwkJ1rgMMZUPPbJFiNqgcMYU0HZJ1sMWVWVMaYisk+2GMjWBH6990zK0mwoxhgTLRY4oiGgR9V8bc5hNVPjlBljjIktCxzRsONPv82kRJsJ1xhTcVngiIZNC/02mzewKUaMMRWXBY6o8G/L2NlpYIjjjDGm/LPAEQ2ehPyX/Q7eRV7zM+KYGWOMiS0LHNFQ/bD8l4LSrF7VOGbGGGNiywJHFOz9a17+61euaB/HnBhjTOxZ4IiC5O8fzn9dNdl6VBljKjYLHNFgA/2MMZWIBY4oyMzOK9jQoOtKGWNMhWGBIwpq5u2KdxaMMabUWOA4RLszswNSrMRhjKnYLHAcov1ZufHOgjHGlCoLHIfor+37/ROsjcMYU8FZ4DhEXy/YEO8sGGNMqYpp4BCRXiKyVERWiMigMMddJiIqIunu9lUiMs/nJ09E2rn7prrX9O5rGMtnKMq4X/4ISLEShzGmYovZaDURSQBeA3oAGcBMERmvqosCjqsB3Ab86k1T1Q+BD939bYFxqjrP57Sr3LXH4+6qw9fCTncjqSqknRrX/BhjTKzFssTRGVihqqtU9SAwCrgwyHGPAs8AmSGucwXwUWyyeOiWbzlQsHH7AqhSJ36ZMcaYUhDLwNEYWOuzneGm5ROR9kBTVf0yzHX+QeHA8a5bTfWAhFifVUT6i8gsEZm1ZcuWEmS/CLnZDJ8yi2z1uX1K9ejfxxhjyphYTqwU7AM9vwFARDzAC0DfkBcQ6QLsV9UFPslXqeo6t4rrU+AaYHihG6kOBYYCpKenR7/h4a3uXLtxPr2SahekJaZE/TbGGFPWxLLEkQE09dluAqz32a4BtAGmishqoCsw3ttA7upDQGlDVde5v/cAI3GqxErNGz+s5LnRk2DjfAAays4izjDGmIolloFjJtBSRJqLSDJOEBjv3amqu1S1vqqmqWoaMAPo7W30dkskf8dpG8FNSxSR+u7rJOB8wLc0Eht5efDVXbBpId9MHEeLBS/F/JbGGFNWxayqSlVzRORWYBKQAAxT1YUi8ggwS1XHh78CpwEZqrrKJy0FmOQGjQRgCvBWDLJfYNtK+ONjmPkWzHyLT0PVRh3WNqbZMMaYskK0Eox0Tk9P11mzSth7d0ityI67dhy06FayexhjTBkkIrNVNT0w3UaOG2OMKRYLHMYYY4rFAkcJ3HnwpiCptgqgMaZysMBRTP1SnuW5J56GIbug+uHxzo4xxpQ6CxzFsP7Cjxk2+MaChIHzoMO1zuvaTYOfZIwxFYwFjjB27DtYsNHsZI5o/Tf/A5KqwAUvw51LoW6L0s2cMcbEiQWOMNZOHVaw0e9rSK5a+CARqGFVVsaYysMCRxhVlztjFPe2uTrOOTHGmLLDAkcYY497geZZI6l+2WvxzooxxpQZFjjCyFMl0WPdbI0xxpcFjjDyFMTGZxhjjB8LHGGoKsGXiTLGmMrLAkcYCngschhjjB8LHGHk5SnWxGGMMf4scISRp1biMMaYQBY4wsizNg5jjCnEAkcYqorH6qqMMcZPTAOHiPQSkaUiskJEBoU57jIRURFJd7fTROSAiMxzf97wObajiMx3r/mySOzKBFZVZYwxhcVszXERSQBeA3oAGcBMERmvqosCjqsB3Ab8GnCJlaraLsilXwf6AzOACUAv4OsoZx9wq6picWFjjCnHYlni6AysUNVVqnoQGAVcGOS4R4FngMyiLigijYCaqjpdncXShwMXRTHPftS5Z6wub4wx5VIsA0djYK3Pdoablk9E2gNNVfXLIOc3F5G5IvKDiHjnM2/sXifkNaNJ1brjGmNMoJhVVRF8LVXN3yniAV4A+gY5bgPQTFW3iUhHYKyItC7qmn43F+mPU6VFs2bNipdzV16etXEYY0ygWJY4MgDfZfGaAOt9tmsAbYCpIrIa6AqMF5F0Vc1S1W0AqjobWAm0cq/ZJMw186nqUFVNV9X0Bg0alOgB8qzEYYwxhcQycMwEWopIcxFJBvoA4707VXWXqtZX1TRVTcNp7O6tqrNEpIHbuI6ItABaAqtUdQOwR0S6ur2prgXGxeoB8tTaOIwxJlDMqqpUNUdEbgUmAQnAMFVdKCKPALNUdXyY008DHhGRHCAXuElVt7v7bgbeA6rg9KaKSY8q9xnw2EgXY4zxE8s2DlR1Ak6XWd+0B0Mc283n9afApyGOm4VTxRVzTndcK3EYY4wv+z4dhjM7brxzYYwxZYsFjjBs5LgxxhRmgSMMm+TQGGMKs8ARhjMA0CKHMcb4ssARhg0ANMaYwixwhGFVVcYYU5gFjjCscdwYYwqzwBGGWonDGGMKscARhjOOwyKHMcb4iunI8fKu45F12JOZE+9sGGNMmWKBI4xbuh8d7ywYY0yZY1VVxhhjisUChzHGmGKxwGGMMaZYLHAYY4wpFgscxhhjisUChzHGmGKxwGGMMaZYLHAYY4wpFlHVeOch5kRkC7CmhKfXB7ZGMTvxZM9S9lSU5wB7lrLqUJ7lSFVtEJhYKQLHoRCRWaqaHu98RIM9S9lTUZ4D7FnKqlg8i1VVGWOMKRYLHMYYY4rFAkfRhsY7A1Fkz1L2VJTnAHuWsirqz2JtHMYYY4rFShzGGGOKxQKHMcaYYrHAEYaI9BKRpSKyQkQGxTs/RRGR1SIyX0TmicgsN62uiHwjIsvd33XcdBGRl91n+0NEOsQ578NEZLOILPBJEG/erAAABdFJREFUK3beReQ69/jlInJdGXqWISKyzn1v5onIuT77BrvPslREevqkx/XvT0Saisj3IrJYRBaKyEA3vdy9L2GepTy+L6ki8puI/O4+y8NuenMR+dX9Nx4tIslueoq7vcLdn1bUMxZJVe0nyA+QAKwEWgDJwO/A8fHOVxF5Xg3UD0h7Bhjkvh4EPO2+Phf4GhCgK/BrnPN+GtABWFDSvAN1gVXu7zru6zpl5FmGAHcFOfZ4928rBWju/s0llIW/P6AR0MF9XQNY5ua33L0vYZ6lPL4vAlR3XycBv7r/3h8Dfdz0N4Cb3df/Bt5wX/cBRod7xkjyYCWO0DoDK1R1laoeBEYBF8Y5TyVxIfC++/p94CKf9OHqmAHUFpFG8cgggKr+CGwPSC5u3nsC36jqdlXdAXwD9Ip97v2FeJZQLgRGqWqWqv4JrMD524v735+qblDVOe7rPcBioDHl8H0J8yyhlOX3RVV1r7uZ5P4ocAYwxk0PfF+879cY4EwREUI/Y5EscITWGFjrs51B+D+0skCBySIyW0T6u2mHqeoGcP7zAA3d9PLwfMXNe1l/plvdKpxh3uodysmzuNUb7XG+3Zbr9yXgWaAcvi8ikiAi84DNOIF4JbBTVXOC5Cs/z+7+XUA9DuFZLHCEJkHSynrf5VNUtQNwDnCLiJwW5tjy+HxeofJelp/pdeAooB2wAXjOTS/zzyIi1YFPgdtVdXe4Q4OklfVnKZfvi6rmqmo7oAlOKeG4YIe5v6P+LBY4QssAmvpsNwHWxykvEVHV9e7vzcDnOH9Qm7xVUO7vze7h5eH5ipv3MvtMqrrJ/c+eB7xFQZVAmX4WEUnC+aD9UFU/c5PL5fsS7FnK6/vipao7gak4bRy1RSQxSL7y8+zur4VTlVriZ7HAEdpMoKXbUyEZp1FpfJzzFJKIVBORGt7XwNnAApw8e3uxXAeMc1+PB651e8J0BXZ5qx/KkOLmfRJwtojUcascznbT4i6g/ehinPcGnGfp4/Z8aQ60BH6jDPz9ufXg7wCLVfV5n13l7n0J9Szl9H1pICK13ddVgLNw2my+By5zDwt8X7zv12XAd+q0jod6xqKVZm+A8vaD00tkGU794X3xzk8ReW2B00Pid2ChN784dZnfAsvd33W1oGfGa+6zzQfS45z/j3CqCrJxvgndUJK8A/1wGvlWANeXoWf5wM3rH+5/2EY+x9/nPstS4Jyy8vcHnIpTdfEHMM/9Obc8vi9hnqU8vi8nAHPdPC8AHnTTW+B88K8APgFS3PRUd3uFu79FUc9Y1I9NOWKMMaZYrKrKGGNMsVjgMMYYUywWOIwxxhSLBY7/b+/+WasIojgMvz8RRA1oo42FojYiaMBOEQS/gIUSUINY29iJoAj2loIpI6YQxTSWpgikEMVLKrGySi9CBC3isdiJfzFm4SbX4n2q3WF22CmWszMw50iSejFwSJJ6MXBI/7kkZ5I8H/V7SKsMHJKkXgwc0pAkudzqJCwmmWqJ6JaT3EsySDKXZE/rO57kZUuuN5sfNS0OJ3nRai0Mkhxqw48leZrkXZKZdhJaGgkDhzQESY4AE3SJJseBFeASsBMYVJd8ch640x55CNyoqmN0J5dX22eA+1V1HDhJdwIdumyu1+lqKBwETm34pKS/2PrvLpLW4SxwAnjdFgPb6ZL/fQUetz6PgGdJdgG7q2q+tU8DT1qusX1VNQtQVZ8B2nivqmqp3S8CB4CFjZ+W9CcDhzQcAaar6uYvjcnt3/qtleNnre2nLz9dr+C3qxFyq0oajjngfJK98L0u9366b2w1Y+lFYKGqPgIfkpxu7ZPAfHX1IZaSnGtjbEuyY1NnIa2Dfy3SEFTV2yS36CowbqHLjHsN+AQcTfKGrvLaRHvkCvCgBYb3wNXWPglMJbnbxriwidOQ1sXsuNIGSrJcVWOjfg9pmNyqkiT14opDktSLKw5JUi8GDklSLwYOSVIvBg5JUi8GDklSL98An3PVm4aYHfEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 60.02324230271948\n",
      "['loss', 'acc']\n",
      "3442\n",
      "446\n",
      "367\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test accuracy:', score[1]*100)\n",
    "print(model1.metrics_names)\n",
    "\n",
    "Y_pred=model1.predict(X_test)\n",
    "\n",
    "\n",
    "# print(len(Y_test[Y_test==1]))\n",
    "print(len(Y_pred))\n",
    "print(len(old[old==4]))\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(len(Y_pred[Y_pred==4]))\n",
    "\n",
    "# print(len(Y_pred[Y_pred<0.5]))\n",
    "# print(len(Y_pred[Y_pred<0.5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 2 ... 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "# print(Y_pred)\n",
    "# Y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(Y_pred)\n",
    "new=Y_pred\n",
    "Y_pred = Y_pred.reshape(len(Y_pred), 1)\n",
    "Y_pred = onehot_encoder.transform(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_pred=(Y_pred > 0.5).astype(np.int)\n",
    "\n",
    "# print(Y_pred)\n",
    "Y_pred=np.ravel(Y_pred)\n",
    "# print(len(Y_pred[Y_pred==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 253   45  120    2   26]\n",
      " [  72  119  314    5   19]\n",
      " [  59   67 1406   24   36]\n",
      " [  19    3  295   57   55]\n",
      " [  33   11  143   28  231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.57       446\n",
      "           1       0.49      0.22      0.31       529\n",
      "           2       0.62      0.88      0.73      1592\n",
      "           3       0.49      0.13      0.21       429\n",
      "           4       0.63      0.52      0.57       446\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      3442\n",
      "   macro avg       0.56      0.47      0.48      3442\n",
      "weighted avg       0.58      0.60      0.56      3442\n",
      " samples avg       0.60      0.60      0.60      3442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(old, new)\n",
    "print(cm)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
